{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import processing_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the input and output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder containing PDF files (1512, removed researchpaper1.pdf)\n",
    "dataset_path = \"F:\\Datasets/\"\n",
    "# output folder and file name\n",
    "# output_path = \"dataset\"\n",
    "# processing_pdf.clear_processed_folder(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Remove duplicated files, only keep the papers (941) with newest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the base filename without the version suffix\n",
    "def get_base_filename(filename):\n",
    "    match = re.match(r'^(.*?)v\\d\\.pdf+$', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return filename\n",
    "\n",
    "# Function to find the newest version of each file\n",
    "def find_newest_versions(folder):\n",
    "    files_by_base_name = defaultdict(list)\n",
    "\n",
    "    # Group files by base filename\n",
    "    for filename in os.listdir(folder):\n",
    "        base_name = get_base_filename(filename)\n",
    "        files_by_base_name[base_name].append(filename)\n",
    "\n",
    "    # Find the newest version of each file\n",
    "    newest_versions = []\n",
    "    for base_name, filenames in files_by_base_name.items():\n",
    "        newest_version = max(filenames, key=lambda x: int(re.search(r'v(\\d+)\\.pdf$', x).group(1)))\n",
    "        newest_versions.append(newest_version)\n",
    "\n",
    "    return newest_versions\n",
    "\n",
    "# Function to remove duplicated files\n",
    "def remove_duplicates(folder):\n",
    "    newest_versions = find_newest_versions(folder)\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename not in newest_versions:\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "remove_duplicates(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Breakdown PDF content by sections and subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_pdf(file_path):\n",
    "    doc, total_text, _ = processing_pdf.open_file(file_path)\n",
    "    table_of_content = doc.get_toc()\n",
    "\n",
    "    if len(table_of_content) > 0:\n",
    "        print(\"Auto generated table of content:\")\n",
    "        display(table_of_content)\n",
    "        # separate content into sections\n",
    "        _, json_dict = processing_pdf.separate_content(total_text, table_of_content)\n",
    "        return json_dict\n",
    "    # some papers have not table of content\n",
    "    #if len(table_of_content) == 0:\n",
    "    #    print(\"The paper has not table of content. Need to use regular expression to map table of content.\")\n",
    "    #    table_of_content = processing_pdf.auto_find_toc(doc)\n",
    "    #    display(table_of_content)\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF file: 1901.00100v1.pdf\n",
      "Processing PDF file: 1901.00101v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction', 1],\n",
       " [1, 'II Related Work', 2],\n",
       " [1, 'III Safety-Guided RRT  via Probabilistically Safe Corridors', 2],\n",
       " [2, 'III-A Gaussian Mixture Modeling of Configuration Spaces', 2],\n",
       " [3, 'III-A.1 Learning Gaussian Mixtures', 3],\n",
       " [3, 'III-A.2 Confidence Regions of Gaussian Mixtures', 3],\n",
       " [2, 'III-B Probabilistically Safe Corridors', 4],\n",
       " [2, 'III-C Guided Steering via Safe Corridors', 5],\n",
       " [3, 'III-C.1 Tree Extension in the Configuration Space', 5],\n",
       " [3, 'III-C.2 Tree Extension in the Task Space', 6],\n",
       " [3, 'III-C.3 GMM-based Biased Sampling', 6],\n",
       " [1, 'IV Results', 6],\n",
       " [2, 'IV-A Learning Gaussian Mixture Models', 6],\n",
       " [2, 'IV-B 2DoF Planar Manipulator', 6],\n",
       " [2, 'IV-C 7DoF Manipulator in 3D Space', 8],\n",
       " [2, 'IV-D Physical Robot Experiments', 8],\n",
       " [1, 'V Discussion', 9],\n",
       " [1, 'References', 9]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00101v1.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 7 Total # of files: 1\n",
      "============================================================\n",
      "Processing PDF file: 1901.00102v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 2],\n",
       " [1, '2 The bremsstrahlung cross section with screening potential', 4],\n",
       " [1, '3 Comparing with the Bethe-Heitler formula', 14],\n",
       " [1, '4 Summary', 21]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00102v1.pdf\n",
      "# of sections: 5\n",
      "Total # of sections: 12 Total # of files: 2\n",
      "============================================================\n",
      "Processing PDF file: 1901.00103v1.pdf\n",
      "Processing PDF file: 1901.00104v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1. Introduction', 1],\n",
       " [1, '2. Background', 2],\n",
       " [2, 'notation', 2],\n",
       " [2, '2.1. Some properties of characters of KR modules', 3],\n",
       " [2, '2.2. fermionic formula', 5],\n",
       " [2, '2.3. polyhedral formula', 5],\n",
       " [1, '3. framework for proving polyhedral formula', 6],\n",
       " [1, '4. Proof of Theorem ??', 7],\n",
       " [2, '4.1. Step ??', 8],\n",
       " [2, '4.2. Step ??', 10],\n",
       " [1, 'References', 13]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'pagesize'\n",
      "MuPDF error: syntax error: unknown keyword: 'width'\n",
      "MuPDF error: syntax error: unknown keyword: '614.295pt'\n",
      "MuPDF error: syntax error: unknown keyword: 'height'\n",
      "MuPDF error: syntax error: unknown keyword: '794.96999pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00104v1.pdf\n",
      "# of sections: 6\n",
      "Total # of sections: 18 Total # of files: 3\n",
      "============================================================\n",
      "Processing PDF file: 1901.00105v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'Top-Assisted Di-Higgs boson Production Motivated by Baryogenesis', 1],\n",
       " [2, 'Abstract', 1],\n",
       " [2, 'I Introduction', 1],\n",
       " [2, 'II Formalism', 1],\n",
       " [2, 'III Collider signature', 2],\n",
       " [2, 'IV Discussion and summary', 5],\n",
       " [2, ' Acknowledgments', 6],\n",
       " [2, ' References', 6]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00105v2.pdf\n",
      "# of sections: 1\n",
      "Total # of sections: 19 Total # of files: 4\n",
      "============================================================\n",
      "Processing PDF file: 1901.00106v2.pdf\n",
      "Processing PDF file: 1901.00107v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Continuous-stage RKN method and its order theory', 3],\n",
       " [2, '2.1 Continuous-stage RKN method', 3],\n",
       " [2, '2.2 Order theory for RKN-type method', 4],\n",
       " [1, '3 Conditions for the symmetry of csRKN methods', 7],\n",
       " [1, '4 Symmetric RKN method', 9],\n",
       " [1, '5 Numerical experiments', 12],\n",
       " [1, '6 Concluding remarks', 13]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00107v2.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 26 Total # of files: 5\n",
      "============================================================\n",
      "Processing PDF file: 1901.00108v2.pdf\n",
      "Processing PDF file: 1901.00109v4.pdf\n",
      "Processing PDF file: 1901.00110v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Triadic time series motifs', 2],\n",
       " [1, '3 Triadic time series motif analysis of chaotic maps', 3],\n",
       " [2, '3.1 Chaotic maps', 3],\n",
       " [2, '3.2 Occurrence frequency distributions of triadic motifs', 3],\n",
       " [2, '3.3 Classification of time series', 5],\n",
       " [1,\n",
       "  '4 Triadic time series motif analysis of the UCR Time Series Classification Archive',\n",
       "  7],\n",
       " [1, '5 Conclusions', 8]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00110v1.pdf\n",
      "# of sections: 6\n",
      "Total # of sections: 32 Total # of files: 6\n",
      "============================================================\n",
      "Processing PDF file: 1901.00111v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Preliminaries', 3],\n",
       " [1, '3 Model formulation', 4],\n",
       " [1, '4 Stability analysis with respect to equilibria', 7],\n",
       " [2, '4.1 Local stability', 7],\n",
       " [2, '4.2 Global attractivity', 9],\n",
       " [1, '5 Numerical simulations', 12],\n",
       " [2, '5.1 Three typical network models', 12],\n",
       " [2, '5.2 Impact of system parameters', 14],\n",
       " [1, '6 Conclusions and discussions', 15]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00111v1.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 39 Total # of files: 7\n",
      "============================================================\n",
      "Processing PDF file: 1901.00112v1.pdf\n",
      "Processing PDF file: 1901.00113v1.pdf\n",
      "Processing PDF file: 1901.00114v2.pdf\n",
      "Processing PDF file: 1901.00115v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Morse index and bifurcation', 3],\n",
       " [2, '2.1 Morse index and eigenvalue problem', 3],\n",
       " [2, '2.2 Bifurcation and eigenvalue problem', 4],\n",
       " [2, '2.3 Morse index and bifurcation', 5],\n",
       " [1, '3 Morse index and bifurcation for homogeneous system', 6],\n",
       " [2, '3.1 Bifurcation at a=0.9966', 6],\n",
       " [2, '3.2 Bifurcation at a=1.3424', 9],\n",
       " [1, '4 Morse index and bifurcation for LJ system', 11],\n",
       " [2, '4.1 Bifurcation yielding Dx y, Dx and D2 solutions', 11],\n",
       " [2, '4.2 Choreographic bifurcation', 12],\n",
       " [1, '5 Summary and discussions', 15],\n",
       " [1, 'Appendix A Conditions for solutions', 17],\n",
       " [2, 'Appendix A.1 Dx y solution', 18],\n",
       " [2, 'Appendix A.2 Dx solution', 18],\n",
       " [2, 'Appendix A.3 Cx solution', 18],\n",
       " [2, 'Appendix A.4 D2 solution', 19],\n",
       " [2, 'Appendix A.5 C2 solution', 19],\n",
       " [2, 'Appendix A.6 Cy solution', 19]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00115v2.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 46 Total # of files: 8\n",
      "============================================================\n",
      "Processing PDF file: 1901.00116v1.pdf\n",
      "Processing PDF file: 1901.00117v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'Abstract', 1],\n",
       " [1, '1 Introduction', 1],\n",
       " [1, '2 Related Work', 1],\n",
       " [1, '3 Background', 2],\n",
       " [2, '3.1 RL on an Ensemble of Models', 2],\n",
       " [2, '3.2 Robust policy learning via CVaR optimization', 2],\n",
       " [2, '3.3 Linear Stochastic Bandits', 2],\n",
       " [1, '4 Active Learning for Efficient Trajectory Sampling', 2],\n",
       " [2, '4.1 Active Learning and the EffAcTS framework', 3],\n",
       " [2, '4.2 Applying EffAcTS', 3],\n",
       " [2, '4.3 Sample Efficiency', 4],\n",
       " [1, '5 Connections to Multi-Task Learning', 4],\n",
       " [1, '6 Experiments', 4],\n",
       " [2, '6.1 Implementation Details and Hyperparameters', 4],\n",
       " [2, '6.2 Bandit Algorithm', 6],\n",
       " [2, '6.3 (RQ1) Performance and Robustness', 6],\n",
       " [2, '6.4 (RQ1) Performance on a 2-D Model Ensemble', 6],\n",
       " [2, '6.5 Visualizing the Bandit Active Learner', 7],\n",
       " [2, '6.6 (RQ2) Analysis of the Bandit Active Learner', 7],\n",
       " [2, '6.7 (RQ3) Non-stationary Bandits for Data Reuse', 7],\n",
       " [2, '6.8 Other Remarks', 8],\n",
       " [1, '7 Conclusions and Further Possibilities', 8],\n",
       " [1, '8 Acknowledgments', 8],\n",
       " [1, 'References', 8]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00117v2.pdf\n",
      "# of sections: 11\n",
      "Total # of sections: 57 Total # of files: 9\n",
      "============================================================\n",
      "Processing PDF file: 1901.00118v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1. Introduction', 1],\n",
       " [1, '2. Énoncé précis du résultat', 2],\n",
       " [1, '3. Démonstrations du énoncé', 4],\n",
       " [1, 'Références', 7]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00118v2.pdf\n",
      "# of sections: 5\n",
      "Total # of sections: 62 Total # of files: 10\n",
      "============================================================\n",
      "Processing PDF file: 1901.00120v2.pdf\n",
      "Processing PDF file: 1901.00121v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction', 1],\n",
       " [2, 'I-A Applications of Deep Learning Networks', 2],\n",
       " [2, 'I-B Emergence of Deep Learning Networks', 2],\n",
       " [2, 'I-C Hardware Acceleration of Deep Learning Networks', 2],\n",
       " [1, 'II Background and Terminology', 3],\n",
       " [2, 'II-A Convolutional Neural Networks (CNNs)', 3],\n",
       " [3, 'II-A1 Convolution (CONV)', 3],\n",
       " [3, 'II-A2 Activation Functions (AFs)', 4],\n",
       " [3, 'II-A3 Normalization', 4],\n",
       " [3, 'II-A4 Pooling', 4],\n",
       " [3, 'II-A5 Fully Connected Layer (FC)', 5],\n",
       " [2, 'II-B Examples of Deep Learning Networks', 5],\n",
       " [2, 'II-C Field Programmable Gate Arrays (FPGAs)', 5],\n",
       " [2,\n",
       "  'II-D Challenges of FPGA-Based Implementation of Deep Learning Networks',\n",
       "  6],\n",
       " [1, 'III Acceleration of Deep Learning Networks: Current Status', 7],\n",
       " [2, 'III-A CNNs Compression', 7],\n",
       " [2, 'III-B ASIC-based Accelerators', 7],\n",
       " [2, 'III-C FPGA-based Accelerators', 9],\n",
       " [1, 'IV Metaheuristics in the Design of Convolutional Neural Networks', 28],\n",
       " [2, 'IV-A CNN Structure Optimization', 31],\n",
       " [2, 'IV-B CNN Weights and Bias Values Optimization', 31],\n",
       " [2, 'IV-C CNN Design Variables Optimization', 31],\n",
       " [1, 'V Summary and Recommendations', 32],\n",
       " [1, 'VI Conclusion', 33],\n",
       " [1, 'REFERENCES', 1],\n",
       " [2, 'Ahmad Shawahna', 41],\n",
       " [2, 'Sadiq M. Sait', 41],\n",
       " [2, 'Aiman El-Maleh', 41]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00121v1.pdf\n",
      "# of sections: 8\n",
      "Total # of sections: 70 Total # of files: 11\n",
      "============================================================\n",
      "Processing PDF file: 1901.00122v1.pdf\n",
      "Processing PDF file: 1901.00123v2.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1. Introduction', 1],\n",
       " [2, '1.1. Definitions and main result', 2],\n",
       " [2, '1.2. Discussion', 3],\n",
       " [2, '1.3. Acknowledgments', 4],\n",
       " [2, '1.4. Notation', 5],\n",
       " [1, '2. Outline of proof', 5],\n",
       " [1, '3. Preliminaries', 8],\n",
       " [2, '3.1. Entropy', 8],\n",
       " [2, '3.2. The mass-transport principle', 8],\n",
       " [2, '3.3. Simulating distributions from random bits', 9],\n",
       " [1, '4. The cell process', 9],\n",
       " [1, '5. Random total orders', 15],\n",
       " [1, '6. The finitary coding', 17],\n",
       " [2, '6.1. Choosing the parameters', 18],\n",
       " [2, '6.2. The construction of the finitary coding', 18],\n",
       " [2, '6.3. Concluding Theorem 1.2', 21],\n",
       " [2, '6.4. The output has the correct distribution', 22],\n",
       " [1, '7. Remarks and open problems', 25],\n",
       " [1, 'References', 27]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00123v2.pdf\n",
      "# of sections: 9\n",
      "Total # of sections: 79 Total # of files: 12\n",
      "============================================================\n",
      "Processing PDF file: 1901.00124v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Background', 3],\n",
       " [2, '2.1 Local Bifurcation Theory', 3],\n",
       " [2, '2.2 Piecewise Deterministic Markov Processes', 5],\n",
       " [1, '3 Two Nontrivial Trapping Regions', 8],\n",
       " [2, '3.1 Supercritical Pitchfork Bifurcation', 8],\n",
       " [2, '3.2 Supercritical Hopf Bifurcation', 10],\n",
       " [2, '3.3 Transcritical Bifurcation', 12],\n",
       " [1, '4 One Nontrivial Trapping Region', 16],\n",
       " [2, '4.1 Subcritical Pitchfork Bifurcation', 16],\n",
       " [2, '4.2 Subcritical Hopf Bifurcation', 17],\n",
       " [2, '4.3 Fold Bifurcation', 18],\n",
       " [1, '5 Applications', 19],\n",
       " [2, '5.1 The Paradox of Enrichment', 19],\n",
       " [2, '5.2 Relaxation Oscillations', 20],\n",
       " [2, '5.3 Adaptive Swarming', 20]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00124v1.pdf\n",
      "# of sections: 6\n",
      "Total # of sections: 85 Total # of files: 13\n",
      "============================================================\n",
      "Processing PDF file: 1901.00125v3.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, ' Acknowledgments', 4],\n",
       " [1, ' References', 4],\n",
       " [1, ' S1: Exact results on complete graphs', 6],\n",
       " [1, ' S2: The random-graph Potts model in the canonical ensemble', 7],\n",
       " [1,\n",
       "  ' S3: The entropy kink at umic and the microcanonical inverse temperature',\n",
       "  8],\n",
       " [1, ' S4: The Potts model on RR graphs of large degree K', 10],\n",
       " [1,\n",
       "  ' S5: The Potts model with large Q values on RR graphs of fixed degree K',\n",
       "  11],\n",
       " [1, ' S6: Potts model with kinetic energies', 12],\n",
       " [1,\n",
       "  ' S7: Bond-diluted lattice systems and short-range interaction range l',\n",
       "  13],\n",
       " [1, ' S8: Droplet nucleation and phase separation', 14]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00125v3.pdf\n",
      "# of sections: 11\n",
      "Total # of sections: 96 Total # of files: 14\n",
      "============================================================\n",
      "Processing PDF file: 1901.00126v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, ' References', 8]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00126v1.pdf\n",
      "# of sections: 1\n",
      "Total # of sections: 97 Total # of files: 15\n",
      "============================================================\n",
      "Processing PDF file: 1901.00127v1.pdf\n",
      "Processing PDF file: 1901.00128v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction', 1],\n",
       " [1, 'II Materials and Method', 2],\n",
       " [2, 'II-A Spiking Neuron', 2],\n",
       " [2, 'II-B Crossbar Array of Synapses', 2],\n",
       " [1, 'III MaD Framework', 3],\n",
       " [2, 'III-A Mapping Function', 3],\n",
       " [2, 'III-B Core Utilization', 3],\n",
       " [2, 'III-C MaD Framework Optimizations', 4],\n",
       " [3, 'III-C1 Core Utilization', 4],\n",
       " [3, 'III-C2 Padding', 5],\n",
       " [1, 'IV Results', 5],\n",
       " [2, 'IV-1 Keeping architecture constant', 5],\n",
       " [3, 'IV-2 Keeping architecture different', 6],\n",
       " [1, 'V Discussion and Conclusion', 6],\n",
       " [1, 'References', 7]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00128v1.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 104 Total # of files: 16\n",
      "============================================================\n",
      "Processing PDF file: 1901.00129v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'Introduction', 1],\n",
       " [1, '1. Background material', 3],\n",
       " [1, '2. Construction of the maximal surface', 10],\n",
       " [1, '3. Description of the boundary at infinity', 13],\n",
       " [1, '4. Parameterisation of wild anti-de Sitter structures', 23],\n",
       " [1, 'References', 26]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00129v1.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 111 Total # of files: 17\n",
      "============================================================\n",
      "Processing PDF file: 1901.00130v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction', 1],\n",
       " [1, 'II Advantages of Deep Nets in Realizing Feature', 2],\n",
       " [2, 'II-A Deep nets with fixed structures', 2],\n",
       " [2, 'II-B A fast review for realizing data features by deep nets', 3],\n",
       " [2, 'II-C Covering number estimates', 3],\n",
       " [1, 'III Necessity of the Depth', 4],\n",
       " [2, 'III-A Limitations of deep nets approximation', 4],\n",
       " [2, 'III-B Remarks and discussions', 5],\n",
       " [1, 'IV Conclusion', 5],\n",
       " [1, 'References', 11]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00130v1.pdf\n",
      "# of sections: 6\n",
      "Total # of sections: 117 Total # of files: 18\n",
      "============================================================\n",
      "Processing PDF file: 1901.00131v4.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, '1 Introduction', 1],\n",
       " [1, '2 Martingale approximations', 4],\n",
       " [1, '3 Main abstract theorem', 8],\n",
       " [2, '3.1 Verifying condition (b) in Theorem ??', 10],\n",
       " [2, '3.2 Verifying condition (a) in Theorem ??', 11],\n",
       " [1, '4 Application to Lorentz gases', 12],\n",
       " [2, '4.1 Setting and main result for Lorentz gases', 12],\n",
       " [2, '4.2 Proof of Theorem ??', 13]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00131v4.pdf\n",
      "# of sections: 5\n",
      "Total # of sections: 122 Total # of files: 19\n",
      "============================================================\n",
      "Processing PDF file: 1901.00132v1.pdf\n",
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction and related work', 1],\n",
       " [1, 'II A real-world dataset', 1],\n",
       " [1, 'III Forecasting technique', 2],\n",
       " [1, 'IV Numerical results', 2],\n",
       " [2, 'IV-A Performance metrics', 2],\n",
       " [2, 'IV-B Results', 3],\n",
       " [1, 'V Conclusion and Future Work', 4],\n",
       " [1, 'References', 4]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "Done with PDF file: 1901.00132v1.pdf\n",
      "# of sections: 7\n",
      "Total # of sections: 129 Total # of files: 20\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# number of PDFs used for training data preparation\n",
    "dataset_limit = 20\n",
    "\n",
    "file_count = 0\n",
    "all_json_dicts = []\n",
    "# Loop through files in the folder\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    file_path = os.path.join(dataset_path, file_name)\n",
    "    # Check if it's a file and if it has a \".pdf\" extension\n",
    "    if os.path.isfile(file_path) and file_name.endswith('.pdf'):\n",
    "        # Process the PDF file\n",
    "        print(\"Processing PDF file:\", file_name)\n",
    "        json_dict = process_one_pdf(file_path)\n",
    "        if len(json_dict) > 0:\n",
    "            all_json_dicts.extend(list(json_dict.values()))\n",
    "            file_count += 1\n",
    "            print(\"Done with PDF file:\", file_name)\n",
    "            print(\"# of sections:\", len(json_dict.values()))\n",
    "            print(\"Total # of sections:\", len(all_json_dicts), \"Total # of files:\", file_count)\n",
    "            print(60*\"=\")\n",
    "        \n",
    "        # Terminate when reaching dataset limit\n",
    "        if file_count >= dataset_limit:\n",
    "            break\n",
    "\n",
    "# get_summaries(all_json_dicts)\n",
    "json_list = json.dumps(all_json_dicts)\n",
    "full_name = \"dataset/dataset_eval.json\"\n",
    "with open(full_name, \"w\") as jsonfile: \n",
    "    jsonfile.write(json_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Generate GPT summary for each section and subsection as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_summary import get_summaries\n",
    "\n",
    "#file = f\"dataset/test.json\"\n",
    "file = f\"dataset/dataset_eval.json\"\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "get_summaries(data)\n",
    "\n",
    "with open(f\"dataset/dataset_eval_ground_truth.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
