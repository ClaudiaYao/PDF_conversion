{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d9fe0a4924e947c09580ddfce0f53212":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c02f1df6ad34914907de84b321b4514","IPY_MODEL_007c60cb4b2f4cdfb4cda4d1317dbf3b","IPY_MODEL_6151ec9a923a44dc8680b38dca57492a"],"layout":"IPY_MODEL_fe80af68759d4d6590a9cf263beeb7aa"}},"8c02f1df6ad34914907de84b321b4514":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b044c85b07140c1b80fb141829a9d85","placeholder":"​","style":"IPY_MODEL_fd46e8d185b341eeb02ffc88d14b77ce","value":"tokenizer_config.json: 100%"}},"007c60cb4b2f4cdfb4cda4d1317dbf3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98240788a3ed40139106d92fc2e9b53d","max":27,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b543f5502d674368b2ff434ce4c173b9","value":27}},"6151ec9a923a44dc8680b38dca57492a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47646c0ab7764573bc49512fef72dcd9","placeholder":"​","style":"IPY_MODEL_d660f30269ae4147a50d8aec7f3ba459","value":" 27.0/27.0 [00:00&lt;00:00, 1.23kB/s]"}},"fe80af68759d4d6590a9cf263beeb7aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b044c85b07140c1b80fb141829a9d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd46e8d185b341eeb02ffc88d14b77ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98240788a3ed40139106d92fc2e9b53d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b543f5502d674368b2ff434ce4c173b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47646c0ab7764573bc49512fef72dcd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d660f30269ae4147a50d8aec7f3ba459":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f55172426e446abad1a491618b5284f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6152d6a717e9447f96af770cb44964cb","IPY_MODEL_ee71ffd9aae846dab3485c6d2d35500a","IPY_MODEL_5c6341c71995468388c6e4ea871b75e1"],"layout":"IPY_MODEL_5c9f7dd70d5f4374bea857406daf82b2"}},"6152d6a717e9447f96af770cb44964cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2430627518a43f2a4985b505142db45","placeholder":"​","style":"IPY_MODEL_748627351ca54d848aa7d4395763419b","value":"vocab.json: 100%"}},"ee71ffd9aae846dab3485c6d2d35500a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fa0529e95b84719a42c8efa852b29ca","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2d8ef4f3f73480ebe3a2b00c09a6a83","value":898822}},"5c6341c71995468388c6e4ea871b75e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62f20fe316504eeba9ff3174be444b43","placeholder":"​","style":"IPY_MODEL_e9c08be5d25e483eb3599eb677d5a047","value":" 899k/899k [00:00&lt;00:00, 1.13MB/s]"}},"5c9f7dd70d5f4374bea857406daf82b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2430627518a43f2a4985b505142db45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748627351ca54d848aa7d4395763419b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fa0529e95b84719a42c8efa852b29ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2d8ef4f3f73480ebe3a2b00c09a6a83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62f20fe316504eeba9ff3174be444b43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9c08be5d25e483eb3599eb677d5a047":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef9ef15b1aa4e20a9efba59ffac731e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c25534ce191d40cf8c382b721122b378","IPY_MODEL_96732d28cf574473bc44892945267107","IPY_MODEL_2f4bdfd412524d0892c2f188309a5bea"],"layout":"IPY_MODEL_d1b5f1fcea3944a19aeba661b7ddd3b6"}},"c25534ce191d40cf8c382b721122b378":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf9e8c5cecbf40469d17e2bf74cd27cc","placeholder":"​","style":"IPY_MODEL_8dc29f0088e04b65a86b7a3cae8c0b3c","value":"merges.txt: 100%"}},"96732d28cf574473bc44892945267107":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c496f6874f784ff0a939e47d78988150","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec75bb595c074123baed91eac9509736","value":456318}},"2f4bdfd412524d0892c2f188309a5bea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a51b163a87b641e48a42c46e212fa9bf","placeholder":"​","style":"IPY_MODEL_9136a783219e4a6e84e3b0d28c7af19e","value":" 456k/456k [00:00&lt;00:00, 767kB/s]"}},"d1b5f1fcea3944a19aeba661b7ddd3b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9e8c5cecbf40469d17e2bf74cd27cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dc29f0088e04b65a86b7a3cae8c0b3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c496f6874f784ff0a939e47d78988150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec75bb595c074123baed91eac9509736":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a51b163a87b641e48a42c46e212fa9bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9136a783219e4a6e84e3b0d28c7af19e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4e43d6662284f53a4729e9a1c20e3b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d259586d0364364af95b1a0b07158b0","IPY_MODEL_8e97db001fbd4aa4bf7323caed5a5ec2","IPY_MODEL_855192a706714ab4af6a1369eca45cd3"],"layout":"IPY_MODEL_9734912fbae544598b6ba9786b058872"}},"9d259586d0364364af95b1a0b07158b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7df964b037cc4ff8a930f57d4196957c","placeholder":"​","style":"IPY_MODEL_bd81d231919d4a9cb9e6ec4f68ae9e2a","value":"special_tokens_map.json: 100%"}},"8e97db001fbd4aa4bf7323caed5a5ec2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c953668c1b16423788906d30c8469eed","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e33df0531404cd4a59935ec2ee955e7","value":772}},"855192a706714ab4af6a1369eca45cd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_997e95da55d540459750a30662c37012","placeholder":"​","style":"IPY_MODEL_e124f9a36da14f9e8aea3c7931ce214d","value":" 772/772 [00:00&lt;00:00, 29.7kB/s]"}},"9734912fbae544598b6ba9786b058872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7df964b037cc4ff8a930f57d4196957c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd81d231919d4a9cb9e6ec4f68ae9e2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c953668c1b16423788906d30c8469eed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e33df0531404cd4a59935ec2ee955e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"997e95da55d540459750a30662c37012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e124f9a36da14f9e8aea3c7931ce214d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1187e4716e7b4c95a97dec67fed78e7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e267548c1e64085b2eecd85327ee684","IPY_MODEL_a2960b8480f34ecc91462113a8f97b32","IPY_MODEL_4c8b3fb837304ca6836f98ffcd7b25a3"],"layout":"IPY_MODEL_8f0d7ea9390c4f20a2c9cb8e69016cb1"}},"0e267548c1e64085b2eecd85327ee684":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e35d6f3de9948ef9f0679c02a21055d","placeholder":"​","style":"IPY_MODEL_3a8ad71842474626be25a9b1c02ab80b","value":"config.json: 100%"}},"a2960b8480f34ecc91462113a8f97b32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4491507e432d45e89fe90fb264813961","max":1291,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5966cda34d794a3c8e1f4a43a5f958c5","value":1291}},"4c8b3fb837304ca6836f98ffcd7b25a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_857f22cfa39c47bb8c63a81d62acf69a","placeholder":"​","style":"IPY_MODEL_42561051be6c462fb608b917903e1abc","value":" 1.29k/1.29k [00:00&lt;00:00, 97.0kB/s]"}},"8f0d7ea9390c4f20a2c9cb8e69016cb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e35d6f3de9948ef9f0679c02a21055d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a8ad71842474626be25a9b1c02ab80b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4491507e432d45e89fe90fb264813961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5966cda34d794a3c8e1f4a43a5f958c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"857f22cfa39c47bb8c63a81d62acf69a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42561051be6c462fb608b917903e1abc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd2e4f769fb540c9b68b5a60c1d72f00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48fd268ae3c840e884fde46b785c8dd4","IPY_MODEL_49c6c514ea0a4255827d65fc21487083","IPY_MODEL_fb83b356c4134f748539bf3d9c0136c8"],"layout":"IPY_MODEL_003a24eaa5ba443692ac32317e852904"}},"48fd268ae3c840e884fde46b785c8dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75a1965895e447f7878fe4b7cb50e56d","placeholder":"​","style":"IPY_MODEL_a9545e4e10064edfb286f18709e54026","value":"pytorch_model.bin: 100%"}},"49c6c514ea0a4255827d65fc21487083":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58a29cf55c8a4fc482d01fa25e79bbcb","max":1839633783,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf15a2add05e4837bbd7e5bad31bbe87","value":1839633783}},"fb83b356c4134f748539bf3d9c0136c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49c79260daa947648271f210d70e2514","placeholder":"​","style":"IPY_MODEL_854063b0b8a3469eaf190bb4fd3d5329","value":" 1.84G/1.84G [01:35&lt;00:00, 20.3MB/s]"}},"003a24eaa5ba443692ac32317e852904":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a1965895e447f7878fe4b7cb50e56d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9545e4e10064edfb286f18709e54026":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a29cf55c8a4fc482d01fa25e79bbcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf15a2add05e4837bbd7e5bad31bbe87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49c79260daa947648271f210d70e2514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"854063b0b8a3469eaf190bb4fd3d5329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc829b4780740bb929e5b4045ec99e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_889c735405f3402bae2da31db8fb6ad9","IPY_MODEL_a8b18d055a0d4c0098fe9542498ea6e2","IPY_MODEL_a800a91a78184e2a9d7f9b7a396dd28f"],"layout":"IPY_MODEL_ac52cd28ed5e4e109264aa874c5e4930"}},"889c735405f3402bae2da31db8fb6ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_969f8e385e1240c6a929cb44e4389ead","placeholder":"​","style":"IPY_MODEL_d0e7a2e1379d491f85eec54a5692cd74","value":"generation_config.json: 100%"}},"a8b18d055a0d4c0098fe9542498ea6e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_069e8a62b02b484283c226153b7ff1c1","max":207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c93bb203319c4ae6983718a195074fac","value":207}},"a800a91a78184e2a9d7f9b7a396dd28f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58ae5bb3fcbf4d9ea1656bede56a0087","placeholder":"​","style":"IPY_MODEL_01d6793fe7aa48adb91527bb4bd641eb","value":" 207/207 [00:00&lt;00:00, 14.4kB/s]"}},"ac52cd28ed5e4e109264aa874c5e4930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"969f8e385e1240c6a929cb44e4389ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e7a2e1379d491f85eec54a5692cd74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"069e8a62b02b484283c226153b7ff1c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93bb203319c4ae6983718a195074fac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58ae5bb3fcbf4d9ea1656bede56a0087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01d6793fe7aa48adb91527bb4bd641eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["\\# This notebook has steps for model initialisation and Training**\n","\n"],"metadata":{"id":"DMsrySAKzEq6"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install tokenizer\n","!pip install datasets\n","!pip install rouge_score\n","!pip install sentencepiece\n","!pip install rouge"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjYjTBehuyBg","executionInfo":{"status":"ok","timestamp":1712465957939,"user_tz":-480,"elapsed":47047,"user":{"displayName":"Sudha Ravi","userId":"04078799224499823775"}},"outputId":"60698c5d-b359-467a-9c4a-3c56ed6e0929"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting tokenizer\n","  Downloading tokenizer-3.4.3-py2.py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizer\n","Successfully installed tokenizer-3.4.3\n","Collecting datasets\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=f5ae896182deba952e311b6734d04af563a95213ab776c2644e1351810297aee\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","import textwrap\n","import json\n","import os\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","transformers.logging.set_verbosity_error()\n","from transformers import LEDForConditionalGeneration, LEDTokenizer\n","from datasets import load_dataset, load_metric\n","import torch\n","from rouge import Rouge\n","# Device configuration\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOMAm4fQ3pRj","executionInfo":{"status":"ok","timestamp":1712466023050,"user_tz":-480,"elapsed":36391,"user":{"displayName":"Sudha Ravi","userId":"04078799224499823775"}},"outputId":"057bb416-f9d3-434c-b1c2-768b17c4ebb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**This section contains the code for loading the dataset and model initialization**"],"metadata":{"id":"UM30ip_zePoT"}},{"cell_type":"code","source":["#Load the datasets\n","dataset_path = \"/content/drive/My Drive/Colab Notebooks/CS5242 Project/data/\"\n","\n","def load_data(file_path):\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","# Join the paths\n","train_file_path = os.path.join(dataset_path, 'train_data.json')\n","test_file_path =  os.path.join(dataset_path, 'test_data.json')\n","\n","# Load training data\n","train_data = load_data(train_file_path)\n","\n","# Load testing data\n","test_data = load_data(test_file_path)\n","\n","\n","#Define the Model\n","class SummarizationModel:\n","    def __init__(self, model_name, device):\n","        self.model_name = model_name\n","        self.tokenizer = LEDTokenizer.from_pretrained(model_name)\n","        self.model = LEDForConditionalGeneration.from_pretrained(model_name).to(device)\n","        self.config=LEDForConditionalGeneration.from_pretrained(model_name).config\n","\n","#Instantiate the model\n","model_name = \"allenai/led-large-16384-arxiv\"\n","model_summarizer = SummarizationModel(model_name, device=DEVICE)\n","model = model_summarizer.model\n","tokenizer=model_summarizer.tokenizer\n","# Define optimizer and criterion\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","criterion = torch.nn.CrossEntropyLoss()\n","#print(modelsummarizer.config)\n","\n","#"],"metadata":{"id":"aSo5fz1lnMtO","executionInfo":{"status":"ok","timestamp":1712466154069,"user_tz":-480,"elapsed":114781,"user":{"displayName":"Sudha Ravi","userId":"04078799224499823775"}},"colab":{"base_uri":"https://localhost:8080/","height":365,"referenced_widgets":["d9fe0a4924e947c09580ddfce0f53212","8c02f1df6ad34914907de84b321b4514","007c60cb4b2f4cdfb4cda4d1317dbf3b","6151ec9a923a44dc8680b38dca57492a","fe80af68759d4d6590a9cf263beeb7aa","8b044c85b07140c1b80fb141829a9d85","fd46e8d185b341eeb02ffc88d14b77ce","98240788a3ed40139106d92fc2e9b53d","b543f5502d674368b2ff434ce4c173b9","47646c0ab7764573bc49512fef72dcd9","d660f30269ae4147a50d8aec7f3ba459","4f55172426e446abad1a491618b5284f","6152d6a717e9447f96af770cb44964cb","ee71ffd9aae846dab3485c6d2d35500a","5c6341c71995468388c6e4ea871b75e1","5c9f7dd70d5f4374bea857406daf82b2","d2430627518a43f2a4985b505142db45","748627351ca54d848aa7d4395763419b","2fa0529e95b84719a42c8efa852b29ca","a2d8ef4f3f73480ebe3a2b00c09a6a83","62f20fe316504eeba9ff3174be444b43","e9c08be5d25e483eb3599eb677d5a047","1ef9ef15b1aa4e20a9efba59ffac731e","c25534ce191d40cf8c382b721122b378","96732d28cf574473bc44892945267107","2f4bdfd412524d0892c2f188309a5bea","d1b5f1fcea3944a19aeba661b7ddd3b6","bf9e8c5cecbf40469d17e2bf74cd27cc","8dc29f0088e04b65a86b7a3cae8c0b3c","c496f6874f784ff0a939e47d78988150","ec75bb595c074123baed91eac9509736","a51b163a87b641e48a42c46e212fa9bf","9136a783219e4a6e84e3b0d28c7af19e","e4e43d6662284f53a4729e9a1c20e3b6","9d259586d0364364af95b1a0b07158b0","8e97db001fbd4aa4bf7323caed5a5ec2","855192a706714ab4af6a1369eca45cd3","9734912fbae544598b6ba9786b058872","7df964b037cc4ff8a930f57d4196957c","bd81d231919d4a9cb9e6ec4f68ae9e2a","c953668c1b16423788906d30c8469eed","1e33df0531404cd4a59935ec2ee955e7","997e95da55d540459750a30662c37012","e124f9a36da14f9e8aea3c7931ce214d","1187e4716e7b4c95a97dec67fed78e7f","0e267548c1e64085b2eecd85327ee684","a2960b8480f34ecc91462113a8f97b32","4c8b3fb837304ca6836f98ffcd7b25a3","8f0d7ea9390c4f20a2c9cb8e69016cb1","3e35d6f3de9948ef9f0679c02a21055d","3a8ad71842474626be25a9b1c02ab80b","4491507e432d45e89fe90fb264813961","5966cda34d794a3c8e1f4a43a5f958c5","857f22cfa39c47bb8c63a81d62acf69a","42561051be6c462fb608b917903e1abc","fd2e4f769fb540c9b68b5a60c1d72f00","48fd268ae3c840e884fde46b785c8dd4","49c6c514ea0a4255827d65fc21487083","fb83b356c4134f748539bf3d9c0136c8","003a24eaa5ba443692ac32317e852904","75a1965895e447f7878fe4b7cb50e56d","a9545e4e10064edfb286f18709e54026","58a29cf55c8a4fc482d01fa25e79bbcb","bf15a2add05e4837bbd7e5bad31bbe87","49c79260daa947648271f210d70e2514","854063b0b8a3469eaf190bb4fd3d5329","ecc829b4780740bb929e5b4045ec99e8","889c735405f3402bae2da31db8fb6ad9","a8b18d055a0d4c0098fe9542498ea6e2","a800a91a78184e2a9d7f9b7a396dd28f","ac52cd28ed5e4e109264aa874c5e4930","969f8e385e1240c6a929cb44e4389ead","d0e7a2e1379d491f85eec54a5692cd74","069e8a62b02b484283c226153b7ff1c1","c93bb203319c4ae6983718a195074fac","58ae5bb3fcbf4d9ea1656bede56a0087","01d6793fe7aa48adb91527bb4bd641eb"]},"outputId":"a53aa359-f68b-4cec-f9bc-498b5b012647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9fe0a4924e947c09580ddfce0f53212"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f55172426e446abad1a491618b5284f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ef9ef15b1aa4e20a9efba59ffac731e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e43d6662284f53a4729e9a1c20e3b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1187e4716e7b4c95a97dec67fed78e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2e4f769fb540c9b68b5a60c1d72f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/207 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc829b4780740bb929e5b4045ec99e8"}},"metadata":{}}]},{"cell_type":"markdown","source":["**Tokenize the sections before training the model**"],"metadata":{"id":"Gty844TasC8e"}},{"cell_type":"code","source":["def process_section(section,results):\n","\n","    # List to include all the sections, content and subsections and Subsection content\n","    summary_results = {}\n","    section_name = section.get(\"Section\", \"\")\n","    content = section.get(\"Text\", \"\")\n","    subsections = section.get(\"Subsections\", [])\n","    ground_truth = section.get(\"Groundtruth\", \"\")\n","\n","    if not content and not ground_truth:\n","      return\n","\n","    inputs = tokenizer(content, return_tensors=\"pt\", max_length=1024, truncation=True)\n","    labels = tokenizer(ground_truth, return_tensors=\"pt\", max_length=300, truncation=True)[\"input_ids\"]\n","\n","    # Append tokenized content and ground truth to the results\n","    results.append({\"section_name\": section_name, \"inputs\": inputs, \"labels\": labels})\n","\n","    # Process the subsections if they exist\n","    if \"Subsections\" in section:\n","        for subsection in section[\"Subsections\"]:\n","            process_section(subsection, results)\n","    return results\n"],"metadata":{"id":"ztfI8_A2LLQQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training**"],"metadata":{"id":"Hzh56qGysM2B"}},{"cell_type":"code","source":["# Model Training\n","def train_model(model, train_loader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0.0\n","\n","\n","    #print(train_loader)\n","    for data in train_loader:\n","      results = []\n","      process_section(data, results)\n","      for result in results:\n","        inputs = result[\"inputs\"]\n","        labels = result[\"labels\"]\n","        # Forward pass\n","        predictions = model(input_ids=inputs.input_ids.to(device), labels=labels.to(device))\n","        # Zero gradients\n","        optimizer.zero_grad()\n","\n","        # Compute loss\n","        loss = predictions.loss\n","\n","        # Backward pass\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    return total_loss / len(train_loader)\n","\n","#Train the model\n","train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    train_loss = train_model(model, train_loader, optimizer, criterion, DEVICE)\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}')\n","\n","# Evaluation loop\n","\n","\n"],"metadata":{"id":"i9dGOcnrj_Jm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e41a366a-460f-498c-cec8-65a32731d870"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Input ids are automatically padded from 2 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 32 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 40 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 350 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 17 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 881 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 160 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 25 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 197 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 252 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 712 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 216 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 12 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 282 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 319 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 299 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 535 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 371 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 386 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 349 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 270 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 177 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 457 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 473 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 3 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 259 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 724 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 594 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 139 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 752 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 41 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 254 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 705 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 63 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 419 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 405 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 411 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 817 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 50 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 787 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 812 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 112 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 667 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 262 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 901 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 323 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 357 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 26 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 564 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 585 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 11 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 341 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 551 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 13 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 206 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 33 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 99 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 60 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 78 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 753 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 241 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 6 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 260 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 265 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 499 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 103 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 191 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 34 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 309 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 465 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 363 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 822 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 600 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 116 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 100 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 235 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 844 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 304 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 274 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 568 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 966 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 279 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 326 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 964 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 62 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 320 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 558 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 48 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 37 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 757 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 159 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 427 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 938 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 737 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 338 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 663 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 654 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 766 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 434 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 676 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 470 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 444 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 49 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 424 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 383 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 345 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 873 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 377 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 381 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 981 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 135 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 331 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 460 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 240 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 472 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 918 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 342 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 156 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 504 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 402 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 353 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 379 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 261 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 225 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 811 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 217 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 394 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 321 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 207 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 567 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 227 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 298 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 426 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 388 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 244 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 5 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 43 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 679 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 220 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 133 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 228 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 390 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 283 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 131 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 605 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 840 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 370 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 759 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 134 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 429 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 232 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 658 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 79 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 950 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 716 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 169 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 148 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 907 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 215 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 105 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 310 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 368 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 147 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 367 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 44 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 908 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 480 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 337 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 479 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 144 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 296 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 798 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 853 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 69 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 109 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 182 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 301 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 194 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 1002 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 894 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 800 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 528 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 407 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 553 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 926 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 396 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 720 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 699 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 303 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 515 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 171 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 570 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 833 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 762 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 376 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 291 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 453 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 398 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 403 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 179 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 66 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 96 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 355 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 325 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 246 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 364 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 893 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 498 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 509 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 662 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 1018 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 186 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 946 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 9 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 354 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 385 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 603 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 503 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 923 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 52 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 201 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 916 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 495 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 836 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 36 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 27 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 238 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 302 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 1012 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 483 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 307 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 565 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 208 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 92 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 339 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 46 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 57 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 734 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 306 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 361 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 286 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 728 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 98 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 491 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 410 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 598 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 90 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 263 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 120 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 266 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 129 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 268 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 214 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 449 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 340 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 168 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 21 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 526 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 735 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 247 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 336 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 73 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 1000 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 83 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 185 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 316 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 124 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 76 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 119 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 387 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 866 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 313 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 593 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 108 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 229 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 765 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 627 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 651 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 58 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 281 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 652 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 10 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 195 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 8 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 488 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 29 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 24 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 693 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 477 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 290 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 343 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 451 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 93 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 640 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 779 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 607 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 348 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 421 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 391 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 767 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 806 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 971 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 702 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 771 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 648 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 71 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 174 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 312 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 680 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 267 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 202 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 436 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 269 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 280 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 213 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 761 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 251 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 475 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 896 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 305 to 1024 to be a multiple of `config.attention_window`: 1024\n","Input ids are automatically padded from 4 to 1024 to be a multiple of `config.attention_window`: 1024\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 2.5874\n","Epoch 2/10, Train Loss: 1.8459\n","Epoch 3/10, Train Loss: 1.4828\n","Epoch 4/10, Train Loss: 1.1986\n","Epoch 5/10, Train Loss: 0.9783\n","Epoch 6/10, Train Loss: 0.7722\n","Epoch 7/10, Train Loss: 0.6453\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"c2Pwy1T8rH6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b_jZLpmLWuQ2"},"execution_count":null,"outputs":[]}]}