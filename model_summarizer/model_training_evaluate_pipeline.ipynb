{"cells":[{"cell_type":"markdown","metadata":{"id":"WgMFPhHk_zbr"},"source":["# 1. Preparation\n","a. Install or import relevant libraries <br>\n","b. Runtime -> change runtime type -> choose any GPU type available for you <br>\n","c. Set variable `RUN_LOCALLY`: <br>\n","    - set it to True: you will run this notebook locally. <br>\n","    - set it to False: you will run this notebook on Colab. <br>\n","\n","d. If you are running the notebook in Colab, you need to: <br>\n","    - specify the project path by setting the value of `project_path` in the following cell.<br>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnOGyYcaJIMm","outputId":"f03f4c3a-df06-4241-8324-f5bac071dcd1","executionInfo":{"status":"ok","timestamp":1714447664959,"user_tz":-480,"elapsed":24876,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=cc350505d01da416b7c94096f818e6aa7febfbd1e8e3406e833f0e4b1c90cc9a\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.22.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n"]}],"source":["\n","!pip install transformers\n","!pip install datasets\n","!pip install rouge_score\n","!pip install huggingface-hub"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Su__gj9U26xb","outputId":"9c82e967-f304-458e-ad71-7d2fa3259869","executionInfo":{"status":"ok","timestamp":1714447665802,"user_tz":-480,"elapsed":854,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 30 03:27:43 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   30C    P8              11W /  72W |      1MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"tgElBEsLtMUr"},"source":["### Set variable `RUN_LOCALLY`: ###\n","    - set it to True: you will run this notebook locally. <br>\n","    - set it to False: you will run this notebook on Colab. <br>\n","\n","\n","### When RUN_LOCALLY is True and run on local machine ###\n","Requirement: <br>\n","1. There are two files training.csv and eval.csv existing in folder `<project_folder>/data/dataset`.\n","2. There are processed PDF file in folder `<project_folder>/processed/`, such as `1901.00936v3.csv`.\n","\n","### When RUN_LOCALLY is False and run in Colab ###\n","Requirement: <br>\n","2. Specify the project path by setting the value of `project_path` in the below cell. <br>\n","1. training.csv, val.csv, and a pre-processed PDF file (e.g.`1901.00936v3.csv`) are put in the folder `data`. The folder `data` is located in the same Google Drive path as this notebook."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbxlvBEhC-kO","outputId":"01fa0f32-3ea6-4096-82df-e55b28e952e7","executionInfo":{"status":"ok","timestamp":1714447750112,"user_tz":-480,"elapsed":84315,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["RUN_LOCALLY = False\n","\n","import os, json, logging\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import re\n","from torch.optim import lr_scheduler\n","\n","transformers_logger = logging.getLogger(\"transformers\")\n","logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n","from transformers import LEDForConditionalGeneration, LEDTokenizer\n","from datasets import Dataset, load_dataset, load_metric, load_from_disk, DatasetDict\n","from rouge_score import rouge_scorer\n","pd.options.display.max_colwidth = 1000\n","torch.device('cpu')\n","\n","######### set RUN_LOCALLY to True/False. Set project_path if the notebook is running in Colab ########\n","if RUN_LOCALLY:\n","    project_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n","    # recently, the repo structure changes, and we need to follow this structure\n","    project_dataset_path = project_path + \"/data/dataset\"\n","    project_processed_data_path = project_path + \"/processed\"\n","    if not os.path.exists(project_dataset_path):\n","        raise Exception(\"The `dataset` folder does not exist.\")\n","    if not os.path.exists(project_processed_data_path):\n","        raise Exception(\"The `processed` folder does not exist.\")\n","\n","else:\n","    # If you want to run on Colab and use GPU, only two extra data files are needed. You do not need to follow the above local data structure. Just ensure folder \"data\" exists in the same Google Drive folder as this notebook\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    project_path = \"/content/drive/MyDrive/Colab Notebooks/Course-NUS-cs5242-Neural Network and Deep Learning/final_project\"\n","\n","    project_dataset_path = project_path + \"/data\"\n","    project_processed_data_path = project_path + \"/data\"\n","    if not os.path.exists(project_dataset_path):\n","        raise Exception(\"The `data` folder does not exist.\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Vb3sduyTBAfr"},"source":["# 2. Define functions\n","This class `Model_operation` wraps all the functions related to the model's operation. At the end of the cell, we create an object of this class. This object will be used in the following trainning and testing steps."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3fa5e4e27c5e471ea49a5b8bba497600","e97ae00353b44d5cb2dc6f9ef93c780d","8ff265954bd1409690220199ffe921ca","fad0f41386434da7a3d3dcc71d9321d6","a3c193e904c841588668330205a92004","43dae62e7a324ea1af112da2910c4454","10c0ff64a14a49c7911848449853796a","762e08c1376040fbad8c9aa94eaa94e2","2a7fedebd23f4939a0192b00ea7caf5f","1b3a30409cd94a6386d96f777834d2cd","2a129e970cf346d585323ada85c602ab","972b7b89c75d4f7fa93339b217c6672c","99c6e25c75a94a36a90b983a6f103a6f","5e1e30da780f4046a1df83fd9786898a","0ccaa0fa1a4c4fe78ec8547b7e8c3c42","2e3c73f6fa944e00b66aa99124c0f2a8","93df08ee30274d90a36aed4b332dca7d","a73a522389394d2f9932293e15e64150","fb32b690d0e24fe586fdfc1b5b06b3ba","cf022384b4594a19b91d8bc716c31eab","8bf53e8a16d048d0a46a47286008d3c7","4aabf63941f54c02b2477b2cc080933c","da0f8ff6e7ea4c69a7874caa1beb9158","a074d147a3c14d0280903f0e421b0ce3","56209b6224c642a0b49c2032abec7f81","5804012072e44502b69f69a0b307352a","8211a0a1c191426ba48f3bf254879126","e0038fe4dbda4e2a87df49889ded43f1","641651b5c69a4459bfe7989c39db58f9","e222064b9b284dbfbbaeefd6ed239845","8768666c82c147719c4a7653da7f8315","052afc11eb5045f28f9a839f14c9bfbc","18d71c66da5843a9b58fa4d09536b0b0","c675b8b4d06e4843ae57fd54c2bd3159","604dd127f6df40eea8f0d6ea533a9382","e83867c6397a4f6ca362e22d2e4d9476","cd0c690e635e4a15b9120ccfecaf2333","8dd5fbd1a00441649c98e002356e8a92","2eb23d9ddbed4f6686e83252e7bc02bb","d6bb1471c7d64e8e8406be853ed5ccec","8b659bf3e976418b915eb35d11a4cfa3","28c2489a280342479231287159274e84","d6b945ee3cd44d7e83eca46d90f080dc","6ce96d9e577d4a1eba85de412e8a804c","a6aa5f11f8af49399a9e10174f0823be","6801026b5a414333b0a104234cc791ab","93a9402327e342cabd96e4896744e3ea","7badc401923640f99ed3d5f83813aafa","fcca7437809c4a9cb5dfee768decf05d","de1895013e2c42489b90636af331f3e6","8acdeabf82d64b71bebc56c9917088f6","e29b1110364540d6bdb080ff6c24004e","881ca39313c94a1a84c85c7bb6f75731","dacdf6436a01453bba4ce96c59e7b928","5da43f0c67734e6b9027256ab2f2e384","86db3eb2cd0c4072af8808a18aa32070","3ea405461bfb4f4c926a4ceb209841dd","d6b48a22023b4a40bd98f17ad2e59a20","8d75a086a1f649fba8e2d25533b5efc6","954e352842a548a188fb8ace537046e1","0ad03682372847ea81939a6d46b667fd","75439258717c45fb938ae72ce890a228","a2348bd4ef6b44008f17989a23a4fd4b","1b2cb1165a86411bbd2cdbe8101cf0fb","393cc3672e024b1085e1b2fd06ecdd79","343c0d3cc0024840bcede5e65812420b","8a861d41f3d44786b2c6396a251e4e39","6adb11b0e0b14db1a0b167d3aa43d50b","3ea2b12ce4d24c258f3fb8b2af9f55c1","259f6c0004f247eabfbf6b4a1c92d408","6df2d5f41d5d4f1a854323d5c4f560b6","4cf1e0b3c83d47bd953cb1476dd3eb3d","ad1663f408a9480dba0d7ea52319cf86","782e7b80b3074b1f949b66d4e79e2140","615b99bd73624120ba6456316204fa1e","637d732d085b42bfb7c9c8cf4c9c8144","c9fcddc37ded43eebfbdcad48400ef98","b577ef44afff4eb1954ccf0e2b59f2a8","d9f91067653749f8a96b93ab1b9515cb","daaa419f80544e1da142b432d09f657a","b34173b7eb8b4f6b9f16ff26a31716d2","0aaa3f93f57440ab87d200e9b2179836","7313d54d931a411da82707d97fc53ab5","347e4c24766b453c8a71fa9043a12be6","51c500b5b6d845aea5dd7592002bade2","4b413d776cfa4c008a0eb3a3dbab126e","65050e92d76e44f794624fd61bfb2774","30a6d7f0f2e84b0da63c3441125c9fee"]},"id":"T0NcbDWxJIMp","outputId":"d4473f1a-8aee-494a-9484-39f04e983b3f","executionInfo":{"status":"ok","timestamp":1714447797795,"user_tz":-480,"elapsed":47687,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa5e4e27c5e471ea49a5b8bba497600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972b7b89c75d4f7fa93339b217c6672c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da0f8ff6e7ea4c69a7874caa1beb9158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c675b8b4d06e4843ae57fd54c2bd3159"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6aa5f11f8af49399a9e10174f0823be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86db3eb2cd0c4072af8808a18aa32070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/207 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a861d41f3d44786b2c6396a251e4e39"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","<ipython-input-4-27fbd476b5e1>:13: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  self.rouge = load_metric(\"rouge\")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b577ef44afff4eb1954ccf0e2b59f2a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Pre-trained Model Config:\n"," LEDConfig {\n","  \"_name_or_path\": \"allenai/led-large-16384-arxiv\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"architectures\": [\n","    \"LEDForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_window\": [\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024,\n","    1024\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_decoder_position_embeddings\": 1024,\n","  \"max_encoder_position_embeddings\": 16384,\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"led\",\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": false,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"transformers_version\": \"4.40.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","Pre-trained Model state-dict:\n","\n","final_logits_bias  -  torch.Size([1, 50265])\n","led.shared.weight  -  torch.Size([50265, 1024])\n","led.encoder.embed_tokens.weight  -  torch.Size([50265, 1024])\n","led.encoder.embed_positions.weight  -  torch.Size([16384, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.0.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.0.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.0.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.0.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.0.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.0.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.0.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.0.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.1.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.1.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.1.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.1.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.1.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.1.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.1.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.1.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.2.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.2.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.2.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.2.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.2.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.2.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.2.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.2.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.3.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.3.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.3.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.3.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.3.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.3.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.3.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.3.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.4.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.4.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.4.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.4.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.4.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.4.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.4.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.4.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.5.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.5.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.5.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.5.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.5.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.5.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.5.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.5.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.6.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.6.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.6.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.6.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.6.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.6.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.6.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.6.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.7.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.7.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.7.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.7.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.7.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.7.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.7.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.7.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.8.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.8.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.8.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.8.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.8.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.8.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.8.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.8.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.9.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.9.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.9.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.9.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.9.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.9.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.9.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.9.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.10.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.10.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.10.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.10.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.10.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.10.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.10.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.10.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.query.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.query.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.key.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.key.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.value.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.value.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.query_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.query_global.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.key_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.key_global.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.value_global.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.longformer_self_attn.value_global.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn.output.weight  -  torch.Size([1024, 1024])\n","led.encoder.layers.11.self_attn.output.bias  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.11.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layers.11.fc1.weight  -  torch.Size([4096, 1024])\n","led.encoder.layers.11.fc1.bias  -  torch.Size([4096])\n","led.encoder.layers.11.fc2.weight  -  torch.Size([1024, 4096])\n","led.encoder.layers.11.fc2.bias  -  torch.Size([1024])\n","led.encoder.layers.11.final_layer_norm.weight  -  torch.Size([1024])\n","led.encoder.layers.11.final_layer_norm.bias  -  torch.Size([1024])\n","led.encoder.layernorm_embedding.weight  -  torch.Size([1024])\n","led.encoder.layernorm_embedding.bias  -  torch.Size([1024])\n","led.decoder.embed_tokens.weight  -  torch.Size([50265, 1024])\n","led.decoder.embed_positions.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.0.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.0.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.0.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.0.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.0.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.0.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.0.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.0.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.0.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.1.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.1.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.1.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.1.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.1.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.1.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.1.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.1.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.1.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.2.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.2.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.2.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.2.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.2.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.2.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.2.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.2.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.2.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.3.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.3.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.3.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.3.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.3.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.3.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.3.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.3.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.3.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.4.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.4.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.4.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.4.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.4.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.4.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.4.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.4.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.4.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.5.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.5.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.5.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.5.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.5.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.5.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.5.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.5.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.5.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.6.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.6.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.6.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.6.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.6.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.6.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.6.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.6.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.6.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.7.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.7.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.7.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.7.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.7.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.7.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.7.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.7.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.7.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.8.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.8.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.8.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.8.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.8.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.8.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.8.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.8.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.8.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.9.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.9.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.9.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.9.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.9.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.9.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.9.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.9.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.9.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.10.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.10.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.10.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.10.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.10.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.10.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.10.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.10.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.10.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.self_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.self_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.self_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.self_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.11.self_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn.k_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.encoder_attn.k_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn.v_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.encoder_attn.v_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn.q_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.encoder_attn.q_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn.out_proj.weight  -  torch.Size([1024, 1024])\n","led.decoder.layers.11.encoder_attn.out_proj.bias  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.11.encoder_attn_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layers.11.fc1.weight  -  torch.Size([4096, 1024])\n","led.decoder.layers.11.fc1.bias  -  torch.Size([4096])\n","led.decoder.layers.11.fc2.weight  -  torch.Size([1024, 4096])\n","led.decoder.layers.11.fc2.bias  -  torch.Size([1024])\n","led.decoder.layers.11.final_layer_norm.weight  -  torch.Size([1024])\n","led.decoder.layers.11.final_layer_norm.bias  -  torch.Size([1024])\n","led.decoder.layernorm_embedding.weight  -  torch.Size([1024])\n","led.decoder.layernorm_embedding.bias  -  torch.Size([1024])\n","lm_head.weight  -  torch.Size([50265, 1024])\n"]}],"source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#Define the Model's operation in one class\n","class Model_operation:\n","    def __init__(self, model_name):\n","        self.model_name = model_name\n","        self.tokenizer = LEDTokenizer.from_pretrained(model_name, torch_dtype = torch.float16)\n","        self.model = LEDForConditionalGeneration.from_pretrained(model_name).to(DEVICE)\n","        self.config = LEDForConditionalGeneration.from_pretrained(model_name).config\n","        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5, weight_decay=0.01)\n","        self.scheduler = lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n","\n","        self.rouge = load_metric(\"rouge\")\n","        self.batchsize = 4\n","        self.max_input_length = 1024\n","        self.max_output_length = 128\n","\n","    # tokenize the data\n","    def process_data_to_model_inputs(self, batch):\n","        inputs = self.tokenizer(\n","            batch['Text'],\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_input_length,\n","        )\n","\n","        batch[\"input_ids\"] = inputs.input_ids\n","        batch[\"attention_mask\"] = inputs.attention_mask\n","\n","        # put global attention on <s> token\n","        # according to https://github.com/huggingface/transformers/issues/18190, As you are running summarization, it is LEDForConditionalGeneration. For this model, we should put 1 for the global_attention_mask on the first token <s> in the encoder input sequence.\n","        batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n","            [1 if index == 0 else 0 for index in range(len(batch[\"input_ids\"][0]))]\n","        ]\n","\n","        outputs = self.tokenizer(\n","            batch['Groundtruth'],\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_output_length,\n","        )\n","        batch[\"labels\"] = outputs.input_ids\n","        # We have to make sure that the PAD token is ignored by setting it to -100\n","        batch[\"labels\"] = [\n","            [-100 if token == self.tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n","        return batch\n","\n","    # Function to calculate ROUGE scores for generated summary and ground truth\n","    def calculate_rouge_scores(self, generated_summary, ground_truth_summary):\n","        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","\n","        rouge1_f1, rouge2_f1, rougeL_f1 = [], [], []\n","        for k in range(len(generated_summary)):\n","            scores = scorer.score(generated_summary[k], ground_truth_summary[k])\n","            rouge1_f1.append(scores['rouge1'].fmeasure)\n","            rouge2_f1.append(scores['rouge2'].fmeasure)\n","            rougeL_f1.append(scores['rougeL'].fmeasure)\n","        return np.mean(rouge1_f1), np.mean(rouge2_f1), np.mean(rougeL_f1)\n","\n","    # convert the logits to real text\n","    def convert_logits_to_text(self, pred_logits):\n","        texts = []\n","        probs = torch.softmax(pred_logits, dim=-1)\n","        generated_ids = torch.argmax(probs, dim=-1)\n","\n","        for i in range(len(generated_ids)):\n","            pred_str = self.tokenizer.decode(generated_ids[i], skip_special_tokens=True)\n","            texts.append(pred_str)\n","        # pred_str = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n","        # labels_ids[labels_ids == -100] = self.tokenizer.pad_token_id\n","        # label_str = self.tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","        return texts\n","\n","    # convert tokens to real text. The difference from convert_logits_to_text is that this function does not need to use softmax\n","    def convert_tokens_to_text(self, tokenized_sequences):\n","        texts = []\n","        for i in range(len(tokenized_sequences)):\n","          tokens_list = tokenized_sequences[i].tolist()\n","          if -100 in tokens_list:\n","              end_index = tokens_list.index(-100)\n","          else:\n","              end_index = len(tokens_list)\n","          pred_str = self.tokenizer.decode(tokenized_sequences[i][:end_index], skip_special_tokens=True)\n","          texts.append(pred_str)\n","        return texts\n","\n","    def log_metrics(self,epoch, train_loss, val_loss, train_rouge_scores, val_rouge_scores):\n","        log_file = project_path + \"/metrics_log.txt\"\n","        with open(log_file, \"a\") as f:\n","            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            log_str = f\"{timestamp}, Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train ROUGE: {train_rouge_scores}, Val ROUGE: {val_rouge_scores}\\n\"\n","            f.write(log_str)\n","\n","    def log_generated_summary(self,epoch, expected_summary, generated_summary, other_info=\"\"):\n","        log_file = project_path + \"/generated_summary_log.txt\"\n","        with open(log_file, \"a\") as f:\n","            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","            log_str = f\"{timestamp}, Epoch {epoch + 1}, \\nExpected: {expected_summary}, \\nGenerated: {generated_summary}, \\nOther Info: {other_info}\\n\"\n","            f.write(log_str)\n","\n","    # tokenize the test data\n","    def process_test_data_to_model_inputs(self, batch):\n","        inputs = self.tokenizer(\n","            list(batch['text']),\n","            padding=\"max_length\",    #  'do_not_pad'\n","            truncation=True,\n","            max_length=self.max_input_length,\n","        )\n","\n","        batch[\"input_ids\"] = inputs.input_ids\n","        batch[\"attention_mask\"] = inputs.attention_mask\n","\n","        # create 0 global_attention_mask lists\n","        batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n","            [1 if index ==0 else 0 for index in range(len(batch[\"input_ids\"][0]))]\n","        ]\n","        return batch\n","\n","    # test the model by passing it a pdf file dataframe. Return a dataframe with generated summary\n","    def generate_summary_for_user_pdf(self, pdf_df):\n","        data_df = pdf_df.copy()\n","        self.process_test_data_to_model_inputs(data_df)\n","\n","        input_ids = torch.tensor(data_df[\"input_ids\"]).to(DEVICE)\n","        test_am = torch.tensor(data_df[\"attention_mask\"]).to(DEVICE)\n","        test_gam = torch.tensor(data_df[\"global_attention_mask\"]).to(DEVICE)\n","\n","        # when not passing labels, the outputs's loss will be None\n","        predicted_ids = self.model.generate(input_ids=input_ids,\n","                attention_mask = test_am, global_attention_mask = test_gam)\n","\n","        generated = self.convert_tokens_to_text(predicted_ids)\n","\n","        for idx, text in enumerate(generated):\n","            generated[idx] = re.sub(r\"\\\\n\", \"\", text).strip()\n","\n","        pdf_df['generated'] = generated\n","        return pdf_df\n","\n","    def show_model_state_dict(self):\n","        for key, value in self.model.state_dict().items():\n","            print(key, \" - \", value.size())\n","        # for name, param in model_action.model.named_parameters():\n","        #     print(name, \" - \", param.shape)\n","\n","    def save_model_checkpoint(self, checkpoint_model_name):\n","        if not os.path.exists(project_path + \"/Checkpoints\"):\n","            os.mkdir(project_path + \"/Checkpoints\")\n","        checkpoint_path = project_path + \"/Checkpoints/\" +checkpoint_model_name\n","        torch.save(self.model.state_dict(), checkpoint_path)\n","\n","\n","model_action = Model_operation(model_name = \"allenai/led-large-16384-arxiv\")\n","# optional: set hyperparameters. Some parameters inherit from https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/configuration#transformers.PretrainedConfig\n","model_action.config.num_beams = 2\n","model_action.config.max_length = model_action.max_output_length\n","model_action.config.min_length = 100\n","model_action.config.length_penalty = 2.0\n","model_action.config.early_stopping = True\n","model_action.config.no_repeat_ngram_size = 3\n","print(\"Pre-trained Model Config:\\n\", model_action.model.config)\n","print(\"Pre-trained Model state-dict:\\n\")\n","model_action.show_model_state_dict()"]},{"cell_type":"markdown","metadata":{"id":"OJ4An9HeDUru"},"source":["# 3. Prepare for DataSet and DataLoader\n","All the training data has been put into CSV file. We load CSV file and convert it to Huggingface Dataset. We then use Dataset's map method to tokenize the data. We format the Dataset and then load the data into PyTorch DataLoader to achieve the best performance.\n","\n","The variable `CREATE_NEW_TOKENIZED_DATASET` decides if we use the existing tokenized dataset or re-create new ones. Using existing tokenized dataset saves time if the training data and verification data do not change from the previous training."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":572,"referenced_widgets":["d3ec44fb997a48908225b79f2d91dd19","c388426d4e094a7ea5f0ecf164b30373","6ec8f012b3be419a9426866e0853db06","af7497424ded49dda52192fd228b211f","3f27cfb282db49cb889cddcc2af00dde","cb661f5de24a4b94ac8e330c502d391e","ee610b54de85438baf36cc3d13753d89","d38ba24f88d8413aadc54fd867665966","08782b0ddcdc4eaa8bfa345abd2496d1","2a6d70879e2346b9bbb5d96db2a2be7b","bf35a626b762404ba8254b28135d38fd","b7f0d0831a8f4a69abcb7c1bf143fded","432297a5dbed491eb9dc63c160703409","be2897b2218845b287d29eae7cd23650","272205d6af4b46cca2e2db7096ff9b0c","1b06954472e24bc499fb2c278350cd88","64937d9d6ca449fd93b66e6e3de2f7cc","cf9684913e3a44dea5fa3d7d0002b2cd","6ae72c930e4a42ef817dc49bf754eac7","fbbef8bbc597481f9571aed448d1abbb","0824990860e244098c949f3cc031db3e","d815b985225c457e8380b76514d9977c"]},"id":"8Ll9mvD-JIMq","outputId":"c41ebb65-08c0-4c7c-eafa-13c55eceaffd","executionInfo":{"status":"ok","timestamp":1714447817046,"user_tz":-480,"elapsed":19267,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["train_dataset records: (660, 3)\n","val_dataset records: (139, 3)\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/660 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3ec44fb997a48908225b79f2d91dd19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/139 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f0d0831a8f4a69abcb7c1bf143fded"}},"metadata":{}}],"source":["# CREATE_NEW_TOKENIZED_DATASET = True\n","\n","train_df = pd.read_csv(project_dataset_path + \"/dataset3.csv\")\n","val_df = pd.read_csv(project_dataset_path + \"/eval3.csv\")\n","train_df.dropna(subset=['Text', 'Groundtruth'], inplace=True, axis=0)\n","val_df.dropna(subset=['Text', 'Groundtruth'], inplace=True, axis=0)\n","\n","text_len = train_df['Text'].str.len()\n","plt.hist(text_len, bins = 20)\n","plt.title(\"Token Number Distribution\")\n","plt.xlabel(\"Total Tokens\")\n","plt.ylabel(\"Sample Number\")\n","plt.show()\n","\n","train_dataset = Dataset.from_pandas(train_df)\n","val_dataset = Dataset.from_pandas(val_df)\n","\n","print(\"train_dataset records:\", train_dataset.shape)\n","print(\"val_dataset records:\", val_dataset.shape)\n","# train_dataset = train_dataset.select(range(100))\n","# val_dataset = val_dataset.select(range(40))\n","# print(\"selected train_dataset records:\", train_dataset.shape)\n","# print(\"selected val_dataset records:\", val_dataset.shape)\n","\n","# if CREATE_NEW_TOKENIZED_DATASET:\n","# tokenize the data te prepare for the training\n","train_dataset = train_dataset.map(\n","    model_action.process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=model_action.batchsize)\n","\n","val_dataset = val_dataset.map(\n","    model_action.process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=model_action.batchsize)\n","\n","train_dataset.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",")\n","val_dataset.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",")\n","    # # save to disk: https://huggingface.co/docs/datasets/v1.5.0/processing.html#:~:text=You%20can%20save%20your%20dataset,objects%2C%20you%20can%20use%20datasets.\n","    # train_dataset.save_to_disk(project_dataset_path + \"/train_dataset/\")\n","    # val_dataset.save_to_disk(project_dataset_path + \"/val_dataset/\")\n","\n","# else:\n","#     # load from the existing formmated tokenized dataset\n","#     train_dataset = load_from_disk(project_dataset_path + \"/train_dataset/\")\n","#     val_dataset = load_from_disk(project_dataset_path + \"/val_dataset\")\n","\n","train_data_loader = DataLoader(train_dataset, batch_size = model_action.batchsize, shuffle=True,drop_last=True)\n","val_data_loader = DataLoader(val_dataset, batch_size = model_action.batchsize, shuffle=True,drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"jfEOwmQLakt0"},"source":["# 3. Fine-tune the Model and Save Check-point\n","\n","The fine tune only occurs in the last layer: lm_head and final_logits_bias. All of the other layers' parameters are frozen.\n","\n","There is early-exit mechanism. When the val_loss continues going up, stop the training process. The latest checkpoint model is saved to sub folder `Checkpoints`. All the training and verification loss, and rouge metrics are saved to folder `Runing_result`too."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"o4oOckh1JIMq","outputId":"59d27b86-4159-4834-fe8c-cd08f28e203e","executionInfo":{"status":"ok","timestamp":1714453954041,"user_tz":-480,"elapsed":6137021,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/10 [00:00<?, ?it/s]\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 0, training loss: 3.5874948501586914\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:05,  5.35s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 1, training loss: 3.7415342330932617\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:08,  4.14s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 2, training loss: 3.9948854446411133\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:12,  3.83s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 3, training loss: 3.4233860969543457\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:15,  3.68s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 4, training loss: 3.65722918510437\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:18,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 5, training loss: 3.572042942047119\n","epoch 0, prediction loss: 3.8506884574890137\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the nasal of a novel - algorithm landmark landmark landmarking algorithm for the reconstruction andthe algorithm is apping the face and using median filtering and andampling and image and anding it dela and and thening the three to crop the nasal region.themarksing is on a minima detector, aative algorithms to remove landmarks landmarks on the nasal region. such as the nasalnasale l eye corners.thelieriers are removed using aative algorithms. remove that selectioning.the algorithm is to be detect the al and avoiding redundant parts of the face andthe     ggg    ',\n"," ' we weooth compact hypersurfaces without boundary are in rm1mathrm{+}$-}1}$gam$ be viewed as are(shypersurfac if\\\\ are have a tubular neighborhood of see are tub of this equival is given.we, there only b \\\\m++1}^{)+ below the grap 1 b ))so that gr 1 ))has has a tubular neighborhood. radius. 1 )). is a -rt-hypersurfac.\\\\, there all smooth uniformly regular hypersurfaces are aRT-hypersurfaces.there instance, there of',\n"," ' we we vib is the of for on the priori estimates for the a of based convergence is the convergence of the unfolded function of the2 ofthe to the convergenceation of the limit vibro-acoustic problem. a formal approach which the sequences constructed with the convergence res.based - -                                                 bb  bbbb   pbpb       ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:23,  3.90s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 6, training loss: 3.3612751960754395\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:26,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 7, training loss: 4.227987289428711\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:30,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 8, training loss: 3.4192724227905273\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:33,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 9, training loss: 3.1976637840270996\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:37,  3.53s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 10, training loss: 3.506321907043457\n","epoch 0, prediction loss: 3.4616987705230713\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we high of the theoretical of the order difference schemes for solving thestationary cauchy typetype ellipt for to theal power elliptic problems.the order approximations are used to approximate the time dependence of the solution  while the elliptic operator is approximated by the finite element sche.the. stability conditions are given for the-level discrete schemes with weight weight parameter andthe order accuracy is proved for the symmetrical crankank-nicelsonson type sche.the family of three-level symmetrical discrete schemes is constructed and investigated. the on the smooth solution.the condition on the first time level of computed by the',\n"," ' we we paper is the concept of a _ - andbgebrabrir and with the non of and which is of a two structure of a two of the associated -ed.the structureatonism of the structuregebroid are determined. and the importance for the the nature structure of the structure bundle structure x -@@@igenigenigenigenigenigenigenigenigenigenigenigenigenibibibibiiiiii    ibiiinoneiiiiiiiiifbfbfbfb  fbibfbfbiiiiiiiiifbfbfbfbfb,,,,,,,,,,,,,',\n"," ' in in e of with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is carried inin closed-form expression for the e error probability of concatenation of molecular two channels was derived andthe optimization problem was at minimize the e error probability of conc system was formulated to determine the symbol durations for both molecular of communication.the reveal that an adaptive system must required to achieve the minimum bit error rate and optimal performance for the e -to-end communication.  -                           ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:41,  3.82s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 11, training loss: 3.6641621589660645\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:44,  3.67s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 12, training loss: 3.64667010307312\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:48,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 13, training loss: 4.517369270324707\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:51,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 14, training loss: 3.4190826416015625\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:55,  3.52s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 15, training loss: 3.623497247695923\n","epoch 0, prediction loss: 4.931088924407959\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we search of the results of a ensemblene affinvariant ensemble sampl to explore the from ofwe bayesian framework is a space uniform priors is used towe toors are used for the r ofbr and pbr of on the fraction sample.we casc prior for that the of must be larger than f parameter avoid trunc andwe resulting is is for a multiplicity systems to be more common than smaller multipl.we -                        adadad b bad adbb b ',\n"," ' we we sensitivity is the sensitivity of the constraints on the matter ( d )pair at in on the bound to the of the momentum of d pair atom and/ -electron scattering at to the of thearks inwe is the need of theizing dpto- andic and electro boson b@-linic d particles at the l hadron coll ( lh ) and the the need of the the- to the-2 operators inwe analytical is discusseszes the state effects of d -atom scattering and dama and and derive the the pair production channels at the proposed linear coll ( ilc )  analytical have the',\n"," ' in in traffic is a in the ever amount that thatthereifying the traces and applicationsifying applications is two tasks in  traffic tracingifications ( nt ) )have classify anomalies in classify the for which they methods are shown in the on ports and the reasons. their ofingorithms that n classification classification are great in they tools forin thebalanced datasets is the -scale networks is a challenging for algorithms in f..inmentation is are machine learning are which as artificial artificial data for are be the imbalance andin novel methodmentation method is k -ensity andimation and kde )and l - -Term memory ( lst']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:59,  3.83s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 16, training loss: 3.7800509929656982\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:03,  3.68s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 17, training loss: 3.7585766315460205\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:06,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 18, training loss: 4.101418495178223\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:10,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 19, training loss: 3.3148674964904785\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:13,  3.53s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 20, training loss: 4.135822772979736\n","epoch 0, prediction loss: 3.698488473892212\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we t of the t and mumford-tate conjectures for the s the components of the gieseker moduli space that lie a product-quotient surf thatthe - s s and and,,     antantfter                      ablefterfterfterfterfterfterfterfterableiiiiiiiiiablefteriiiableablefterableiiiiiiiiiiiiawareiiihereiiiiiiiiiiiipbiiiiiibypbthethethethethepbpbbypbpbpbpbpbpbpbpbpb',\n"," ' we we is of the the of obtain the is component of a a refined isomorphism between the6 decomposition ofthe is a a isomorphism of for to theu-de-taquin s@ - s s and@@@     fterfterfterfter   ftervfter  hadhadhadvivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentpartyivalentivalentivalentivalentableableivalentableivalentawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawarebyawareawarebybybybyawareawareawareawareawareawareawareaware',\n"," ' we we ke of the use of creating a stellar sample for use a detection efficiency map of the data. the1q17.0 stellar is 86 parameters from theur et a.s ga stellar values from ga dr2.we the measurements have been been updated from the dr2, the has25 stellar mass values have updated updated towe account thatteness mapping we we star must have a stellar of its a and mass measurementwe values for either fields result in omission wewe, the on placed on the cycle and fc >.5 )and time length of light light curve (we final is the -varying noise']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.82s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 21, training loss: 3.63729190826416\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:21,  3.67s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 22, training loss: 3.936893939971924\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:24,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 23, training loss: 3.648979425430298\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:28,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 24, training loss: 3.2207953929901123\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:31,  3.53s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 25, training loss: 3.7514283657073975\n","epoch 0, prediction loss: 3.6385440826416016\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we singular on the minimal domin1 theoremthe singular for which the minimal regularity conditions on the singular t that which the t holds.the is that the minimal on which minimal to almost unknown. we about they theorem dini cond can be relaxed tothe main is the main assumptions on t k yielding yield thewise sparse domin.the proof are in results and the the numbermma for a of the of to the weak.the is with showing that the the bounded extension of t t is l2 to itself, then bounded condition on be onthe -                ',\n"," ' we we ke on the effects of a new of represent the ke eff of the ke survey forwe grid is created into 100,000 regions of period and radius spac andthe region is then in in log space for period and radius spac all each are assigned m based on the order.we probability order of are the of detecting multipleoplanets in each detection ofwe probability of repeated for each of of the detection order grids.we probability probability maps for the effects of limbity and limb the new function for account mis mis transits.thepreating between made to account the probabilities for the detection order.the eff are created for m multipl',\n"," ' we we j is the use theory of thear-tensor theories f the j frame, and the role of ill order time derivative terms in are ill-posednes inwe, we is shown that equations of motion can always reduced to a second-order-in-time form as the original e frame formulation is well posedposed.the inverse transformation from the j frame to the e frame is not be possible for all field values in the, but we fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f fwe results motivation is a better understand the scalarization and its general']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:36,  3.83s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 26, training loss: 3.640336275100708\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:39,  3.68s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 27, training loss: 3.5562803745269775\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 28, training loss: 3.861215353012085\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:46,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 29, training loss: 3.3521132469177246\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.54s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 30, training loss: 4.54160737991333\n","epoch 0, prediction loss: 4.437633514404297\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we point is of improved version of the pointwise sparse domination principle established by the first author inthe allows allows us the the singular assumptions on for a singular integral operator to admit a sparse domin.thech          gn                                 iii     aden aden             adenadenaden  awareaware       aden     ',\n"," ' we we crystal result of in this paper is that multiplicity freereeness of the b with this labeling labeling convent. which well by figure 2. in main7 crystals b are be decomposed into the le subalgebra of type a6 and a multiplicity freefree way. and by a computation. a the in using the and we loops to everyices in and adding the composition graph g, we is shown that the e b is type e is a multipl rule. the multipl m of x x inin proofposition is multipl shown by amma  and theabeling the fundamental weight.  leading in a multiplicity',\n"," ' we we point on a examples of the admitting admit thewise sparse domin.the main is the the of bounds are known known and but here unified approach simplified approach to provided to on theore 1 and its variant.in results are from from the results in thei  and sheldy ombrosi. and the improvements in in the to and5 paper results is the the latter admits of weak type and to theorem 1 andthe a specific refined form with by the more case. by.in                          ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:54,  3.84s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 31, training loss: 3.7163619995117188\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.68s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 32, training loss: 3.1069700717926025\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:01,  3.62s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 33, training loss: 3.883918285369873\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 34, training loss: 3.2047791481018066\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:08,  3.54s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 35, training loss: 3.78164005279541\n","epoch 0, prediction loss: 4.1559648513793945\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we weinstein of are the transit study of to properties of the populations fromwe key function is used for the bayesian theorem theorem and extract the parameters fromusing method distribution is modeled as a independent power -law distributions in period and rad.we distribution that a single planetary population is made by assuming the distribution of this assumption is examined.using distribution is on the systems and thezes the effect effects of the and multipl ofusing distribution used to on the studies to including the by detection order andwe of are a on the factors detection order and the distribution sorting for this introduced the distribution distribution fun ( to this.we statistics is also to to',\n"," ' we we keism we by this paper is applied to infer the occurrence rate parameters for planets orbiting gk dwarf stars based  from the final ke release dr25 and including planet radius measurements from theks and ga,, and a detection eff for multiple-planet systems are used.  resulting is on the poisson process likelihood function used allows a bayesian framework to to anmsthe resulting are that values for the revised of which a at the best fitfit model at at p p ofthe novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m',\n"," ' we we ke presents on the multipl in we the planetary parameters from theoseismic updates fromwe inclusion of the updates has the radius measurements andwe explore thelier systems, the ga data, we measurements are tested against the ke dr25 cat andwe of also from the curves and thus periods effect on the data cks data. we positives are removed by the thes to thus the planets with 500 days are considered. be contamination from we -icity effects are explored by a all the within in we a of on the and period cut. we with a positives are artificially removed to the order   inclusion detection multiplicity we in a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 36, training loss: 3.411705493927002\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:16,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 37, training loss: 3.7387773990631104\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 38, training loss: 3.264660120010376\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:23,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 39, training loss: 3.7910075187683105\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 40, training loss: 3.7752718925476074\n","epoch 0, prediction loss: 3.7208566665649414\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in isisms are on the for of for in for by for andfulerryerson andinisms are the sense are the -fulalkerson flows oninflows on a network is defined by a inequalities,inflow is a to minflowichai flowinperner s original on that min ranks are satisfy hall s condition are to min naturalperne -et.in and har introduced hall s matching cond by give rot. s conjecture by and the category matching condition. a normalized of the normalized flow property.in category flo is with theyclic vertex-weighted networks and and aisms preserving the morphisms preserving',\n"," ' we we differenceauchy problem method is a to solving solution of solvingolving of the on the auxiliary pseudo-time evolutionary problem,the a priori estimates  be obtained for solve numer problem, the the prior implicit two -level euler scheme the the forthe difference scheme is unconditionally stable with the initial dat for using these estimates recursively we we validity of the difference is proved.5 - - the ,,,,,,adadadadadadadadadadadadadadadabababab)=()=(ababab)=(pb)=(pbabpbabpbpbpbabpb',\n"," ' we we aim presents the classification of the which by theodge theory and in by the which irregular3 type. product modental part.we are the of the t of the surfaces and their a answers to the questions about the conditions.the main also the the classification of these surfaces is not not and that the state state of the art ofthe also on the-quotients surfaces and show mod group theoretical dat. and well as the moduli spac.  results obtained can used to prove that t and mumford-tate conjectures for these surfaces.  proof also the authors of inspiration and the a overview of the current state']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:31,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 41, training loss: 3.090019941329956\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 42, training loss: 3.8355159759521484\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 43, training loss: 3.7044665813446045\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 44, training loss: 3.263662576675415\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 45, training loss: 3.963395118713379\n","epoch 0, prediction loss: 3.436476469039917\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we number  the use of a modified poisson distribution function to modelolate to expected of existence for a multiplicity systems systems.we using this function to we expected of that the fraction empirical multiplicity of be extrap by a function of selection effect.the best is shows the implications of this function to the the of the multipl and period forthe, the is the impact of this model of multiplicity in our solar system for theability. and that lack for a studies of support the claims..         dd  dddddd  dd dd dd ddab ',\n"," ' in in aim results the model is three different datasets is that our method of sampling in able in im thebalanced classification andthe of that to precision1 measure, precision and and recall measurethe overall is performance on compared with that in and the in precision and in to the false predictions predictions andthe overall accuracy of the model is also than sampling in with a improvement in precision and recall and and confusion accuracy.  model is that accuracyiz of accuracy decrease in false negative. to the in.          ddddddddddddddddddddddddddddddddddddabab',\n"," ' we we effective of the effective interactions of theermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the thermally averaged indirect indirect matter pair d )pair annihilation cross-section and the spin-independent d - with le and/or bound electron. and that with the dat.  - - the,,   ,                       bbbb   bpbpb pbpb   ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 46, training loss: 3.3716132640838623\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 47, training loss: 3.444160223007202\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:56,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 48, training loss: 3.3193819522857666\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 49, training loss: 3.7046868801116943\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:03,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 50, training loss: 3.8146495819091797\n","epoch 0, prediction loss: 3.3729007244110107\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in inrones are getting being in the fields fields in the such google, facebook, amaz amaz, their own drone technology.drones are used in many journalism so obtain videos of areas toto -access areas andincopter are which quad of quad, four rotorors, are one used in and the ofors working clockwise and two other two counter counterclockclockwise, balance that ofinrones are be autonomously based on a-entered program without and without with a resolutionresolution cameras and image processing and computer vision techniques. in, a of when a or or satellite -captured satellite maps are not.in paper',\n"," ' a a novel algorithm is introduced to this paper to address the invari invariariant face recognition, that the 3d shape of nos nasal (the algorithm isages a robust anding algorithm, a feature space, discriminative feature descriptors and feature feature selector tothe results is applied over three well face datasets, fr that results for both and verification..the, the algorithm achieves a ranks of than previous nasal region-based algorithms, outper betterformed many 3d holistic and multi -modal appro.the algorithm is performance for to other in other alignment, low dimensionaldimensional face recognition and pattern pattern rejectio  research on are the',\n"," ' we we j on the j of generalizations of spontaneousar- andensor theories that sts )that the j frame where where where the scalar is replaced with other fields and couplings can depend on derivative ofwe first for from the that spontaneous tensoriz, where are most naturally defined in the e frame wherewe are be applied to any generalization of on a conformal scaling of the metric in the matter action bywe first is the the scalar in a vector or the-tensor theories, vector to the-based spontaneous scalarization arewezing the j of that time derivative terms in no renders order and equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 51, training loss: 3.8726885318756104\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:11,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 52, training loss: 4.351571559906006\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 53, training loss: 3.5768187046051025\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:18,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 54, training loss: 4.194729328155518\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 55, training loss: 4.08143424987793\n","epoch 0, prediction loss: 3.5993902683258057\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we s is the s of the electrodynamics theory under theity transformation and using on the drangian invari of the the theion and dilaton fields intowe is the sance of the equations under equations of motion and energy-momentum tensor under the-duality transformationwe extensionsetries of transformations involving the theory are discussed discussed. including as the s of the of type i super superstring theory and the s of of theitudes of the-duality.we isves into the s of the involving equationsitudes of the-duality transformation and and the role of the of the-duality',\n"," ' we weac s@obi - are a models that are the the theoryac equations with a externalic equation of of form a set set of with a information.the structures are called in the framework of the equations and are be used to the physical models. the of theolds and@x -@@@ognigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenibibnonenonenonenoneib,nonenoneibibnonenonenonenonenonefbibnonefb,,ibfbfbfbfbfbfbfbfb,,,,,,,,,   ,,,',\n"," ' in in fraction is numerical numerical of fractional power equations in time models of solving applications  as sub, biology or finance finance.in is on the fraction with fractional power elliptic operators and numerical of the elements and quadlov subspace method.in numerical to solve fractional powerin-space reaction-diffusion equations are analyzed and in the integral and adaptively preconditioned lzos method.the numerical also presents theimations of fractionstation ellipt by the a new algorithm for on the to a pseudo-parabolic equation. solving fractional power elliptic problems..the is with a results to the results and the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:26,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 56, training loss: 3.3026676177978516\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 57, training loss: 3.8805336952209473\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 58, training loss: 4.095123767852783\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 59, training loss: 3.1516902446746826\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 60, training loss: 4.127309322357178\n","epoch 0, prediction loss: 3.7828781604766846\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we q of a new of the invisible qcd axion model with domain wall. which the heavy heavy heavy are present.the is is first in the contextxiv pre19002.v3.. the 2015st2019.  - -@@.       gngngn           ad      bbadbbbad adadiiiadadadbababiiiiiiawareabawareabfbabiiiabab awareabababb  iii    b    ',\n"," ' we we cosmic is the possibility between the physics and cosmology and the appearance of topological defects during spontaneous breaking and the context.we is the possibility wall problem and theion models majoron models and proposes a to as the inflation and the warides-shafq and the the witten effect towe minimal minimal is proposed where the breaking of peq symmetry is at at a newiral confining force and which the domain wall problem.the model of instantons interference effects also and solve the instant wall problem and using the peq symmetry by the,.the model also discusses the question of thebaryons in which heavy',\n"," ' we we boundary on the boundarydimensional haddorffme on the to the the the boundary local time of the ofthe le also the naotoaka kajino for his comments on the proof of lema.the. - -@...  ggadadadadadgadadadgggadg..adadadadggggadggadadadadad.adadenadenawaread.adenadenawareawareawareawareawareawareawareawareawaretheadenadenadenadenthetheadenthethetheadenadenthetheadenthepbadenawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 61, training loss: 3.821988105773926\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 62, training loss: 2.9644575119018555\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 63, training loss: 3.3547191619873047\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 64, training loss: 4.176869869232178\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 65, training loss: 3.667405128479004\n","epoch 0, prediction loss: 3.852104663848877\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in e on a e -to-end e2health communication which for includes molecular and electromagnetic wireless commun betweenthe- and and are d via a relay-assisted diffusion-based molecular communication system, which aomachransmissionters in a molecules.the relay node is be improve the link andthe proposed is includes a- and and off-body communication via which the time of nan schemes. different symbol intervals. each communication type.theomachines/ as relay nod in which nearly free and communication betweenthe proposed is includes a2out-off-body communication communications between aways. the communication between the body-health system.',\n"," \" we we paper of a simple of the theorem of the themma  and the the in show the theoremollary ofthe cor of that that the bound u is '' is unounded and and the result is based by using the arguments to in the proof of the theorem.the - - - -   the  ggngnad ggadjivalentivalentivalentpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbababpbpbpbababpbpbpbpbabpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpb\",\n"," ' the the vib of the vib of the and vibration reduction in the design of the in the industry civil engineering.the is on the the wave propagation in periodicallyating perforated plates immersed which the of respect modelling of to the geometrical ofthe vib presents a modelling to theogenization to derive viblocallocal vibro-acoustic transmission conditions for the per designed with an inviscid fluid.the method is us the reduced modelling modelling of takes information details about the need of disc discretization ofthe approach is a new approach for modelling ofroporous panels which providesates the proposedogenization re of direct numerical simulations.the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 66, training loss: 4.293423175811768\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:06,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 67, training loss: 3.7492611408233643\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 68, training loss: 3.7167837619781494\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:13,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 69, training loss: 2.9525883197784424\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 70, training loss: 3.4502756595611572\n","epoch 0, prediction loss: 3.416170120239258\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' deep deep learning ( ability to high stakestakes decision problemsmaking is a challenging for it influence may uncertain and extensive test anditing deep learning agents to high high may lead in critical failures, in methods have been proposed to analyze the internal mechanisms of deep learning agents, to their performance-m,.in these of have focused on feedability of feedforward deep learning, we studies also the issue of more learning ( well. in majority-hoc interpretability of deep learning agents has be used to predict and prevent potential, but it their is the learning agents is a agents. in potential approach to to provide the in reinforcement learning agents by',\n"," ' we we ke of the effects for incompleteness due the planet occurrence rates due to transit multiplicity inwe ke data typically planets in order of descending strength and but we detectability of transits experiences a by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics that affect the radius and period distributions of each detection ord.  results rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog.  results model is consistent with the studies but now includes an improved estimate of the multiplicity distribut.  average also',\n"," ' we we ability is the applications of thes agents to are secondary to evaluate a agents from r agents.we agents are evaluate used in specific-specific problems andwe from of such as state multiple rewards and of state rewards, can be used to evaluate r- andtheizing the actual of state- can on the such coordinates and velocities can be the performance of qs agents.thes agents can also multiple matching and value networks to evaluate agents values of.@ proposed between p p cortex and pfc ) hippocampus and and anterior cingulate cortex ( discussed for the andwe p also that one of of q q cing']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 71, training loss: 3.6985297203063965\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 72, training loss: 3.3251163959503174\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:28,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 73, training loss: 3.4469587802886963\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 74, training loss: 4.005324840545654\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 75, training loss: 4.091567516326904\n","epoch 0, prediction loss: 2.970306873321533\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we as on the method analysis which the the acoustic acoustic pressure and the displacements and and rotation in a limit lay ofthe is is based for the understanding - and vib of vib vibroacoustic problem imposedthe asymptotic analysis is based using the unfolding method which which developed in the seminal paper by elaborated elaborated further thin structures inthe@ -@@    gg              ad            iii)=()=()=()=()=()=()=()=()=()=(iiipbpbpbiiipbpbiiipb ',\n"," ' we we ant is a following of ant antichain a a pos connected set of aet )p no two elements are compar.an@ and and@@@@     iii         ivalentivalentivalentfamfamfamfamfamfamfamfamfamfamadenadenadenfamfamadenadenfamfamfamadenadenadenadenivalentivalentivalentadenadenivalentadenadenadenadenadenadenadenadenadenadenawareawareadenadenadenadenawareadenawareadenawareawareadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden',\n"," ' the the vib of the vibogenization of thero-acoustic transmission on perforated plates andthe is a the plate by an interface on is transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inthe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withthe homogenized model of theroacoustic transmission is obtained using the -scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation per,the nonlocal implicit implicit transmission conditions involve a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 76, training loss: 3.6161599159240723\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 77, training loss: 3.3980917930603027\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 78, training loss: 4.014302730560303\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:50,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 79, training loss: 3.2720632553100586\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 80, training loss: 3.601379156112671\n","epoch 0, prediction loss: 3.980756998062134\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in paper presents a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation.the layer is treatedoupled form the outer acoustic field by theumann fluxes and is by theymptotic analysis based averagingogenization based.the numericalaging procedure based to a of outer acoustic field with the-layer variables whichtheumerical examples illustrate the validityogenization model and accuracy and with the numerical simulations of@ research on at design the of compliantforated plates in vibroacoustic trans problems@ paper of supported by the grants grants of ',\n"," ' the the en is ( this contextured the en and modeling the state vector and action a inputs and the the next state.the this paper, we network layer of a nodes is used to the env network tothe is shown using the squared error recurrent each episode of random learning.. the r learning rate of 0.0. - -...adadadadadadddddddddddddddddddddddadddadadenadenadenadenadenadenadenadenadenadadadenadenadenadenadenadenadenadenadenadenadenadenadenbadenbadenadenadenadenadenbhbhadenbhib',\n"," ' we we effect of theooninivityverseal of @ -@@@....bb____b__iiiiiiineineine__ (iiiinefbfbiiiiiiineinebiabiabiainebiabiaineibiiiineineibib,,ineine,,ineineineib,,,,,,,,,,ib,,,,ibibibibibibibibiiiiiiibibiiiiiiiiiiiiiiiiiiibibib,,ibibib,iiiiiiiiiiiiiii,,,,,,ib,,,,ib,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:58,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 81, training loss: 3.745314836502075\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 82, training loss: 3.600388288497925\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 83, training loss: 3.6923141479492188\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 84, training loss: 4.023563385009766\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 85, training loss: 3.376279592514038\n","epoch 0, prediction loss: 3.4681224822998047\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using thenating them key points between the and and then a robust fitting to to finding changes rotation. as rotation andthe, when we to stitch more result image with a third image, the will because the result will tries the black background as the image process.to happens is due by the that theofcv, so to a images. stitching more than two images.to avoid this problem we open algorithm was implemented using openc, find this problem problem by theofcv. translation. to effects.thew..',\n"," ' quasi quasi agent-critic model is a to a reference r agent to the paper tothe structure of quasi quasi-symbolic agent ( matching and value networks, which single layer and network,entially connected thatthe matching and memorizes input vectors by imprinting normalized inputs to synaptic weights converthe value of matching nodes is identical to the number of value nodes and and the-to-one mapping between matching.the the new node is added to the matching network, a new node is also to the value network, keep one one betweenthe strength between between these of determined by the reward induced by r selected agent withthe gradient of the',\n"," ' we we comb of the comb of a7 crystals weight elements from using the7 crystals weight elements as the decom computation of.the combposition into e7 crystals is multiplicity free and is shown to the comb that to the one of proposition conjecture ofthe combinatorial r-matrix is a to its ability to map classical components to classical components. which the weights are k k of k in computed from a function ofthe is is as a step towards proving a conjecture of a a construction of a7crysta value for the finite way.  -                ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 86, training loss: 3.5378167629241943\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 87, training loss: 4.262124061584473\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 88, training loss: 3.6097910404205322\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 89, training loss: 3.0495176315307617\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 90, training loss: 3.9447171688079834\n","epoch 0, prediction loss: 3.2654590606689453\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we following of some but/ extensions of the theorem theorem of namely on the point precise version of pointwise sparse domination 7.1 main of this theorem result of the original theorem is that. and some is used how it result can used in a applicationsorems.1 proof also discusses some possibility of the theorem to a multilinear cas. and the the results obtained1essary and in the proof are pointed out. and the the original of of the theorem theorem.1          iiiiii                  ',\n"," ' we we vib is the problem vib of vibro-oustic response in inwe problem is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofwe problem is on the the vib field in the layer with the surrounding en and the a coupling equation whichwe conditions for the global problem are provided. which are the to the limit on the limit limit forthe - the.                  .ad.ab bbab)=()=()=(bbbbbbbbpbpbabpbpbababpb',\n"," ' we we we of the weence of vb-algebroid structures on d we lie algebroid and horizontal or vertical differentials on two of the weil algebras and a well as ger gerstenhaber bracket on the th wear is discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras.ar -.                                  ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 91, training loss: 3.8584330081939697\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 92, training loss: 3.3968074321746826\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 93, training loss: 3.3683419227600098\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 94, training loss: 3.078228712081909\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 95, training loss: 4.012847423553467\n","epoch 0, prediction loss: 4.2972025871276855\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we aim on a method of the theorem on the the monmma ofwe is the convergence of the pro of themma  and le to theorem condition. shown in the theorem bythe proof is a concept ft : the to themma 3. le leotone convergence theorem forthe, the is the ex for the with respect to the probability measure p the with section with using the theoremms of themmaps. thethe -     bbb   aware   .   ivalentivalentabititababababpbababpbpbabpbpbpbpbpb',\n"," ' we we ke presents the modeling soft the from the keomult soft soft extract the ke population of determine constraints of  key modeling presented each of planets according on the parameters and and the randomly to of detection accordingthe probability parameters the population parameters with is that weak in the radius population around which due by a unique population planet and population population.the -planet systems are also and comparison analysis and and that population dependence.the forward model is from ouresian analysis of compared and and that in the parameters due uncertainty due.the best isiates between multiple and and and and single-planet systems and and the implications future studies of planet period and radius',\n"," ' in in goal of in this paper is more 70 gigabytes of real traces traffic from the campus of amirkabir university of technology and which of more and tcp link fromweows are labeled using n n sourcesource dpi tool n nd and and which the classes of applications from from more 50 gigabytes of packets. which more44,000 instances.the percent of these flows were chosen for training and while the rest are test datthe dataset is 90 total of applications classes and including more classes of more than thanthe imbalance is a imbalance feature with more 83 percent of the whole consisting of 4 cl ofthedpi is the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 96, training loss: 3.521763801574707\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 97, training loss: 3.897886276245117\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [06:00,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 98, training loss: 3.3299026489257812\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 99, training loss: 3.912217855453491\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:07,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 100, training loss: 3.2859046459198\n","epoch 0, prediction loss: 3.6321938037872314\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and a inclination dispersion and while the other having low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems,l, the ke of be affected by the effteness effects the loss such here, of that the for detection loss atens the need for an additional population to explain the ofwe inclusion of suggests that the transiting systems are more dynamically excited than multiple systems and consistent this stellar hass this this notion that some populations share dynam dynam',\n"," ' we we ke presents the bayesian method to to estimate population parameters for the ke sampleoplanet sample with a bay using using upon the bay we extract information about the multiplicit and comple a best replication of the empirical popul multiplwe studies have used that steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters of with the from a provided a bay.we study is that with the for prior bay using and at the case of planets radius planets down to the threshold.we usingorously treating completeness mapping and a',\n"," ' we we aimured the in the images images in to the and can be the of.we main presented in to solve these by improve that transitions between the images.the, ity details details during occur occur the quality.thisosing the best appropriate algorithm for this problem is a because to the issues.  - s is.,,,adadadadaddaddadaddaddaddaddaddaddaddaddaddaddaddaddaddadenaddadenadenadenadenadenadenadenadenadenabababababababababadenadenababababababababababababpbpbababab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 101, training loss: 3.618866443634033\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:15,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 102, training loss: 3.687221050262451\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 103, training loss: 3.739967107772827\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:22,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 104, training loss: 3.2838823795318604\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 105, training loss: 3.5761935710906982\n","epoch 0, prediction loss: 4.412326812744141\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we splitting of the splitting theoremorems of json pairs and j proposed by dazord, lichnerowicz and and marle inin new point of the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.as - - -@...                         antedanted    ab        partypartypartyadenadenabpartypbpbpbpb pbpbpbpbpbpbpbawarepb',\n"," ' we we author on the results in to the of dir subsetets and andichlet form and andotone class argument and andity and and domain and and and eigenfunction and and and and dini s theorem.the words are the thatity of the dirichlet form and the convergence of themma  and proof of to the works.the section is contains the authorification theorem of the pn t on l  the convergenceiteness of the*. theorem s                              ',\n"," ' we we wellured the well -posedness of for the wellard - of which on the workorems on the of to the regular surfaces andthe proof is from to as in the previous proof ofthex and and@@                ivalent   ivalentivalent  ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentgianivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent ivalent aware  ivalentawareivalentawareawareiiiivalentivalentivalentivalentawareabawareawareivalentpbivalentpbpbpbawarepbpbivalentpbpb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 106, training loss: 3.4398303031921387\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 107, training loss: 3.330273151397705\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 108, training loss: 3.211862802505493\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 109, training loss: 3.404062509536743\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:44,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 110, training loss: 3.497183322906494\n","epoch 0, prediction loss: 3.13616943359375\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we index on theasipinear inequalities with aity -ity in whereization the index j sub acritical and the sub inequality and satisfied and critical in the holds in the certain case.wex is is@     ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,ivalentivalentivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentabivalentivalentabivalentababababababababivalentivalentababtheababivalentabivalentabababababab,abab',\n"," ' the the ke mission has increased our understanding of the around sun-like stars withthe final data release dr dr25, provides all on to the failure of two reaction wheel on providing the end end of the primary phase oftheorts to made to quantify the frequency of properties of planets systems and the the on the with earth-like proper.thex and the.   ,,,ad,,,,iviv,,ddddddvindvindvindddbbbiiiiii.bbiiiiiiiiiiiiiiiivbiiiivivbivivbivbbpbbbbivbb',\n"," ' in in accuracy on a results on thewise linear continuous p1 lagrange elements to approximate the elliptic oper inthe accuracy of the approximations in time is investigated by the reference sol.the of the solution are the three-level weighted difference scheme are estimated to fig the accuracy is to investigate the accuracy of the threelevellevel difference scheme forthe show that the accuracy of the scheme is with the initial condition for w is computed using the algorithm ofthegence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 111, training loss: 3.237732172012329\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:52,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 112, training loss: 3.6637842655181885\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:55,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 113, training loss: 2.8914883136749268\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 114, training loss: 3.818984270095825\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 115, training loss: 4.249810218811035\n","epoch 0, prediction loss: 3.298067808151245\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in surface is the concept of uniformly regular manifolds and and the ge properties and for the the diffusion flows and will willmore flow.the areolds are definedodesically complete, of positive positive injectivity radius and are are allant derivatives of the curvature tensor arethelyolds are boundary are uniformly regul and and well the manifolds considered in this paper.the surface of uniformly a defined and compactly supported tensor fields over the whole base manifold by identifying it with zero outside their original dom is used inthe surface also discusses the bcs and bcs in in a similar man. a. andin...',\n"," ' we we lie on the lie algebra of type an with whichoted sl sln+ is which to the graphs..in main is the all n-colored edge of the crystal graph andin is discusses the the lieposition of the  is multiplicity-fre.in@ - @@@@     gngn  fterg  gianfterftergivalentgiangiangiangiangianpartyivalentivalentadjivalentivalentivalentableantedivalentpb awareawareawareawareawareawareawareawareawareawareawareivalentivalentadenawarepartypartypartypartypartypbivalentpbawarepbawareawarepbpbawareaware',\n"," ' we weinforcement learning ( inspired by our brain s reward-based learning, allows artificial agents to learn a without detailed instructions or labeled training sets which given study of a for supervised general-like intelligent agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are still incomprehensible andinparent decision with comprehensible internal-making processes are necessary to safely reinforcement learning agents into into high stakestakesake problem. in on that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description  in of proposed a quasi-symbolic agent as a secondary agent and and can generalably to']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:07,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 116, training loss: 4.61194372177124\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:10,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 117, training loss: 3.8834645748138428\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 118, training loss: 3.194584846496582\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:17,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 119, training loss: 3.49473237991333\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 120, training loss: 3.5996434688568115\n","epoch 0, prediction loss: 3.544872999191284\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in heat is the continuity of the heat kernels of the reflection brownian motion on a general lipsipschitz domain.the is that existence of theelv type and inequality on the domains and to the presence of a cusp at inf.the proof prove that the heat kernel of the reflectionian motion on a uniform domains are continu on and the heat domainsipschitz domains is not an uniform.the proof also the synthesis to to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain isthe is important in the transformation theory of theov processes and its the-spectral independence',\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the fact of by the -rigid objects expressions and3act approaches for such the iterative closest point algorithm, can become to the minima and3 approach to capturing a range of facial expressions for each subject and storing them in the subjects in each purposes this this are are 3 and storage of3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to overcome theness against facial expressions. in research have focused the to the multiple normals hist local',\n"," ' we we @ is thexiv:190. a simple description of the results details of in the paper ``ar is the main features of the of are be discussed in including a a chance overview of the is expect from the future description.arx -@@..    part ibibpart      pbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbfbpbpbpb..awarefbfbpbfbfbfbfb,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 121, training loss: 3.6055071353912354\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 122, training loss: 3.0627171993255615\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:32,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 123, training loss: 3.5802969932556152\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 124, training loss: 3.771723508834839\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 125, training loss: 2.915938377380371\n","epoch 0, prediction loss: 2.8880598545074463\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study of auscule u with the to the weight uq-crystals.we min weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. wez and is@,,@gggggnivalentgngngngngngngggggadjvivalentivalentivalentpbpbivalentivalentggpbpbivalentivalentadjadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden',\n"," ' the the homogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the def problemd heterogeneous solid structure representing the mult model which on the finite element approximation ofthe numerical of are the the referenceogenized and the models are constructed inthe numerical of the homogenized model - performed in two steps  comparing the of deflections obtained by the numerical simulations ofthe firstogenized model andifies the problem by to the complexity of the finite element mesh complexity the number of theforating holes.the reference are implemented',\n"," ' abstract abstract tens on the concept of the of abstract u in which the on theq-crystals and a abstract on the e 7 dynkin diagram.the is the definition between regular and seminormal abstract crystals and abstract general abstractq-crystals.the tens is the definitionor product convention for the tens for the abstract crystal to be a as a uq-crystal. of a u uq-mod.the.. the,,,,,,,,,ad..adadadadadadadadad adadadad            ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 126, training loss: 3.2825727462768555\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 127, training loss: 3.615787982940674\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 128, training loss: 3.506284475326538\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 129, training loss: 3.730713129043579\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 130, training loss: 3.6263599395751953\n","epoch 0, prediction loss: 3.6899349689483643\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we importance of a the in the measurements into a bayesian hierarchical model into the for parameters into order context generation of occurrence fitt.we methodicity parameters derived here be in determining an eta earth measuremenwe the importance of neighboring planets could the long of an earth analog is a multiple sy is important.using importance also that a injection experiments to study the eff and to the effects in the eff.theining data from missions will it as ke and t tess,, will essential to a occurrence measure of as for the detection effiencies across  method presented here to incorporate these selection effects into producing a uniform population distribut.  method',\n"," ' we we distribution of the resultsolation of the populations parameters to longer periods ofwe is the the results of not differ greatly from those studies of that consistent with the results ofwe. with found between theman-mackey et recent to uses the a particular functional form for theol to using aussian process regression to determine the functions.weman-mackey et approach is a ter pipeline in to does reports the highest signal to to- noiseise candidate around each st.we ter also discusses the detection order can bias the and in leadingcounting small planets and long period and  results used by bur et a.@ used by the',\n"," ' we we paper is a aff answer to a question of theodge is andoremical weightram- ofwe is the weight of t for the is a eve for12 proof also the to prove to t twists of the hodge struct and the that l is unimodula.the proof is in a slightly weaker form of the theorem of a a construction of is arewise a primitive embedding and a hodge isometry on the transcendental lattice.the proof of v hodge is is2 new is the by the -k2.12, the weight of the ranks of h2 new and h2 givenoted by']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:02,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 131, training loss: 3.1071672439575195\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 132, training loss: 3.6037075519561768\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:09,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 133, training loss: 3.506049633026123\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.62s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 134, training loss: 3.852522373199463\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:16,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 135, training loss: 3.7587976455688477\n","epoch 0, prediction loss: 3.746089458465576\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[\" we we paper is a bounds for cal operators and harmonic analys andwe and and sparseness are two ingredients in make them bounds especially in quantitative norm inequ.in paper on sparse bounds for too andinars bounds for cal on - andymund operators are calizations domination principles are reviewed inin paper show a new sparse on means the main hypot of the it the weighted wq proper ''  result simpl the need for work with the grand maximal truncated operator mt which it sparse more convenient.the paper also also as five  the proof of the theorem theorem and some and and and and new t1-type result and and a\",\n"," ' in in aim of with the algorithm developed by us authors is a best candidate for creating a bigger image from small images, and theofcv can results to fit two images with better accuracy,after algorithm also that theofcv can results are be imp for the mapping because to the it,after algorithm concludes that the algorithm developed short of achieving goal of create the parking lot, and the in the stitching and the ar-drone.0 and0 also that the different version of the ar, even different drone with a 1080p camera to this image.the, the of with the ar were to the results stitching results.the algorithm',\n"," ' we we weured a weyl group of the we ofoted by w g by w0,wex s and@@@@ the the,,,inianivalentivalentivalentivalentinianinianivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentawareivalentababivalentivalentivalentivalentivalentivalentivalentivalentivalentthethethetheivalentivalentivalentivalentivalentivalentivalentivalent)=()=(ivalentivalent']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 136, training loss: 3.353672981262207\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:24,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 137, training loss: 3.0176897048950195\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:27,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 138, training loss: 3.6627399921417236\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 139, training loss: 3.582598924636841\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 140, training loss: 3.6513235569000244\n","epoch 0, prediction loss: 3.768033266067505\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ratio is the partial of partial and graded posets in the order theory.the chain is a poset in every pair of elements is compar and and a graded poset is a poset equipped a rank fun.the the chainet is not explicitly weighted, the weight is implicitly the counting meas.the this, har partial partial in the of order theory was obtained by one of ten ten ten outstanding results in the editor ofin-chief of the journal ofin are a a of a partial order, absolute order onthe....                 ',\n"," ' in in augmented of that to the our augmentation of in a data from a that less population in the dat isin aug of in and convstm layer on generate the pattern of directions and tcp windows sizes in the flo of and and the distribution functions ( pdfs )of every features and and points points in the feature dom and on the pdfs, and then a dat dat with the.in the number of packets in the generated sequence is less than 20, the rest of app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat and and a batch architecture and rel normalization lay and',\n"," ' we we well is a construction of uniformly well in for which the mean curvature and a and the applicationability to the hypersurfaces.we is the wellence of the notion of uniformly strongly elliptic and uniformly normally elliptic hypers the scalar case.we well -posedness result for the pro class is obtained for the methods about applications resultsms. including the importancearkinchitz continuity of the semiflow.the - -  ...adadad.adadad..ad...adabab)=(abababababab)=(bbpbpbpbpbpbpbpbpbpb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 141, training loss: 3.587130546569824\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:42,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 142, training loss: 3.7396790981292725\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:46,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 143, training loss: 3.9055984020233154\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:49,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 144, training loss: 3.2181804180145264\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:53,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 145, training loss: 3.2509100437164307\n","epoch 0, prediction loss: 4.316806316375732\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in error results to that performance of the proposed e -to -end e sy for diff diffusive environment like blood wherethe channel coding is considered forthe error probability performance analyzed as on the parameters and such location, and at and and symbol velocity ofthe analyzing the parameters, the performance error probability ( ber )per be improved.the trade-off between the conversion and channel rate time also between where the trade e -to-end ber e2e )berern performance when the the energy molecular channel ( dmc ) and errorstatic ( ec )..the the velocity and the minimum2e berery performance increased increased the',\n"," ' we we study of theinc s lie bundles and a are the to the lie algebroids andwe paper is been in applications with other fields problems onwe, it concept discusses the splitting of double vector bundles and37res - et@@@      adfterfter giangianfterfterftergiangianpbpbpbpbpbpbpbivalentivalentpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbababpbpbbybyawareivalentpbpbbybybybybybybybybybybybybybypbpbpbpbbypbpb',\n"," ' we we splitting of discusses on the splitting of double vector bundles in the context of the to the to the vector on including well in the paper...42x and and@@@@@pp   parenivalentivalent  ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentnoneivalentivalentivalentivalentawareivalentivalentawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentawareawareawareawareawareawareawareawarearticlearticleawareawareadenawareawarearticleawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:57,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 146, training loss: 3.227132558822632\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 147, training loss: 3.2369022369384766\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 148, training loss: 3.697208881378174\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 149, training loss: 4.0663909912109375\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 150, training loss: 3.5162570476531982\n","epoch 0, prediction loss: 4.234081745147705\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we current is the current of the matter ( d )@ density from using the thermalally averaged andaged annihilation annihilation cross- forwe current have the cross-averaged annihilation cross- for f operators candidates which compare the results to compute the cos density constraintsthey direct are such as dermil,abs, hess are are sensitive to the types candidates andweihilation cross sections for the types candidates are computed for the with le leptons and photons.the results also discusses the on theider experiments to the operators for the on theh and.  results is on the detection experiments which d particleselectron scattering delastic',\n"," ' in in main is a simple of theorem 1  using that simple of the theorem of in theorem a. we its between the proofs proofs, they complete proof is provided for reader andthe proof is a a common ingredient of both proofs and and a cases and and a a partition of obtain the desired result.the partition to a proof of a new 2-sparse family ofqj such  proof is shows the model on - onymund operator model. the cal version.  proof is with showing the similarmma to a the proof with theorem a ........    ',\n"," ' the the aim selection step is the engineeringgorithm ( ga )is to select thoseets of curves vectors extracted curves and spherical patches that are more against facial expression andthe modified vector is used to select select the most expression subs from remove the features.the using the value vector b the subs and patches are selected or omitted based depending removing the rates. removing the selection space the appro. fisher fisher s analysis. withthe algorithmgorithm is to in the non dimensionaldimensional binary high -convex optimization problem. and a high nsga-ii that elitism over the individuals non individuals..- ga assignments for the are are explained in section']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 151, training loss: 3.852799654006958\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 152, training loss: 3.854055643081665\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 153, training loss: 3.5490081310272217\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 154, training loss: 4.188357353210449\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 155, training loss: 3.7335124015808105\n","epoch 0, prediction loss: 3.292581796646118\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we continuity of the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  is provides the estimates for the densit surface that the surface measure on the domain is in the local kato class of the reflecting brownian mot.ar -                    ad     ad  ad   ad  adadadad             adenadenaden adenadenadenb            ',\n"," ' reinforcement reinforcementactionforcement learning ( are agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples here algorithms can however of learning as humans, can called as a for the a intelligence intelligence ( here advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for the tasks  to develop the applicability of reinforcement learning to we need of explainable and networks agbased reinforcement is imperative. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent, whose a rule as decision-m.thepirical evaluation of that for building a comprehens and comprehens agent using a method',\n"," \" we werillov-reshetikhin crystals k )cry are a dimensionaldimensional representations for affne lie algebras and by their drinfel'd polynomials k are mathematical such such as their of the q-system.we k for to determine a uniform model for k crystals in which are been achieved for br,1 by kashiwara s construction ofweaito and sagaki have constructed k construction brceptional affne br by lmibai-seshadri paths andwe crystals are a for the physics and have connected to mathematical k mathematics subject class 05e10,17b\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 156, training loss: 3.16739821434021\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 157, training loss: 3.5189449787139893\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:41,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 158, training loss: 3.2806904315948486\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 159, training loss: 3.1451144218444824\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:48,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 160, training loss: 3.32499098777771\n","epoch 0, prediction loss: 3.3814189434051514\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' tele tele time of the importance of the duration ratio ( emedicine communication for e communication delivery in nanomachin.the objective symbol slot partitioning ( a by the the user to-end symbol error rate (the optimization algorithm is formulated for find the best performance in e betweenthe optimization is a the symbol slot interval three of in types of communication link andthe achieve the quasiconvex feasibility problem, a quection optimization is formulated to on amc parameters and symbolr of the to the bis is a in the ec transmission side and does of and robust from low complexity complexity.the.....b',\n"," ' we we main on a results of to the closed dirichlet form on the bounded-chitz domain andwe using theorem of we closed of a byp main result is the paper is that existencehei matsuura theorem  which states that the regular closed of a continuous vers ofthech s              adggggggableggableableabableableableableableableableabeabeabababawareawareawareawareawareawareawareawareababivalentabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' we wealar-tensor theories have among alternatives to general relativity and have had a large impact on cosmology andsc theories commonly aar degrees of freedom in addition to the usual metric of general relativity, but to various phenomenology due to various coupling terms in their action.  two to choose the field variables while them the of the the j or or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form, the relationship of at generalize the analysis of the relationship between these two to theories that higher spin fields such vectors insteadwe main of on theories']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 161, training loss: 4.166506290435791\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 162, training loss: 3.6820895671844482\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:59,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 163, training loss: 3.79410457611084\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:03,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 0, batch 164, training loss: 3.2774152755737305\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:06,  3.68s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 3.6178803068218808\n","epoch {}'s average verification loss: {} 3.708667792379856\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 1/10 [10:31<1:34:40, 631.12s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 0, training loss: 3.642615556716919\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:04,  4.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 1, training loss: 3.754636764526367\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:08,  3.96s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 2, training loss: 3.7885212898254395\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:11,  3.76s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 3, training loss: 3.4600868225097656\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:15,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 4, training loss: 3.361621618270874\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:18,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 5, training loss: 3.421196699142456\n","epoch 1, prediction loss: 3.0697336196899414\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the theised features descriptors are used to the nasal region using the spherical in spherical ontheised from theabor wavelets filters are a featuresors and which to a dimensionality and reduced redundancy and and enableabilistic feature selection. reduce the to facial expressions while maintaining theinative part.the landmarks are used to define the keypoints in which sphericaling these of the nasal surface results spherical patchesors.the sphericalors are the use of the spherical on the nasal surface and when the selection selection andthe, theogonal planes toing with the nasal surface provide a on the evaluation evaluation.the.......',\n"," ' we we index on theasipinear inequalities with aity -ity in whereization the index j sub acritical and the sub inequality and satisfied and critical in the holds in case certain case.wex is is@     ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,ivalentivalentivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentabivalent.abababababababivalentivalentababababab,abivalentabababababab,abab',\n"," ' the the influence on a results of of the homogenized model of a perforated plate of the reissner-mindlin typ andthe results is to compare the responses of the homogenized plate model with the of the associated 3d elastic structure withtheations boundary conditions and loading functions are used to the homogenized model and where the aimd elastic represented by the plate model described as a 2d structure,the deflections are computed for the models using the d of the 3d elastic and usingiscale simulations of the plat modelthe influence of the compliance on the loss in the waveguide is discussed inthe second']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:23,  3.95s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 6, training loss: 4.089618682861328\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:26,  3.75s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 7, training loss: 3.1611149311065674\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:30,  3.67s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 8, training loss: 3.344703197479248\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:33,  3.62s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 9, training loss: 3.431105613708496\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:37,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 10, training loss: 2.7799880504608154\n","epoch 1, prediction loss: 4.03218412399292\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the aim project we to develop an image processing algorithm that the the university of bridgeport parking lot using using two images into with the drone device with a good camera  which the ar-drone  the main camera of the drone will the imagesapped images which which can then into the algorithm thatethecv and boofcv are were used to the processing and and thecv being java interface being a primary component ofboofcv is a-level image processing capabilities and bo low example processing algorithm for for whiching images the open goal goal ofthe stitching refers combining a 2d geometric transform which combine two images into and the such',\n"," ' in in isisms are on the category of for in networks by for andfulerryerson andinisms are the category are the-fulalkerson flows oninflows on a network is defined by a inequalities andinflow is a to minflowichai flowinperner s original on that min ranks are satisfy hall s condition are to min naturalperne -et.in and har introduced hall s matching cond by give rot. s conjecture by and the category matching condition and a normalized of the normalized flow property.in category flo is with theyclic vertex-weighted networks and and aisms preserving these morphisms preserving',\n"," ' we we effect of a detailed introduction of theson sld and a on the only of in the study of  also as a guide reference to the the features in thei sometry. the problems and x is is is is is is ispbigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,igen,,,,,,,,,,,pbibibib,pbpbibibpbpbpbpbibibpbibib,,,,ib,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:41,  3.90s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 11, training loss: 3.2464547157287598\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:45,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 12, training loss: 3.7760391235351562\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:48,  3.67s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 13, training loss: 3.2604269981384277\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:52,  3.62s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 14, training loss: 3.7531144618988037\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:55,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 15, training loss: 3.335022211074829\n","epoch 1, prediction loss: 3.280534029006958\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in aug of that to the our augmentation of in a data from a that less population in the dat isin aug of in and convstm layer on generate the pattern of directions and tcp windows sizes in the flo of and and the distribution functions ( pdfs )of every features and and points points in the feature dom and on the pdfs and and then a dat dat with the.in the number of packets in the generated sequence is less than 20, the rest of app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat and and a batch architecture and rel normalization lay and',\n"," ' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.the results is applied with a sampled and augmented datasets and and the results obtained that our proposed method performsforms thenn in terms of overall, recall, and f -.inx         ad   dddddddd ddddddddadddababadenababababababab..abababababababababababababababababababababbhbhababab',\n"," ' we we singular on the minimal domin1 theoremthe singular for which the minimal assumptionsity conditions on the singular t that which the singular holds underthe is that the proof on which minimal to not unknown what it about they theorem dini cond can be relaxed tothe section is the main assumptions on t k yielding yield thewise sparse domin.the proof are in results and the the numbermma for a of the of to the weak.the is with showing that the the bounded extension of t t is l2 to itself if then bounded condition on hold onthe -      g   ad     ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [01:00,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 16, training loss: 2.99857234954834\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:03,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 17, training loss: 3.698875904083252\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:07,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 18, training loss: 3.1822874546051025\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:10,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 19, training loss: 3.151700258255005\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:13,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 20, training loss: 3.4073586463928223\n","epoch 1, prediction loss: 3.6059792041778564\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we continuity of the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  is provides the estimates for the densit surface that the surface measure on the domain is in the local kato class of the reflecting brownian mot.ar - ...               ad    adad  ad   ad  adadadad             adenadenaden adenadenadenb            ',\n"," ' we we effective is the effective interactions of theermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the thermally averaged indirect indirect matter pair d )pair annihilation cross-section and the spin-independent d - with le and/or bound electron and and that with the data.  -..,,g ,                       bbbb bbbb  bbbb ',\n"," ' we we aim algorithm is for thecv is is the image processing technique sur to to image point detection and which well in her bay,sur is is a local feature detector and descriptor that by theift and but with a in details andsur main is a blob detector based on the heian matrix to find points of int and the heant of the heian matrix is usedized andthe determin is two from using blending the last image for performance and level detail detail and rendering in a single merging ofthe main image image is as the first to the algorithm followed the analysis. the drone moves forward.the...g   ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:18,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 21, training loss: 3.2416043281555176\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:21,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 22, training loss: 3.4277989864349365\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:25,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 23, training loss: 4.307178974151611\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:28,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 24, training loss: 3.4368326663970947\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:32,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 25, training loss: 3.3582260608673096\n","epoch 1, prediction loss: 3.7455594539642334\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we probability on a method of convergence theorem on the the monmma of using is the convergence of the pro of themma  and le to theorem condition in shown in the theorem bythe proof is a concept ft : the to themma 3. le proofotone convergence theorem forthe, the is the ex for the with respect to the probability measure p the with section with using the theoremms of lemmaps of thethe -.   bbb  awareaware ... ababivalentivalentabababababababbabababababpbpbpbpbpb',\n"," ' in in crystal result of in this paper is that multiplicity freereeness of the decom. this labeling labeling convent  which well by figure 2. in main7 crystals b are be decomposed into a le subalgebra of type a6 and a multiplicity freefree way. and by a computation. a the in using the and we loops to everyices in and adding the composition graph g, we is shown that the e b is type e is a multipl rule. the multipl m of x x inin proofposition is multipl shown by amma  and theabeling the fundamental weight. and leading in a multiplicity',\n"," ' we we number  the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity systems systems tothe using these function to we expected of that 0 fraction empirical multiplicity of be extrap by a function of selection effect.the best uses discusses the implications of this function to the the for the multipl and period forthe, the is the impact of this model of multiplicity in our solar system for theability claims finding that lack for a studies for support such claims...        dddddddddddd  ddddddabdd ddabab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:36,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 26, training loss: 3.81777024269104\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:40,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 27, training loss: 3.7504994869232178\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:43,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 28, training loss: 3.892153263092041\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:47,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 29, training loss: 3.7421939373016357\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:50,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 30, training loss: 3.6370863914489746\n","epoch 1, prediction loss: 3.5745670795440674\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the fact of by the -rigid objects expressions and3act approaches for such the iterative closest point algorithm, can become to the minima and3 approach to capturing a range of facial expressions for each subject and storing them with the subjects in each purposes but this are are 3 and storage of3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to overcome theness against facial expressions. in research have focused the to the multiple normals hist local',\n"," ' we we paper is a aff answer to a question of theodge is andoremical weight.- of12 is the weight of t for the is a eve for12 proof also the only prove to t twists of the hodge struct and the that l is unimodula.the proof is in based slightly weaker form of the theorem of a a construction of is arewise a primitive embedding and a hodge isometry on the transcendental lattice.the proof of v hodge is is2 new is the by the -k2.12, the weight of the ranks of h2 new and h2 givenoted by',\n"," ' in in : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional inthemedicine is which implementation of tele technologies to provide medical services is has a as a promising solution for address the needs.in is the communication communication sensing technologies to provide biological signals and medical them information to the providers.the of application of telemedicine is the delivery which which the focus on the therapy. control drugs information to the. minimizing the effects.the between a central role in the themedicine system between which the advances has to the-based molecular communication ( inner body and wireless (']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:55,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 31, training loss: 3.244098424911499\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:58,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 32, training loss: 3.240872383117676\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:02,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 33, training loss: 4.4804582595825195\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:05,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 34, training loss: 3.3173980712890625\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:09,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 35, training loss: 3.4774210453033447\n","epoch 1, prediction loss: 3.9359824657440186\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using thenating them key points between the and and then a robust fitting to to finding changes rotation. as rotation andthe, when we to stitch more result image with a third image, the will because the result will tries the black background as the image process.to happens is due by the that theofcv, so to a images. stitching more than two images usingto avoid this problem we open algorithm was implemented using openc, find this problem problem by theofcv. translation. to effects.thew..',\n"," ' we we j on the j of generalizations of spontaneousar- andensor theories where sts )based the j frame where where where the scalar field replaced with other fields and couplings can depend on derivative ofwe first for from the that spontaneous tensoriz where where are most naturally defined in the e frame wherewe are be applied to any generalization of on a conformal scaling of the metric in the matter action bywe first is the the scalar in a vector or the-tensor theories obtained vector to the-based spontaneous scalarization arewezing the j of interesting time derivative terms in no renders order and equations',\n"," ' we we keism we by this paper is applied to infer the occurrence rate parameters for planets orbiting gk dwarf stars based  from the final ke release dr25 and including planet radius measurements from theks and ga,, and corrected detection eff for multiple-planet systems are used in  resulting includes on the poisson process likelihood function used includes a bayesian framework to using anmsthe resulting are that values for the occurrence of including a at the best fitfit model at at p times ofthe novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:13,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 36, training loss: 3.8989832401275635\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:17,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 37, training loss: 3.2352046966552734\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:20,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 38, training loss: 3.4768099784851074\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:24,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 39, training loss: 2.9967856407165527\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:27,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 40, training loss: 3.5940897464752197\n","epoch 1, prediction loss: 4.102721214294434\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke presents the effects of a new of represent the ke eff of the ke survey forwe grid is created into 100,000 regions in period and radius spac andthe region is then in in log space for period and radius spac all each are assigned m based on the order ofwe probability probability of are the for detecting multipleoplanets in each detection ofwe probability of repeated for each of in the detection order grids andthe probability probability maps for the effects of limbity and limb the new function for account mis mis transits withinthepreating between made to determine the probabilities for multiple detection order.the eff are created using m multipl',\n"," ' we we we on the - and algebra of the weil algebra with 16 55 and2z......ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentbivalentivalentivalentivalentawareivalentivalentabawareawareawareawareabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalentthethetheawareivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent',\n"," ' we we search of a results of a ensemblene affinvariant ensemble sampl to explore the from towe bayesian framework is linear space uniform priors is used towe toors are used for the r ofbr and pbr of on the fraction sample.we casc prior for that f must must be larger than f parameter avoid trunc andwe resulting is is for larger multiplicity systems to be more common than smaller multipl.we -  the                      adadadadbbbadbadbbbbb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:32,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 41, training loss: 3.5511391162872314\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:35,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 42, training loss: 3.2667744159698486\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:39,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 43, training loss: 3.208606719970703\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:42,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 44, training loss: 4.006411552429199\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:46,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 45, training loss: 3.5106706619262695\n","epoch 1, prediction loss: 4.222011566162109\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in comb on theing the.- from the comb of the of the ofin using the certain approachinatorial approach of we comb theorem for for proved to provepose the into i0,2-crystals accordinginz - -@.     gngngngngngngngngngngngngdgdgdgdgdadjvivalentadjgdadjpbadjadjgiangianpbpbadenadenadjadjadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden',\n"," ' to to ability is the applications of thes agents to are secondary to evaluate a agents from r agents andq agents are evaluate used in specific-specific problems andwe from of such as state multiple rewards and of state rewards, can be used to evaluate r- andtheizing the actual of state- can on the such coordinates and velocities can be the performance of qs agents.ls agents can also multiple matching and value networks to evaluate agents values of andq proposed between p brain cortex and pfc ) hippocampus and and anterior cingulate cortex ( discussed for the andp p also that one of of q q cing',\n"," ' we we paper presents the concept of a  - andbgebrabrir and with the single of and which is of a two structure of a two of the associated aled.the structureorphism of the structuregebroid are determined and and the importance for the the dynamics structure of the structure bundle structure x -@@.igenigenigenigenigenigenigenigenigenigenigenigenigenibibibibiiiiii    ibiiifbfbfbfbfbfbfbfb.,fb,fbfbfbfbfbfbfbfbfbfb,,,,,,,,  ,,fb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:50,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 46, training loss: 3.5315866470336914\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:53,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 47, training loss: 2.9073758125305176\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:57,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 48, training loss: 3.258493423461914\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [03:00,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 49, training loss: 3.596126079559326\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:04,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 50, training loss: 3.1025328636169434\n","epoch 1, prediction loss: 3.6104319095611572\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in s of that sn is the normalized matching property which which that sn is indeed sperne sin is a by the example on on the normalized case is trivia as. the baseive step is the theutations from the copies of sn to the collapsing the n of we new network is constructed which be the normalized matching cond. which to the conclusion that sn is indeed sperner. well satisfies normalized normalized flow property.inch.                  iiiadenadenadenadenabababbbbiiibabpbadenbpbpbpbpb',\n"," ' we we point is of improved version of the pointwise sparse domination principle established by the first author inthe allows allows us the singular singular assumptions on for a singular integral operator to admit a sparse domin.thex.        gn                  vv vv          iii    adenaden aden    aware   awareaware aware adenadenadenadenawareawareawareaware  aden   aden   aware ',\n"," ' we we this paper we we boundary is the boundary of boundary boundary value problem for the fractional power of the power power withthe is the boundary to solvingimating the boundary by the finite of finite finite element method.thex boundary boundary@@        gn                fbfbfbfbfbpbfbfbpbfbfbfbfbfbfbfbfbfbfbawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:09,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 51, training loss: 3.866281509399414\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:12,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 52, training loss: 3.6089301109313965\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:15,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 53, training loss: 3.4469611644744873\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:19,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 54, training loss: 3.452941656112671\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:22,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 55, training loss: 3.366333484649658\n","epoch 1, prediction loss: 3.5358145236968994\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in transparent of transparents agents to transparent transparent r agent which which two operating units, matching and value network. with two are q agentss agents to actions suggested suggested choose the most probable cho based using for a to reach states by the env model whichthe suggest that q proposed q has the of to its simple inner and transparent. selecting selection.  proposed of the nodes and nodes from q manual analysis modification of q s without  property makes the the the weights of synaptic states of which the improvement of improvement avoidance. ......bb   b         ',\n"," ' we we this paper of of wes and is q )@ interact with r learning ( r ) agents and make model env ) agents in learn future actions.qs three are constructed using thetorch, an open-source machine learning toolkit.qsx - -. ( (adadadadadibibibadgdgdgdgdgdgdgdb..gdgdgdbbgdgdgdbbibib.ibibadenadenadenaden.ibibib...awareawareibibawareabadenadenadenadenawareawareawareawareawarebiiiawareawareadenadenibibibawareaware',\n"," ' in in first presents the thestation fractional power elliptic operator problems numerically using using equivalent local nonstationary initial value pseudo-parabolic problem the such were the implicit backward and symmetrical euler method for while the paper proposes to the fourth-parameter family of three-level finite difference schemes forthe fourth-order approximation scheme is developed by optimal optimal weight paramizationthe resultsical analysis and are supplemented by extensive computational experiments. -- - ,                bbbbbbbbbbbbbbbb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:27,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 56, training loss: 3.581179141998291\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:30,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 57, training loss: 3.392522096633911\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:34,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 58, training loss: 3.3582568168640137\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:37,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 59, training loss: 3.290311574935913\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:41,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 60, training loss: 2.8901190757751465\n","epoch 1, prediction loss: 3.698007822036743\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we boundary on the boundarydimensional haddorffme on the to the the the boundary local time of the ofthe le also the naotoaka kajino for his comments on the proof of lema.he. - -........gadadadadadgadad.gggad.....ad....adad..adadbad...adenaden.....awareaware..awareaware..awareadenadenadenadenadentheadenadenadenawarebadenadenawareadenadenbbadenawareaware',\n"," ' in inrones are getting being in the fields fields such the such google, facebook, amaz amaz, their own drone technology.drones are used in a journalism so obtain videos of areas toto -access areas anddcopter are which quad of quad, four rotorors, are one used in and the ofors working clockwise and two other two spin counterclockclockwise  balance that ofdrones are be autonomously based on a-entered program without and without with a resolutionresolution cameras and image processing and computer vision techniques. in, a of when a or or satellite-captured satellite maps are not.in paper',\n"," ' it it s is the s of the electrodynamics theory under theity transformation and considering on the drangian invari involving the the theion and dilaton fields intoit is the sance of the equations under equations of motion and energy-momentum tensor under the-duality transformationit extensionsetries of transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the existence of of theitudes involving the-duality transformationwe isves into the s of the involving equationsitudes under the-duality transformation and and the role of the of the-duality']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:45,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 61, training loss: 3.470205783843994\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:49,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 62, training loss: 3.3961737155914307\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:52,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 63, training loss: 3.4891316890716553\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:56,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 64, training loss: 3.745224952697754\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:59,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 65, training loss: 3.5805742740631104\n","epoch 1, prediction loss: 3.7654027938842773\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in point of a but/ extensions of the theorem theorem of namely on the point precise version of pointwise sparse domination 7.1 main of this theorem result is the original theorem is that and and some is used how it result can used in a applicationsorems and1 proof also discusses some possibility to the theorem to a multilinear cas and and the the results obtained1essary and in the proof are pointed out. and the the original of of the theorem theorem.1...       iiiiii                ab ',\n"," ' we weac s2obi - are a models that are the a theoryac equations with a externalic function of of form a set set of with a information.@ structures are called in the context of the equations and are be used to the physical models. the of theolds and x latt@@..igenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenibibibnoneibib,,,none,,nonefbnonefbfbfbfbfb..,,,fbfb,,,fb,,,,,,,,,,,, ,,,',\n"," ' we we sensitivity presents the sensitivity of the constraints on the matter pair d )production at including on the bound to the of the momentum of d pair atom and/-electron scattering at to the of thearks inon is the need of theizing dpto- andic and electro boson b2-linic d particles at the proposed hadron coll ( lh ) and the the need of the the- to the-2 operators inon analysis is discusseszes the state effects of d -atom scattering and dama data and derive the the pair production channels at the proposed linear coll ( ilc )  analytical have the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:04,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 66, training loss: 3.190260648727417\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:07,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 67, training loss: 3.338935136795044\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:11,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 68, training loss: 3.305555820465088\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:14,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 69, training loss: 2.7700109481811523\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:18,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 70, training loss: 2.6806867122650146\n","epoch 1, prediction loss: 3.1595230102539062\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in works have been recurrent learning architectures or address network flows in however of have shown on the of in order and however others have focused the to as convesian neural networks or convabilistic graphical models to semi-supervised learning in in in been been done in the neural neural networks to however,stm networks to to solve time data in but the flow data in in aim of a approachmentation scheme for generating time data in network traffic trace g tcp the contribution that in the results used in generating cases and numer data aug.the used as recurrent augetermination andimation and kd ) and used to generating new data and the recurrent -',\n"," ' we weface diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space thethe surface velocity of evolving surfaces is determined by purely geometric quant  while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, we paper considers uniformly regular hypersurfaces and which non -compac surfaces.we using the study of uniformly larger class of manifolds, we surface presented to the study research of geometric flows on non -compact manifolds.we study relies based by the theory of continuous maximal',\n"," ' we weorem on theic surfaces3 surfaces of ch ch with chow motives of surfaces andwe is a proofposition of theow motives of surfacesic surfaces into aic and transcendental components and and by a comput and computations.the proofogenical decomposition of theelian varieties with group action is also in and to a is of the case example inthe proof is with a discussion on the specific example in a k of k algebraic k3 partner of a k between kers surfaces and k resolutions of which the importanceogenism between kental surfaces of1.......  addad ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:22,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 71, training loss: 3.588944435119629\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:25,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 72, training loss: 3.3981118202209473\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:29,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 73, training loss: 2.7853810787200928\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:32,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 74, training loss: 3.734570026397705\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:36,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 75, training loss: 3.6298654079437256\n","epoch 1, prediction loss: 3.673269033432007\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke presents the modeling soft the from the keomult soft soft extract the ke population of determine constraints from  key modeling presented each of planets according on the parameters and and the randomly to of detection accordingthe probability parameters the population parameters with is that weak in the radius population around which due by a unique population planet and population population.the -planet systems are also and comparison analysis and and that population dependence.the forward model is from ouresian analysis is compared and and that in the parameters due uncertainty due duethe best parametersiates between multiple and and and and single-planet systems and and the implications further studies of planet period and radius',\n"," ' in in aim results a model is three different datasets is that our method of sampling in able in im thebalanced datasets andthe results that to precision1 measure, precision andrec recall measurethe performance is performance on compared with sampling in and the in precision and in to the false predictions predictions andthe overall accuracy of the model is also than sampling in with a improvement in precision and recall and and confusion accuracy.  model is that accuracyiz and accuracy decrease in false negative due to the in. x.....  ddddddddddddddddddddddddddddddddddddddabab',\n"," ' we we effects is the effects of mutual inclination on the k k forwe effects recovery study was not account for mutual multiplicity planet and thus there not account the incl effects here planets were injected with a impact parameters from study the effects parameter mutual inclination on detection eff. here effects was at the effect in impact parameters for recovered planet systems with known planet andthearger mutual inclinations can cause certain planets to ge avoid transit compleometrically complethex  the....,  b..b..  iii   bbhehehehebhehehehehehebhebb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:41,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 76, training loss: 2.985509157180786\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:44,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 77, training loss: 3.0998518466949463\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 78, training loss: 3.018995761871338\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:51,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 79, training loss: 3.498910903930664\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 80, training loss: 3.875619649887085\n","epoch 1, prediction loss: 3.476426362991333\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we effects presents on the multipl in multipl the parameters parameters from theoseismic data fromwe inclusion of the updates allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat andwe of also from the curves and thus periods effect on the data cks data. we positives are removed using the thes to thus the planets with 500 days are considered. be contamination from we -icity effects are explored by a all the within in we a of on the and period cut. we with multiple positives are artificially removed to the order   inclusion detection multiplicity we in a',\n"," ' we we ke presents the bayesian method to to estimate population parameters for the ke sampleoplanet sample with a bay using using upon the bay we extract information about the multiplicit and comple a best replication of the empirical popul multiplwe studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters using with the from a provided a bay andwe study is that with the with prior bay using and at the case of planets radius planets down to the threshold.we usingorously treating completeness mapping and a',\n"," ' we we eccentric of the eccentricity into our model system is increase the detection efficiencywe is theiallyity models for including the modified gamma distribution used to a beta distribution usedwe from that significant differences between theity between the and multi-planet systems, the same & mur eccentric,we, using the the eccentricities reveals significant betweenwe bias is theity occurrence using as multi-planet systems producing more low eccentricity detections than  analysis suggest that differences between the empirical of ation of detection eff is important when determiningity occurrence measurement   evidence for needed to determine if there populationsity populations exist between the and multi-planet systems.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:59,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 81, training loss: 3.346083879470825\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 82, training loss: 3.870251178741455\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:06,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 83, training loss: 3.365169048309326\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:09,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 84, training loss: 3.0183417797088623\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:13,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 85, training loss: 3.2630252838134766\n","epoch 1, prediction loss: 3.343982219696045\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this advanced of tele care applications, high communication links between crucial for the end-toendend telemedicine sy with in delivery, molecular communication play two building the-nano-medical applications  in paper presents the e-toendend e link consisting electromagnetic electromagnetic and molecular communication for  closed-form expression for presented for the e error probability ( the e system link an optimization problem is formulated with minimize the e error rate of the the optimal symbol duration for the time from from numerical proposed is solved by an iterative algorithm based on the bisection met.numerical results show that the proposed method ob ob',\n"," ' in in study of in this paper is more 70 gigabytes of real traces traffic from am campus of amirkabir university of technology and which of more and tcp link fromweows are labeled using n n sourcesource dpi tool n nd and and which the classes of applications from from more 50 gigabytes of packets from which more.,000 instances werethe percent of these flows were used for training and while the rest are test datthe dataset was 90 total of applications classes and including more classes of more than thanthe imbalance is a imbalance feature with more 83 percent of the dataset consisting only 4 cl ofindpi is the',\n"," ' we weooth compact hypersurfaces without boundary are in rm1mathrmz+}--}1}$gam$ be viewed into are(shypersurfac if\\\\ are have a tubular neighborhood of see are tub of this equival is provided inwe, there only b \\\\m-+1}^{)+ below the grap 1 b ))so that gr 1 ))has has a tubular neighborhood. radius. 1 )). is a -rt-hypersurfac.\\\\, there all smooth uniformly regular hypersurfaces are aRT-hypersurfaces. there instance, there of']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 86, training loss: 3.720303773880005\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:21,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 87, training loss: 3.222445011138916\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:24,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 88, training loss: 2.5991146564483643\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:28,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 89, training loss: 3.040971517562866\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:31,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 90, training loss: 3.4169952869415283\n","epoch 1, prediction loss: 3.622424602508545\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study of theinc s lie bundles and a are the to the lie algebroids andwe paper is been in applications with other fields problems onwe, it concept discusses the splitting of double vector bundles and37res - et@.@      adadfter giangiangianftergiangiangianpbpbpbpbpbpbpbivalentivalentpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbpbabababawarepbbybyawareivalentivalentpbbybybybybybybybybybybybybybybyabbypbbybypb',\n"," ' tele tele time of the importance of time duration ratio ( emedicine communication for e communication delivery in nanomachin viathe objective symbol slot partitioning ( a by the the userto-end symbol error rate (the optimization algorithm is formulated for find the best performance in e betweenthe optimization is a the symbol slot interval three of in types of communication link andthe achieve the quasiconvex feasibility problem, a quection optimization is formulated to on amc parameters and symbolr of the to the bis is a in the ec transmission side and does of and robust from low complexity complexity.the......b',\n"," ' in in concept presents the -to-end communication error rate ( computing the types links of such the molecular communication channel model and a diffusive environment and a and relay and and receiver nodes inthe of the molecules is assumed by a maximum-a-posterior probability rule and the the transmitted distribution function is computedimated by sim s rul.the thispersmbol interference is ignored in the the of left to future work.to error error performance ( ( also in the on- and and off-body communication channel. the the of the such the, motion ofthe-norm distribution off assumed to the best fitting distribution these-body communication']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:36,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 91, training loss: 3.228286027908325\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:39,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 92, training loss: 3.4687016010284424\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:43,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 93, training loss: 3.6787431240081787\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:46,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 94, training loss: 3.2505087852478027\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:50,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 95, training loss: 3.3008830547332764\n","epoch 1, prediction loss: 4.253985404968262\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke mission has increased our understanding of the around sun-like stars withthe final data release dr dr25, provides all on to the failure of two reaction wheel on providing the end end of the primary phase oftheorts are made to quantify the frequency of properties of planets systems and the the on the with earth-like proper.thex the the.....,,,,,,,,iviv,,ddddddvindddvinddd).....bbbiiibiiiivivbivivivbivivbivbbivbbbivbb',\n"," ' we we wellured the well -posedness properties for the wellard - on which on the workorems on the of to the regular surfaces andthe proof is from to as in the previous proof ofthex and and@@               ivalentivalent  ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent ivalentawareaware  ivalentawareivalentawareawareivalentivalentivalentivalentivalentawareabawareawareivalentivalentivalentawareawareivalentawarepbpbivalentawareaware',\n"," ' we we t is the tford-tate and t conjectures for surfaces fib of namely on the cycles- surfaces ofwe mainford-tate conjecture of v with whichoted by g, g, is the using detail to theic cycles and the overthe t also a of to theelian motives and theodge ms and that existenceelian nature of the fib andthe textford-tate conjecture for also for the certain fib of the alese variety, and a to the thodge conjecture and the class mapthe....      abababad   habhab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:54,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 96, training loss: 3.5955991744995117\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:58,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 97, training loss: 3.963035821914673\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [06:01,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 98, training loss: 3.0235893726348877\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:05,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 99, training loss: 3.1881372928619385\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:08,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 100, training loss: 3.050135612487793\n","epoch 1, prediction loss: 3.023829221725464\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' abstract abstract concept on the concept of the of abstract u in which the on theq-crystals and a abstract on the e 7 dynkin diagram.the is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals withthe tens is the definitionor product convention for the tens for the abstract crystal to be a as a uq-crystal. of a u uq-mod.the....,,,,,,,,,.......adadadadad adadadadv           ',\n"," ' we wealar-tensor theories have among alternatives to general relativity and have had a large impact on cosmology andsc theories commonly aar degrees of freedom in addition to the usual metric of general relativity and but to various phenomenology due to various coupling terms in their action.  two to choose the field variables while them the of the the j or or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form, the relationship of at generalize the analysis of the relationship between these two to theories that higher spin fields such vectors insteadwe main of on theories',\n"," ' we we study is auscule u with the to the weight uq-crystals.we min weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. thez and is@.,.gggggnivalentgngngngngngg......ivalentivalent..ivalentivalentivalentggivalentivalentivalentivalent..adenadenadenadenadenadenadenadenadenadenaden.adenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:13,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 101, training loss: 4.354245185852051\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:16,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 102, training loss: 3.0580949783325195\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:19,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 103, training loss: 3.508481025695801\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:23,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 104, training loss: 2.8241379261016846\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:26,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 105, training loss: 3.1177494525909424\n","epoch 1, prediction loss: 3.252814531326294\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[\" in in paper is a bounds for cal operators and harmonic analys andwe and and sparseness are two ingredients in make them bounds especially in quantitative norm inequ. in paper on sparse bounds for too andinars bounds for cal on- andymund operators are calizations domination principles are reviewed inin paper show a proof proof on means the main hypot of the them the weighted wq proper ''  result simpl the need for work with the grand maximal truncated operator mt which it sparse more convenient.the paper also also as five  the proof of the theorem theorem and the and and and and new t1-type result and and a\",\n"," ' we we well is a construction of uniformly well in for which the mean curvature and a and the applicationability to the hypersurfaces.we is the wellence between the notion of uniformly strongly elliptic and uniformly normally elliptic hypers the scalar case andwe well -posedness result for the pro class is obtained for the methods about results resultsms. including the importancearkinchitz continuity of the semiflow.the. -......adadad,adadad..adabababababab)=(ababababababbbababababbhbbabbhbh',\n"," ' we we ke of the effects for incompleteness due the planet occurrence rates due to transit multiplicity inwe ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data and  distribution also the statistics that affect the radius and period distributions of each detection ord and  results rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog.  results model is consistent with the studies but now includes an improved estimate of the multiplicity distribut and  average also']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:31,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 106, training loss: 3.3418617248535156\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:34,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 107, training loss: 4.109323024749756\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:38,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 108, training loss: 3.150174140930176\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 109, training loss: 4.120977878570557\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:45,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 110, training loss: 3.766773223876953\n","epoch 1, prediction loss: 3.9351022243499756\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we author on the results in to the theory dir subsetets and andichlet form and andotone class argument and andity and and domain and and and eigenfunction and and and and dini s theorem.the words are the thatity of the dirichlet form and the convergence of themma 1. proof of to the results.the section is includes the authorification theorem of the pn t. l. the convergenceiteness of the*.......                          ',\n"," ' we we type on the the type e6 crystal decomposition into using the and adding loops at everyices of the the composition graph gwe example decom r is an as an i0,7-highest weight ele in the sectionposition..we@ - notation....,,,,gnivalentivalentadadgngngngian.gdgianivalentivalentivalentivalentivalentivalentivalentivalentivalentgiangianivalentivalentivalentivalentadjivalentivalentadenadenadenadenadenadenadenadenawareawareawareawareawareivalentawareawareabadenadenadenadenadenadenadenawareawareadenivalentawareawareadenadenawareawareadenawareaware',\n"," ' the the datasetsd face are used to evaluate the new recognition algorithm proposed thegc,bosphorus and and bu-3de. the firstgc dataset is 5 with 5 sets expressions and and the bosphorus dataset contains samples of six prototypic expressions andthe b is performanceing accuracy and accuracy are evaluated using and that accuracy for thegc than to the samples andthe robustors were inabor wavelets and g g scale, for each recognition are,the results was a accuracy rates for the b al and the samples and and aness for the-neutral samples and probes. isons results of the algorithms is also for showing']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:49,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 111, training loss: 3.0467679500579834\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:53,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 112, training loss: 3.3840315341949463\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:56,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 113, training loss: 2.965735912322998\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [07:00,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 114, training loss: 3.159323215484619\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:03,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 115, training loss: 3.3413233757019043\n","epoch 1, prediction loss: 3.1506905555725098\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the differenceauchy problem method is a to solving solution solving solvingolving of the on the auxiliary pseudo-time evolutionary problem forthe a priori estimates are be obtained for solve numer problem. the the prior implicit two-level euler scheme the the for5 difference scheme is unconditionally stable with the initial dat for using these estimates recursively we  validity of the difference is proved.5im....,,,,,,,,adadadadadad..ad...adababababababababababb)=(ababababbbababab',\n"," ' in in e of with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is conducted toin closed-form expression for the e error probability of concatenation of molecular two channels was derived andthe optimization problem was at minimize the e error probability of conc system was formulated to determine the symbol durations for both molecular of communication.the reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication. -..                      dd  ',\n"," ' we we main on a results on to the closed dirichlet form on the bounded-chitz domain andwe using theorem of  closed is a byp main result is the paper is that existencehei matsuura theorem  which states that the regular closed of a continuous vers ofpch theorem...    g    gadggggggableggableableabableableableableableableableabeabeabababawareawareawareawareawareawareawareawareababivalentabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:08,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 116, training loss: 3.2391440868377686\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:11,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 117, training loss: 3.591991901397705\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:15,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 118, training loss: 3.246220350265503\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:18,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 119, training loss: 2.596451997756958\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:22,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 120, training loss: 3.9792070388793945\n","epoch 1, prediction loss: 3.3483474254608154\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we weinstein of are transit transit study of to properties of the populations fromusing key function is used for the bayesian theorem theorem and extract the parameters fromusing method distribution is modeled as a independent power -law distributions in period and rad.using distribution that a single planetary population is made by assuming the distribution of this assumption is examined usingusing distribution is on multiple systems with thezes the effect effects introduced the and multipl distributionsusing distribution used to on previous studies to including planets by detection order andusing results show evidence on the factors detection order and show distribution parameters for this introduced the distribution distribution fun ( to this.using statistics are discussed to to',\n"," ' christ christ detection is the the eff can be calculated for as considering artificial planet signals into the christ pixels of the field stars andwe doing the light light curves with the standard detection pip, the recovery fraction can be assessed using producing a probability function based on transit mes probabilityto-noise ratios. pr )  christ of detection order on recover is discussed and and the order defined by the variable m. here christ from split into injection with and after the days and and well 200 time the distributions begin significantly.we is made on the with 2 or discovered...ggggggggggbg',\n"," \" we werillov-reshetikhin crystals k )cry are a dimensionaldimensional representations for affne lie algebras and by their drinfel'd polynomials k are mathematical such such as their of the q-system andwe k for to determine a uniform model for k crystals using which are been achieved for br,1 by kashiwara s construction ofweaito and sagaki have constructed k construction brceptional affne br using lmibai-seshadri paths andwe crystals are a for the physic and have connected to mathematical k mathematics subject class 05e10 subject17b\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:26,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 121, training loss: 3.0669331550598145\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:30,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 122, training loss: 3.561664342880249\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:33,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 123, training loss: 2.7917699813842773\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:37,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 124, training loss: 3.0040526390075684\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:40,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 125, training loss: 3.4329588413238525\n","epoch 1, prediction loss: 3.087176561355591\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the thefaces diffusion and willmore flows are two for uniformlyurfaces parameterized over a uniformly regular reference manifold with uniform tubular neighborhood withthe the are in a fourth-order quasilinear parabolic equation with non singular structures satisfying the formlinear terms satisfyingthech and and and..                           able ableableableableable        awareable  abababab)=(abababab)=()=()=(awareawareawareawareawareaware)=(awareaware',\n"," ' the the acoustic on the method analysis which the the acoustic acoustic pressure and the displacements and and rotation in a limit lay ofthe is is based for understanding understanding - and equations of vib vibroacoustic problem imposedthe convergenceymptotic analysis is based using the unfolding method which which developed for the seminal paper by elaborated elaborated further thin structures inthex....g ggg              ad     . .  iii)=()=()=()=()=()=(,,)=(,iii,,,iiipbpb)=(,,',\n"," ' deep deep learning ( ability to high stakestakes decision problemsmaking is a challenging for it influence may uncertain and extensive test anditing deep learning agents to high high may lead in critical failures, in methods have been proposed to analyze the internal mechanisms of deep learning agents and to their performance-making process. however these studies have focused on feedability of feedforward deep learning, we studies focused the issue of more learning ( well. in majority-hoc interpretability of deep learning agents has be used to predict and prevent potential and but it their is the learning agents is a agents. in potential approach to to provide the in reinforcement learning agents by']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:45,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 126, training loss: 2.9217591285705566\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:48,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 127, training loss: 3.5127012729644775\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:52,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 128, training loss: 2.751607656478882\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:55,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 129, training loss: 3.0939016342163086\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:59,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 130, training loss: 3.332304000854492\n","epoch 1, prediction loss: 3.026447057723999\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the en is ( the contextured the en and modeling into state vector s action a inputs and the the next state andthe this text we we network layer of a nodes is used to the env network tothe is shown using the squared error recurrent each episode of random learning (. a ensemble learning rate of 0.0. -........adad.bbbddbbadbddadadadadaddaddaddaddaddadadadad..ad..adadbb}\\\\ad}\\\\bbbb.biiibbhbhbhbhbhiiibhbh',\n"," ' we we q of a new of the invisible qcd axion model without domain wall and with the heavy heavy heavy are present inthe is is first in the contextxiv pre19002..3.. the 2015st2019.  - et....      gngngn         ad adadfbbbbbbbadbbbadadbadfbabadadbfbabaware..awareawarefbfbawarefbababawareawareawareawareaware...,,,,.bb,..',\n"," ' in in paper presents a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation periodthe layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization based basedthe numericalaging procedure based to a of outer acoustic field with the-layer variables whichtheumerical examples illustrate the validityogenization model and accuracy and with the numerical simulations of@ research on at design the of compliantforated plates in vibroacoustic trans problems@ paper of supported by the grants grants funded ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:03,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 131, training loss: 2.745115041732788\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:07,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 132, training loss: 3.2553749084472656\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:10,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 133, training loss: 3.009094476699829\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:14,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 134, training loss: 3.6931629180908203\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:17,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 135, training loss: 2.8281588554382324\n","epoch 1, prediction loss: 2.9575767517089844\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in surface is the concept of uniformly regular manifolds and and the ge properties and for the the diffusion flows and will willmore flow.in areolds are definedodesically complete, of positive positive injectivity radius and are are allant derivatives of the curvature tensor arethelyolds are boundary are uniformly regular and and well the manifolds considered in this text.the surfaceally uniformly a defined tens compactly supported tensor fields over the whole base manifold by identifying it with zero outside their original dom is used inthe surface also discusses the bcs and bcs. in a similar man in a. andin...',\n"," ' the the homogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing the mult model derived on the finite element approximation ofthe model of are the the referenceogenized and the models are constructed inthe response of the homogenized model - performed in two steps  comparing the of deflections obtained by the numerical simulations of1 firstogenized model isifies the problem by to the complexity of the fe element mesh complexity the number of perforating holes andthe reference are implemented',\n"," ' in in goal we to use the drone to camera to take images images from a parking parking lot and blend them to create a large large image  the entire parking.to different were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to first was images images during certain points intervals so create the merging ofto this field test, we drone lot was divided into a 4x4 matrix so better the drone s movement and andthe goal was taking images at the and then them images together each column and and then merging them columns together afterthe']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:22,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 136, training loss: 3.2459018230438232\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:25,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 137, training loss: 3.3527653217315674\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:28,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 138, training loss: 3.1559646129608154\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:32,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 139, training loss: 3.5349295139312744\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 140, training loss: 3.422070026397705\n","epoch 1, prediction loss: 3.2111315727233887\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the vib presents the vib of modelling and vibration reduction in the design of the in the industry civil engineering.the is on the the wave propagation through periodicallyating perforated plates immersed where the related respect modelling of to the geometrical ofthe vib presents a modelling to theogenization to derive nonlocallocal vibro-acoustic transmission conditions for the per designed with an inviscid fluid inthe method is us modelling reduction modelling modelling of takes information details about the need of disc discretization atthe approach is a new approach for modelling theroporous panels which providesates the proposedogenization re of direct numerical simulations.the',\n"," ' the the convergence is the of for on the priori estimates for the a. based convergence provides convergence convergence of the unfolded function in the2 andthe to the convergenceation of the limit vibro-acoustic problem in a formal approach which the sequences constructed with the convergence res.basedch -.                                      aware  awareawareawareawareawareawarebb,awarebbb,,,,b,,awareaware,,,',\n"," ' we we aim presents the classification of irregular which by theodge theory and al by the which irregular3 type with product modental part.we are the related the t of the surfaces and their a answers to the questions related certain conditions.the main also the the classification of these surfaces is not not and that the state state of the art up  also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac.  results obtained can used to prove that t and mumford-tate conjectures for these surfaces.  proof also the support of inspiration and provide a overview of the current state']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:40,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 141, training loss: 3.3430144786834717\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:43,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 142, training loss: 3.7616026401519775\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 143, training loss: 3.47942852973938\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 144, training loss: 2.7706847190856934\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 145, training loss: 3.447340726852417\n","epoch 1, prediction loss: 2.9660027027130127\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the high is the theoretical of the order difference schemes for solving thestationary cauchy typetype ellipt for to theal power elliptic problems withthe order approximations are used to approximate the time dependence of the solution while while the elliptic operator is approximated by the finite element sche.the. stability conditions are given for the-level discrete schemes with weight weight parameter andthe order accuracy is proved for the symmetrical crankank-nicelsonson type sche andthe family of three-level symmetrical discrete schemes is constructed and investigated  the on the smooth solution.the condition on the first time level are computed by the',\n"," ' the the proposed space method the filteredured based on the surface normal methodthe proposed feature isises thelets overlap and redundancy in the images andthe is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations ando the frequency component set andthe proposedization for the scale and are computed into a block matrix and the analysis.thex - the..,,,,adad,,adbaddd.ad...........ab)=(dddddd)=()=()=(bb)=(b)=(bbababbbbb.',\n"," ' using using importance is a the in the measurements into a bayesian hierarchical model into the for parameters into order context generation of occurrence fitt methodswe methodicity parameters derived here be in determining an eta earth measuremenas the importance of neighboring planets could the long of an earth analog is a multiple sy is important.using importance also that a injection experiments to study the eff across understanding the effects in the eff.theining data from missions will it as ke and t tess, will will essential to understanding occurrence measure of as for the detection effiencies across  method described here to incorporate these selection effects into producing a uniform population distribut.  method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:58,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 146, training loss: 3.1053802967071533\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 147, training loss: 3.5679149627685547\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:05,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 148, training loss: 3.740520477294922\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:09,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 149, training loss: 3.077317476272583\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:12,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 150, training loss: 3.2814671993255615\n","epoch 1, prediction loss: 2.9071056842803955\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the this present, wem isat theoryversal are considered and a new model for describes a crucial role in the the understanding the systems.the systemsversals are a framework tool for studying the such the thelectic and nonyphlectic effects are involved.@ using the structuresversals as  can able to study insight insights into the nature of dynamics between the systems. and it useful useful resource for the areas fields and modeling. x.......    .   iiiiiiiiiiii,.,,         ,,',\n"," ' the the hom on the the homogenized vibroacoustic transmission model derived the p `` be used for numerical simulation of acoustic waves using the two -scale in.the numerical of is to to the one considered the paper of where the zero neumann condition appl a same acoustic fluid and the solid are.the numericalscopic responses are computed in compared in fi of illustrate the model.the-....,  ,     bb, ....dd   )=()=(dd)=(bbbbbb bb bbb b ',\n"," ' quasi quasi agent-critic model is a to a reference r agent to order paper tothe structure of quasi quasi-symbolic agent q matching and value networks, which single layer and network,entially connected thatthe matching network memorizes input vectors by imprinting normalized inputs to synaptic weights converthe value of matching nodes is identical to the number of value nodes and and the-to-one mapping between matching.the the new node is added to the matching network, a new node is also to the value network, keep one one between the strength between between these is determined by the reward induced by r selected agent withthe gradient of matching']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 151, training loss: 2.616596221923828\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 152, training loss: 2.8988122940063477\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:24,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 153, training loss: 3.1189730167388916\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 154, training loss: 3.1293885707855225\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:31,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 155, training loss: 3.3203251361846924\n","epoch 1, prediction loss: 2.973496675491333\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' let let weured a conceptyl group of the certain ofoted by w g by w0.wex is and... the the,,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentaware..abivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentab,ivalent,ivalent,,,ivalentivalentivalent)=(,ivalent',\n"," ' the the potential presents the potential of the patches and curves for expression expressiond face recognition in  novel five-step algorith is presented and based with coarsely of the nose tip location segmenting and alignmenting the face and and thenpping the nasal region.  very anding algorithm is seven key points on the nasal reg andthe genetic algorithm-based feature selector is the patches and curves over different facial expressions.  algorithm provides the ranks ranks on the datasets and requiring alignment or denoising steps. is with when only one sample per subject per the gallery and and does not require a training step for theing.1....',\n"," ' reinforcement reinforcementactionforcement learning ( allow agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples here algorithms can however of learning as humans, can called as a for the a intelligence intelligence ( to advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for reinforcement tasks  to develop the applicability of reinforcement learning to it need of explainable and networks agbased reinforcement is crucial. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent whose whose simple rule as decision-making.thepirical evaluation of that for building a comprehens and comprehens agent using a method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 156, training loss: 3.5136539936065674\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:39,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 157, training loss: 3.708202362060547\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 158, training loss: 3.0702321529388428\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 159, training loss: 2.897831678390503\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:49,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 160, training loss: 3.295187473297119\n","epoch 1, prediction loss: 3.5810749530792236\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' * * *aic - is a method to to calculatingson solds to which are used of which with a top that@ is the the equations of a basis of obtain the and to the results.@x is is, (gpbpbpbpbpbigenpbpbpbpbpbpbpbigenigenigenigenigen,,,,,,fbfbfb,fbfbfbfbfbfbpbpbfbfbfbfbfbfb,,,,fbfb,,,fbfb,,,,,,,,,,,,,,fb',\n"," ' in in order difference-level difference difference scheme are constructed in this paper they stability condition for the of the scheme iswoted by w,,is to be computed with some symm levellevel numerical algorithm and the same accuracy as of main scheme wwemmetrical scheme are the with the order accur  suff smooth solutions.we conditions for derived for the symm-level scheme and the that stability with respect to the dat the high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy.we the schemes can be constructed to this condition w they restrictions are that using for',\n"," ' we we is on the the of obtain the is component of a a refined isomorphism between the6 decomposition ofthe is a a isomorphism of for to theu-de-taquin s@res is is and@@@     adadadadadadad vadadgvvadvivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentableableivalentableawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawarebyawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:54,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 161, training loss: 3.568966865539551\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 162, training loss: 3.1859731674194336\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [10:00,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 163, training loss: 2.996776819229126\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:04,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 1, batch 164, training loss: 3.8355743885040283\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:07,  3.68s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 3.3657593568166098\n","epoch {}'s average verification loss: {} 3.472791761159897\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [20:43<1:22:43, 620.39s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 0, training loss: 2.938019275665283\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.33s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 1, training loss: 3.3791110515594482\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:06,  3.43s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 2, training loss: 3.284071683883667\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.46s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 3, training loss: 3.114030599594116\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:13,  3.48s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 4, training loss: 3.251610517501831\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.48s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 5, training loss: 3.427691698074341\n","epoch 2, prediction loss: 3.649585485458374\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' tele tele time of the importance of time duration ratio ( emedicine communications for e communication delivery in nanomachin viathe objective symbol slot partitioning ( a by the the user to-end symbol error rate (the optimization algorithm is formulated for find the best performance in e betweenthe optimization is a the symbol slot interval three of in types of communication link andthe achieve the quasiconvex feasibility problem, a quection optimization is formulated to on amc parameters and symbolr of the to the bis is a in the ec transmission side and does of and robust from low complexity complexity.the.......',\n"," ' using using importance describes a the in the measurements into a bayesian hierarchical model into the for parameters into order context generation of occurrence fitt methodswe methodicity parameters derived here be in determining an eta earth measuremenas the importance of neighboring planets could the long of an earth analog is a multiple sy is important.using importance also that a injection experiments to study the eff across understanding the effects in the eff.theining data from missions will it as ke and t tess, will will essential to understanding occurrence measure of as for the detection effiencies across  method described here to incorporate these selection effects into producing a uniform population distribut.  method',\n"," \" in in paper presents a bounds for cal operators and harmonic analys andweization and sparseness are two ingredients in make them bounds especially in quantitative norm inequ. in paper on sparse bounds for too andinars bounds for cal on- andymund operators are calizations domination principles are reviewed inin paper show a proof proof on means the main hypot of the them the weighted wq proper ''  result simpl the need for work with the grand maximal truncated operator mt which it sparse more convenient andthe paper also also as five  the proof of the theorem theorem and the and and and and new t1-type result and and a\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:21,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 6, training loss: 3.3301355838775635\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 7, training loss: 2.9842381477355957\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 8, training loss: 2.8487861156463623\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 9, training loss: 3.532170295715332\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 10, training loss: 3.2892489433288574\n","epoch 2, prediction loss: 3.9552085399627686\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the impact discusses thely interacting dark matter ( ( their interactions with their are be motivated from various and indirect detection experiments apartthe u physics extensions of standard standard model ( sm )and been proposed to provide the matter candidates d ) candidates or whose as uly interactingacting dark (ons ( wimps )  detection experiments have shrunk the parameter space of the models where theimps to with the visible world viathe constrained of sm particles sm model particles are encaps in the lagrangian approach where where the of the dimensional lore operators constructedthestrained on the higher are then from the data and const the the u models where in sensitivity',\n"," ' we we current presents the current of the matter ( d )ther density from using the thermalally averaged andaged annihilation annihilation cross- forwe current have the cross-averaged annihilation cross- for f types candidates including compare the results to compute the cos density constraintsthey direct are such as dermil,abs, hess are are sensitive to the types candidates andweihilation cross- for various types candidates are computed using pair with le leptons and photons usingthe results also discusses the on theider experiments to these operators for the on theh and.  results is on the detection experiments which d particleselectron scattering delastic',\n"," ' the the en is is the contextured the en and modeling into state vector s action a inputs and the the next state andthe this text we we network layer of a nodes is used to the env network tothe is shown using the squared error recurrent each episode of random learning (. a ensemble learning rate of 0.0. -........adad..bbddbbadbddadadadadaddaddaddaddaddadadadad..ad...adbb}\\\\ad}\\\\bbbb.biiibbhbhbhbhbhiiibhbh']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 11, training loss: 2.6659433841705322\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 12, training loss: 3.0038607120513916\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 13, training loss: 3.5233967304229736\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 14, training loss: 3.333570718765259\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 15, training loss: 3.6500091552734375\n","epoch 2, prediction loss: 3.176872730255127\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposesthe is the importance of the 3 for surface features for expression robust andust recognition and includinging previous work that providing very discrim of discriminant strength andthe proposed is a landmarking and feature extraction techniques to multi-resolution gabor wavelets tothe isforms previous approachesd nose recognition algorithms by achieves that performance compared with recent that the whole facial dom the, the proposed is a such as improved denoising and and fast pose pose correct algorithmsthe features are achieved in the text of theing and feature extraction and and',\n"," ' in in aim results a model is three different datasets shows that our method of sampling in able in im thebalanced datasets andthe results that to precision1 measure, precision andrec recall measurethe performance is performance on compared with sampling in and the in precision and in to the false predictions predictions andthe overall accuracy of the model is also than sampling in with a improvement in precision and recall and and confusion accuracy.  model is that accuracyiz accuracy accuracy decrease in false negative due to the in. x...... ddddddddddddddddddddddddddddddddddddddabab',\n"," ' we we effects is the effects of mutual inclination on the k mode forwe effects recovery study was not account for mutual multiplicity planet and thus there not account the incl effects here planets were injected with a impact parameters from study the effects parameter mutual inclination on detection eff. here effects was at the effect in impact parameters for recovered planet systems with known planet andthearger mutual inclinations can cause certain planets to ge avoid transit compleometrically completo. the.....,........  ,..bhehehe.bhehehehehehebhebb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:58,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 16, training loss: 3.2802560329437256\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 17, training loss: 3.733048915863037\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 18, training loss: 3.155207395553589\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 19, training loss: 3.4112071990966797\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 20, training loss: 2.5361714363098145\n","epoch 2, prediction loss: 3.488826036453247\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.in results was applied with a sampled and augmented datasets and and compared results obtained that our proposed approach performsforms thenn in terms of overall, recall, and f -.inx.....    ad   dddddddd.dddddddd.ddababababab.ababab...abababababababababababababababababababababbhbhababab',\n"," ' we we aim algorithm is for thecv is is the image processing technique sur to to image point detection and which well in her bay,sur is is a local feature detector and descriptor that by theift and but with a in details andsur main is a blob detector based on the heian matrix to find points of int and the heant of the heian matrix is usedized andsur determin is two from using blending the last image for performance and level detail detail and rendering in a single merging ofthe main image image is as the input to the algorithm followed the analysis and the drone moves forward.the.......',\n"," ' in in aug of that to the our augmentation of in a data from a that less population in the dat isin aug of in and convstm layer on generate the pattern of directions and windows windows sizes in the flo of and and the distribution functions ( pdfs )of every features using and points points in each feature dom and on the pdfs and and generating a dat dat with the.in the number of points in the generated sequence is less than 20, the rest of app with arrays arrays points if convolutional recurrent neural network was trained trained on the augmented dat to and a batch architecture and rel normalization lay and']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 21, training loss: 3.136406421661377\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 22, training loss: 3.4018361568450928\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:24,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 23, training loss: 3.3852202892303467\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 24, training loss: 2.6905598640441895\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:31,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 25, training loss: 2.7322680950164795\n","epoch 2, prediction loss: 3.0860931873321533\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study is a concept of ant antichain a a pos connected set and aet )p no two elements are compar andanx and et@@@@     iii         ivalentivalentivalentfamfam.famfam..fam..adenaden....aden...adenadenadenadenivalentivalentivalentadenadenivalentadenadenadenadenadenadenadenadenadenadenawareawareadenadenadenawareawareawareawareadenawareawareawareawareadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden',\n"," ' the the this context, wem isat theoryversal are considered and a new model for describes a crucial role in the the understanding the systems withthe systemsversals are a framework tool for studying the such the thelectic and nonyphlectic effects are involved.@ using the structuresversals as  can able to study insight insights into the nature of dynamics between the systems. and them useful useful resource for the areas fields and modeling. x.......   ...  iiiiiiiiiiii,.,,   ,   ,,,',\n"," ' in in goal we to use the drone to camera to take images images from a parking parking lot and blend them to create a large large image  the entire parking.to different were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to first was images images during certain points intervals so create the merging ofto this field test, we drone lot was divided into a 4x4 matrix so better the drone s movement and andthe goal was taking images at different and then them images together each column and and then merging them columns together afterto']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 26, training loss: 3.609945297241211\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 27, training loss: 3.394016981124878\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 28, training loss: 3.6855151653289795\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:46,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 29, training loss: 3.3983871936798096\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 30, training loss: 3.12288498878479\n","epoch 2, prediction loss: 3.2220382690429688\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in error results to that performance of the proposed e -to-end e sy for diff diffusive environment like blood wherethe channel coding is considered forthe error probability performance analyzed as on the parameters like such location and and at and and symbol velocity ofthe analyzing the parameters, the performance error probability ( ber )per be improved bythe trade-off between the conversion and channel rate time also between where the trade e -to-end ber e2e )berern performance when the the energy molecular channel ( dmc ) and errorstatic ( ec ). (in the velocity can the minimum2e berery performance increased increased the',\n"," ' we we we is the weence of doubleb-algebroid structures on d double lie algebroid and horizontal or vertical differentials on two of the threeil algebras and a well as ger gerstenhaber bracket on the th wear is discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras andar....                     ..',\n"," ' we we point is are improved version of the pointwise sparse domination principle established by the first author inthe allows allows us determining singular singular assumptions on for a singular integral operator to admit a sparse domin.ar....       gn                ..vvv........       adenadenawareaware   awareaware   awareawareawareawareawareawareadenadenawareawareaware,,. adenaware,,aden ,, ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:54,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 31, training loss: 2.718766212463379\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 32, training loss: 4.092751979827881\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:00,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 33, training loss: 3.548182249069214\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 34, training loss: 3.108792304992676\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 35, training loss: 3.3930203914642334\n","epoch 2, prediction loss: 2.694249153137207\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we diffusion of the relation of the in the presence of the diffusion flows in and the theore 2. for for the process of flow and well asthe. and.....@,,fterfterfterfterantingadad  ivalentivalent adjadjadjadjadjadjadjadjadjadjadj....pb.....ivalentivalentpbpbpbivalentivalent..abababab...abivalentawareivalent..abab......ababababababababababababababababababababababab',\n"," ' quasi quasi agent-critic model is a to a reference r agent to order paper tothe structure of quasi quasi-symbolic agent q matching and value networks, which single layer and networks,entially connected thatthe matching network memorizes input vectors by imprinting normalized inputs to synaptic weights converthe value of matching nodes is identical to the number of value nodes and and the-to-one mapping between matching.the the new node is added to the matching network, a new node is added to the value network, keep one one between the strength between between these is determined by the reward induced by r selected agent withthe gradient of matching',\n"," ' in in this advanced of tele care applications, high communication links between crucial for the end-toendend telemedicine sy with in delivery, molecular communication play two building the-nano-medical applications  in paper presents the e-toendend e link consisting electromagnetic electromagnetic and molecular communication for  closed-form expression for presented for the e error probability ( the e system system based optimization problem is formulated with minimize the e error rate of the the optimal symbol duration for the time from from numerical proposed is solved by an iterative algorithm based on the bisection met.numerical results show that the proposed method ob ob']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 36, training loss: 3.035606861114502\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 37, training loss: 2.7177951335906982\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 38, training loss: 2.99770188331604\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 39, training loss: 3.6353888511657715\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 40, training loss: 2.7203972339630127\n","epoch 2, prediction loss: 3.2308878898620605\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we weooth compact hypersurfaces without boundary are in rm1mathrmz+}--}1}$gam$ be viewed into are(shypersurfac if\\\\ are have a tubular neighborhood of see are tub of this equival is provided inwe, there same b \\\\m-+1}^{)+ below the grap 1 b ))so that gr 1 ))has has a tubular neighborhood. radius. 1 )). is a -rt-hypersurfac. this, there all smooth uniformly regular hypersurfaces are aRT-hypersurfaces. there instance, there of',\n"," ' the thefaces diffusion and willmore flows are two for uniformlyurfaces parameterized over uniformly uniformly regular reference manifold possessing uniform tubular neighborhood withthe the are in a fourth-order quasilinear parabolic equation with non singular structures satisfying the formlinear terms satisfyingthech and and...                     able able   ableableableableableableable.. .......abababababababababab)=()=()=(awareawareawareawareawareaware)=(aware,',\n"," ' we we t is the tford-tate and t conjectures for surfaces fib of namely on the cycles- surfaces ofwe mainford-tate conjecture is v with whichoted by g, g, is the using detail to theic cycles and the overthe t also a of to theelian motives and theodge ms and that existenceelian nature of the fib andthe textford-tate conjecture for also for the certain fib of the alese variety and and a to the thodge conjecture and the class mapthe.......  ababababab   habhab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 41, training loss: 2.9586174488067627\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 42, training loss: 2.99275279045105\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 43, training loss: 2.598252773284912\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 44, training loss: 3.6541879177093506\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 45, training loss: 3.016232490539551\n","epoch 2, prediction loss: 3.4643325805664062\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in traffic is a for the ever amount that in withifying the traces and applicationsifying applications is two tasks in with traffic tracingifications ( nts ) have classify anomalies in classify applications for however they methods are shown in the on ports in lack reasons. their ofingorithms in n classification classification have great in they solutions for however thebalanced datasets is networks networksscale networks networks a challenging for deep due f and and inmentation is are machine learning are which as artificial artificial data for are be these imbalance issuesin novel methodmentation method is k dataensity andimation and kde )and litudinalestTerm memory ( lst',\n"," ' we we search of a results of a ensemblene affinvariant ensemble sampl to explore the from towe bayesian framework is linear space uniform priors is used towe toors are used for the r ofbr and pbr to on the distribution sample samplewe casc prior for that f must must be larger than f parameter avoid trunc andwe resulting is is for larger multiplicity systems to be more common than smaller multipl.- -..                     adadadadadbbbadbadbbbbb',\n"," ' in inrones are getting being in the fields fields such the such google, facebook, amaz amaz. their own drone technology suchdrones are used in various journalism so obtain videos of areas toto -access areas anddcopter are which quad of quad that four rotorors, are one used in and the ofors working clockwise and two other two spin counterclockclockwise  balance that ofdrones are be autonomously based on a-entered program without and without with a resolutionresolution video and image processing and computer vision techniques. in, such of when a or or satellite-captured satellite maps are not.in paper']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 46, training loss: 3.279911756515503\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 47, training loss: 3.0298359394073486\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:56,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 48, training loss: 2.9243011474609375\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 49, training loss: 3.4823765754699707\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:03,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 50, training loss: 3.1220948696136475\n","epoch 2, prediction loss: 3.2278659343719482\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the vib presents the vib of modelling and vibration reduction in the design of the in the industry civil engineering.the is on the the wave propagation through periodicallyating perforated plates immersed where the related respect modelling of to the geometrical ofthe vib presents a modelling to theogenization to derive nonlocallocal vibro-acoustic transmission conditions for the per designed with an inviscid fluid inthe method is us modelling reduction modelling modelling of takes information details about need need of disc discretization atthe approach is a new approach for modelling theroporous panels which providesates the proposedogenization re using direct numerical simulations.the',\n"," ' we we boundary on the boundarydimensional haddorffme on the to the the the boundary local time of the ofthe section also the naotoaka kajino for his comments on the proof of lema.he...........gadad.adadgad...........ad..........b............aware......awareadenadenadenadenadenadenadenadenaware..awareaware.adenbbadenaware.',\n"," ' we we new method for determining the frequency of exoplanet multiplicity within the ke dat is presented and using method isizes over mutual inclination and the empirical ke period set to determine the probabilities for multiple-planet systems containing using isifies the of multipl containing up to 7 planets and and is important for fitting multiplicity parameters via m that mm or weumptions made made that the equ of planet radius and period and but eccentric orbits are assumed to be circular in using method is that eccentricity can theicity occurrence by slightly the expected number of planets around each planet by using model of this method model is that may a reasonable description of the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 51, training loss: 3.3289520740509033\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 52, training loss: 2.701129674911499\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 53, training loss: 3.625166416168213\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:17,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 54, training loss: 3.1505284309387207\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 55, training loss: 2.8173506259918213\n","epoch 2, prediction loss: 3.697770118713379\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the aim of with the algorithm developed by us authors is a best candidate for creating a bigger image from small images using and theofcv can results to fit two images with better accuracy,after algorithm also the theofcv can results are be imp for the mapping because to the it,after algorithm concludes the the algorithm developed short of achieving goal of create the parking lot and and the in the stitching and the ar-drone.0.0 also that the different version of the ar, even different camera with a 1080p camera to this image.the, the of with the ar were to the results stitching results.the text',\n"," ' in inorem on theic surfaces3 surfaces of ch ch to chow motives of surfaces and1 is a proofposition of theow motives of surfacesic surfaces into aic and transcendental components and and by a comput and computations.it proofogenical decomposition of theelian varieties with group action is also in and to a is of the case example in1 proof is with a discussion on the specific example in a k of a algebraic k3 partner of a minimal between kers surfaces and k resolutions of which the importanceogenism between kental surfaces of1............',\n"," ' the the r of the behaviorogeneousization phase of with the with surfaces on the role structure of theaus inthe equations are the types such as the properties and the size and determine a descriptions for the the understanding the behavior in the systems.thex -@@@.,,,,fbivalentivalentivalentivalentivalent ivalentivalent.......fb........fbfb....fbfbfbfb...fbfb.....,fbfbfb,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:26,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 56, training loss: 3.781514883041382\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 57, training loss: 3.5255444049835205\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 58, training loss: 2.8501033782958984\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 59, training loss: 3.614103317260742\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 60, training loss: 3.0788938999176025\n","epoch 2, prediction loss: 3.060049533843994\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the potential presents the potential of the patches and curves for expression expressiond face recognition in  novel five-step algorithm is presented and based with coarsely of the nose tip location segmenting and alignmenting the face and and thenpping the nasal region to  very anding algorithm is seven key points on the nasal reg andthe genetic algorithm-based feature selector is the patches and curves over different facial expressions.  algorithm provides the ranks ranks on the datasets such requiring alignment or denoising steps and is with when only one sample per subject per the gallery and and does not require a training step for theing.1....',\n"," ' in in splitting is the splitting theoremorems of json pairs and j proposed by dazord, lichnerowicz and and marle inas new point is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.ar...........     . ...ad anted...adantedanted...abab....... partyadenadenadenababababawareawareawareawareaware',\n"," \" we werillov-reshetikhin modules k )cry are a dimensionaldimensional representations for affne lie algebras and by their drinfel'd polynomials k are mathematical such such as their of the q-system andwe k for to determine a uniform model for k crystals using which are been achieved for br,1 by kashiwara s construction ofweaito and sagaki have constructed k construction brceptional affne br using lmibai-seshadri paths andwe crystals are also for the physic and have connected to mathematical k mathematics subject class 05e10,17b\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 61, training loss: 2.951202869415283\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 62, training loss: 2.6360902786254883\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 63, training loss: 3.3469038009643555\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 64, training loss: 3.281157970428467\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 65, training loss: 2.6931934356689453\n","epoch 2, prediction loss: 3.8092870712280273\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' christ christ christ discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars andwe doing the light light curves with the standard detection pip, the recovery fraction can be assessed using producing a probability function based on transit mes probability to-noise ratios. pr )  christ of detection order on recover is discussed and and the order defined by the variable m. here christ from split into injection with and after the days and and well 200 time the distributions begin significantly.here is made on the with 2 or discovered. the...gggggggggb.',\n"," ' let let weured a conceptyl group of the certain ofoted by w.g by w0.wex is and...,,,,,,,ivalent,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentaware..ab.ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,,,ivalent,,,ivalentivalent,,,,',\n"," ' double double study of theinc s lie bundles and a are the to the lie algebroids andwe paper is been in applications with other fields systems onwe, it concept discusses the splitting of double vector bundles into37res et et...      adad  giangiangian giangiangiangianpbpbpbpbfbfbivalentivalentivalentpbpbivalentpbpbpbpbpbpbpbpbivalentababivalentabpbpbabababaware.awareabawareivalentivalentawarebybybybybybybybyabbybybybybyababbypbbyabab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 66, training loss: 2.8294503688812256\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:06,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 67, training loss: 2.8482882976531982\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 68, training loss: 3.7073657512664795\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:13,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 69, training loss: 3.1034469604492188\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 70, training loss: 2.7368998527526855\n","epoch 2, prediction loss: 3.240000009536743\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we effects discusses on the multipl effects multipl the parameters parameters from theoseismic data fromwe study of new updates allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat andwe of also from the curves and thus periods need on the data cks data. when positives are removed using the thes to thus the planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in we a of on the and period cut. we with multiple positives are artificially removed to accuracy order in  inclusion detection multiplicity we in 7',\n"," ' the the vib discusses the homogenization of thero-acoustic transmission on perforated plates andhom is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inthe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withthe homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation pericitythe nonlocal implicit implicit transmission conditions involve a',\n"," ' we we ke presents the impact of a new of represent the ke eff of the ke survey forwe grid is created into 100,000 regions in period and radius spac andthe region is then in in log space for period and radius spac all each are assigned m based on the order of for probability order is are the for detecting multipleoplanets within each detection withinwe probability of repeated for each of in the detection order grids andthe probability probability maps for the effects of limbity and limb the new function for account mis mis transits withinthepreating between made to determine the probabilities for multiple detection order andthe eff are created using m multipl']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 71, training loss: 3.4967775344848633\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 72, training loss: 3.1872010231018066\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 73, training loss: 3.2100422382354736\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 74, training loss: 2.7105884552001953\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 75, training loss: 3.5698680877685547\n","epoch 2, prediction loss: 3.4411160945892334\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in one presents the thestation fractional power elliptic operator problems numerically using using equivalent local nonstationary initial value pseudo-parabolic problem forthe such were the implicit backward and symmetrical euler method for while the paper proposes to the fourth-parameter family of three-level finite difference schemes forthe fourth-order approximation scheme is developed by optimal optimal weight paramizationthe resultsical analysis and are supplemented by extensive computational experiments.......,               bbbb.bbbbbbbbbbb',\n"," ' we we author on the results in to the theory dir subsetets and andichlet form and andotone class argument and andity and and domain and and and eigenfunction and and and and dini s theorem.the words are the thatity of the dirichlet form and the convergence of themma 1. proof of to le results.the section is includes the authorification theorem of the pn t. l. the convergenceiteness of the*.........       ..            ',\n"," ' in in internet presents the long learning on packets in classify flow traffic patterns order imbalanced environment andhas is a novel augmentation approach based longstm network for generating flow patterns and and kernel density estimation for replicating the features ofthe results is to improve the with which those network with less popul ofthe of all datasets demonstrates that performance of precision of precision, recall and and f1 measure for every classes classes.......adadbbadbbbadddddddddddddddddddddddddddababbbbbbbababbbbabbb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 76, training loss: 2.9968953132629395\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:42,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 77, training loss: 4.303195953369141\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 78, training loss: 3.275712013244629\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 79, training loss: 3.6389191150665283\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 80, training loss: 3.0582668781280518\n","epoch 2, prediction loss: 3.1611313819885254\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using using eccentric discusses the eccentricity into our model system is increase the detection efficiencywe is the eccentricity models for including the modified gamma distribution used to a beta distribution usedwe from that significant differences between theity between the planet multi-planet systems when the same & mur eccentric  however, using the the eccentricities reveals significant betweenwe bias is theity occurrence using leading multi-planet systems producing more low eccentricity detections than  analysis suggest that differences between the empirical of ation of detection eff is important when determiningity occurrence measurement due  evidence for needed to determine if there populationsity populations exist between the and multi-planet systems.',\n"," ' the the high is the method of the order difference schemes for solving thestationary cauchy typetype ellipt for to theal power elliptic problems withthe order approximations are used to approximate the time dependence of the solution while while the elliptic operator is approximated by the finite element sche.the. stability conditions are given for the-level discrete schemes with weight weight parameter andthe order accuracy is proved for the symmetrical crankank-nicelsonson type sche andthe family of three-level symmetrical discrete schemes is constructed and investigated. the on the smooth solution.the condition on the first time level are computed by the',\n"," ' the the proposed space method the filteredured based on the surface normal methodthe proposed feature isises thelets overlap and redundancy in the images andthe is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations ando the frequency component set.the proposedization for the scale and are computed into a block matrix and the analysis.thex....,,,,ad,,,.................abab)=(dddd)=()=()=(bb.b)=(babababbbbb.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:57,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 81, training loss: 3.4162492752075195\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 82, training loss: 3.0453696250915527\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 83, training loss: 3.3020341396331787\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 84, training loss: 2.7218713760375977\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 85, training loss: 2.666019916534424\n","epoch 2, prediction loss: 3.418949842453003\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study is auscule u with the to the weight uq-crystals andwe. weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. thez and is....,,,ggnivalentgngn..gng.......ivalent....ivalentivalent..ivalentivalentivalent....adenadenadenadenadenadenadenadenaden..adenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenaden',\n"," ' we we main on a results on to the closed dirichlet form on the bounded-chitz domain andwe using theorem of  closed is a byp main result is the section is that existencehei matsuura theorem on which states that the regular closed of a continuous vers ofpch........ g   ggadgggggableableablegableableabableableableableableableableabeabeabababawareawareawareawareawareawareawareawareababivalentabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' transition transition continuity of the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  also provides the estimates for the transitionit surface that the surface measure on the domain is in the local kato class of the reflecting brownian mot.ar--......             adad. adad..adad  ad. adad...  ad... .adenadenaden  ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 86, training loss: 2.596740484237671\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 87, training loss: 3.259450674057007\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 88, training loss: 2.890272617340088\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 89, training loss: 2.930875062942505\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 90, training loss: 3.277595281600952\n","epoch 2, prediction loss: 2.925567388534546\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the hom on the the homogenized vibroacoustic transmission model derived the p `` be used for numerical simulation of acoustic waves using the two-scale in.the numerical is is to to the one considered the paper of where the zero neumann condition appl a same acoustic fluid and the solid are.the numericalscopic responses are computed in compared in fi of illustrate the model.the.....,,,,,,,   bb.,........ dddddd)=(bbbb.b bv bbb..',\n"," ' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with a bay using using upon previous bay we extract information about the multiplicit and comple a best replication of the empirical popul multiplwe studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters using with the from a provided a bay andwe study is that with the with previous bay using with at the case of small radius planets down to the threshold.we usingorously treating completeness mapping and a',\n"," ' we we vib is the application vib of vibro-oustic response in inwe problem is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofwe coupling is on the the acoustic field in the layer with the surrounding en and the a coupling equation whichwe conditions are the global problem are provided. and are the to the limit on the limit limit forthe.....,,..,.ad   ad............abab)=(,abbbbbbbbbabababbbabab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 91, training loss: 2.7810122966766357\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:38,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 92, training loss: 3.2986369132995605\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 93, training loss: 3.0537261962890625\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 94, training loss: 3.0702500343322754\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 95, training loss: 3.028482675552368\n","epoch 2, prediction loss: 2.9497218132019043\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' well well wellured the well -posedness properties for the wellard - equation the on the workorems on the of to the regular surfaces andthe proof involves from to as in the previous proof ofthex and....              ivalentivalent ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentawareaware..ivalentawareivalentawareawareivalentivalentivalentivalentivalentawareawareawareawareivalentivalentivalentawareawareivalentawareawareawareivalentawareaware',\n"," ' the the vibogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model derived on the finite element approximation ofthe model of are the the referenceogenized and the models are constructed inthe response of the homogenized model - performed in two steps  comparing the of deflections obtained by the numerical simulations of1 firstogenized model isifies the problem by to the fe of the fe element mesh complexity increasing number of perforating holes andthe reference are implemented',\n"," ' the the acoustic discusses the method analysis which the the acoustic acoustic pressure and the displacements and and rotation in a limit lay ofthe is is based for understanding understanding - and equations of vib vibroacoustic problem imposedthe convergenceymptotic analysis is based using the unfolding method which which developed for the seminal paper by elaborated elaborated further thin structures inthex......gggg             ad.  .......,,)=(,,,,,,,,,,,,iii,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 96, training loss: 3.564971685409546\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 97, training loss: 2.8996188640594482\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [05:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 98, training loss: 3.4381728172302246\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 99, training loss: 3.3300282955169678\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:06,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 100, training loss: 2.6265106201171875\n","epoch 2, prediction loss: 3.4367165565490723\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we well is a construction of uniformly well in for which the mean curvature and a and the applicationability to the hypersurfaces.we is the wellence between the notion of uniformly strongly elliptic and uniformly normally elliptic hypers the scalar case andwe well -posedness result for the sphere class is obtained for the methods related results resultsms. including the importancearkinchitz continuity of the semiflow andthe. -.......ad..adadad...ab.ababababababababababababbabababababbbababab',\n"," ' effective effective effective discusses the effective interactions of theermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the thermally averaged indirect indirect matter pair d )pair annihilation cross-section and the spin-independent d - with le and/or bound electron and and that with the data. -....,,,,,.  ... ... ..      bbbb bbbb  bbbb ',\n"," ' in in : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional necessthemedicine is which implementation of tele technologies to provide medical services is has a as a promising solution for address the needs ofin is the communication communication sensing technologies to provide biological signals and medical them information to the providers throughin of application of telemedicine is the delivery which which the focus on the therapy where control drugs information to the organism minimizing the effects.the between a central role in the themedicine system between which the developments has to the-based molecular communication ( inner body and communication (']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 101, training loss: 3.3193228244781494\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 102, training loss: 3.1473584175109863\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 103, training loss: 2.928936004638672\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 104, training loss: 3.1657676696777344\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 105, training loss: 3.1592330932617188\n","epoch 2, prediction loss: 3.485525369644165\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order and however others have focused the to as convesian neural networks or convabilistic graphical models to semi-supervised learning in in in been been done in the neural neural networks to however lstm networks to to address time data in however neural flow data in in aim presents a approachmentation scheme for generating time data in network traffic trace g tcp the contribution that in the results used in generating cases and numer data aug.the used as recurrent augetermination andimation and kd ) and used to generating new data and the network-',\n"," ' it it d discusses the symmetry of elect electrodynamics theory under theity transformation and considering on the drangian transformations involving the the theion and dilaton fields intoit is the dance of the equations under equations of motion and energy-momentum tensor under the-duality transformationit extensionsetries of transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the existence of of theitudes involving the-duality transformationit isves into the d of the involving equationsitudes under the-duality transformations and and the role of the of the-duality',\n"," ' in in s is that sn is the normalized matching property which which that sn is indeed sperne sin is a by the example on. the normalized case is trivia as and the baseive step is the theutations from the copies of sn. the collapsing the n of we new network is constructed which be the normalized matching cond. which to the conclusion that sn is indeed sperner. well satisfies normalized normalized flow property.inim...  ..    ......adenadenadenabababab.bababadenbbhpb']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:29,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 106, training loss: 3.8270187377929688\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 107, training loss: 3.0348312854766846\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 108, training loss: 3.697067975997925\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 109, training loss: 2.5009868144989014\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 110, training loss: 2.9187099933624268\n","epoch 2, prediction loss: 3.006472587585449\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the convergence discusses the properties for on the priori estimates for the a. based convergence provides convergence convergence of the unfolded function for the2.the to the convergenceation of the limit vibro-acoustic problem in a formal approach which the sequences constructed with the convergence res.basedch-...               .  ..   ..   awareaware.  awareaware.....awareawareawareb,,,,b,,,,,,,,awareaware,,,,',\n"," ' the the study of a detailed introduction of theson sld and a on the only of in the study of  also as a guide reference for the the features in thei geometryometry. the problems and x........igenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,igen,,,,,,,,,,,.,,,,,.,,,fb...,,...,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' we we tree is the tree-matal amplitude and d3-brane couplings in the on the thelevellevel s-matrix elements of one ramond-ramond and three open strings by imposing this symmetry the tree-level s-matrix elements of one kb-ramond and three open string.we also discusses a effective invariant form of the d3-brane effective action containing derivative gauge fields with derivative corrections that from one-loop level four-point amplitud.ar expansion with derivative corrections at found at expansion the nonlinear sl invariant structures at the more gauge fields at -..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 111, training loss: 3.137883186340332\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 112, training loss: 2.7733631134033203\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:55,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 113, training loss: 2.721130609512329\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 114, training loss: 3.002378463745117\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:02,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 115, training loss: 3.204122543334961\n","epoch 2, prediction loss: 3.1637651920318604\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the theised features descriptors are used to the nasal region using the features in spherical ontheised from theabor wavelets filters are a featuresors and which to a dimensionality and reduced redundancy and and enableabilistic feature selection to reduce the to facial expressions while maintaining theinative part.the landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.the sphericalors are the use of the spherical on the nasal surface and when the selection selection andthe, theogonal planes toing with the nasal surface provide a on the evaluation evaluation.the.......',\n"," ' in in isisms are on the category of for in networks by for andfulerryerson andinisms are the context are the-fululkerson flows oninflows on networks network is defined by a inequalities andinflow is defined to minflowichai flowinperner showed original on that min ranks can satisfy hall s condition are to min naturalperne poset andin and har introduced hall s matching cond by prove rot. s conjecture. leading the category matching condition and a normalized of the normalized flow property.in category flo is with theyclic vertex-weighted networks and and aisms preserving these morphisms preserving',\n"," ' splitting splitting splitting of discusses on the splitting of double vector bundles in the context of the to the to the vector on including well in the paper...42x and.........  parenivalentivalent  ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent..ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent.ivalentivalentawareawareaware.awareawareaware..awareawareawareawareawareawareawareivalentawareawareawareawareawareaware..,,aware,awareaware,,awareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 116, training loss: 2.9461679458618164\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:10,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 117, training loss: 3.1590898036956787\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 118, training loss: 3.654085874557495\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:17,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 119, training loss: 2.6836507320404053\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 120, training loss: 3.0654377937316895\n","epoch 2, prediction loss: 3.3065457344055176\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in goal presents a method to d map Creator using dmc )@ can computer vision technique to create create a by stitching together visual information captured by a d  camera camera.d proposed is the speeded up robustotic features method to detect the points for each image frame and identify the the points between frames by maximizing the determinant of a heian mat.the proposed points are st to st together two by and in a st creation. some from the external environment....         ddddddddddddddddddddddddddbbddbb',\n"," ' in in type on the the type e6 crystal decomposition into using the and adding loops at everyices of the the composition graph gwe example decom r is an as an i0,7-highest weight ele in the sectionposition..wech decom.....,,.,,ivalentivalentad.gngngn......ivalentivalentivalentivalentivalentivalentivalentgiangianivalentivalentivalentivalentadjivalentivalentadenadenadenaden.adenadenawareawareawareawareawareawareawareawareawareabadenadenadenadenawareawareawareawareawareawareivalentawareawareawareawareawareawareadenawareaware',\n"," ' the the comb of the comb of a7 crystals weight elements from using the7 crystals weight elements as a decom computation of.the constructionposition into e7 crystals is multiplicity free and is shown to the comb that to the one of proposition conjecture inthe proofinatorial r-matrix must used to its ability to map classical components to classical components and which the weights are k k are k. computed from a function ofthe is is as a proof towards proving a conjecture of a a construction of a7crysta value for the finite way....              ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 121, training loss: 3.2292544841766357\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 122, training loss: 3.2965571880340576\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:31,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 123, training loss: 3.2485764026641846\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 124, training loss: 3.175262212753296\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:38,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 125, training loss: 2.9704601764678955\n","epoch 2, prediction loss: 3.6668899059295654\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this imageured the in the images images using to the and can be the of.we main presented in to solve these by improve that transitions between the images by , ity details details can occur occur the quality. inosing the best appropriate algorithm for this problem is a because to the issues. inio algorithm........adaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenadenadenadenaddadenadenadenaden..abababababababababababababababababababababababababab',\n"," ' in in crystal result of in this paper is that multiplicity freereeness of the decom. this labeling labeling conventality which well by figure 2. in proof7 crystals b are be decomposed into a le subalgebra of type a6. a multiplicity freefree way. and by a computation using a the 2 using the and and loops to everyices in and adding the composition graph g  we is shown that the crystal b is type e is a multipl rule. the multipl m of x x inin proofposition is multipl shown by amma. theabeling the fundamental weight. and leading in a multiplicity',\n"," ' we we is on the the of obtain the is component of a a refined isomorphism between the6 decomposition ofthe is a a isomorphism between for to theu-de-taquin s@res is is and...     adadadadadadad vadad..vadvivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentableableivalentawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 126, training loss: 2.679286003112793\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:46,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 127, training loss: 3.4277470111846924\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 128, training loss: 3.6659975051879883\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:53,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 129, training loss: 3.0585713386535645\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 130, training loss: 2.9693007469177246\n","epoch 2, prediction loss: 3.6925411224365234\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' a a novel algorithm is introduced to this paper to address the invari invariariant face recognition using that the 3d shape of nos nasal (the algorithm isages a robust anding algorithm and a feature space and discriminative feature descriptors and feature feature selector tothe results is applied over three well face datasets, fr that results for both and verification scenarios.the, the algorithm achieves a ranks of than previous nasal region-based algorithms and outper betterformed many 3d holistic and multi-modal appro.  algorithm can performance for to face in other alignment, low dimensionaldimensional face recognition and pattern pattern rejectio  research on are the',\n"," ' in in point on a examples of the admitting admit thewise sparse domin andin main is the the of bounds are known known but but the unified approach simplified approach to provided to on theore 1. its variant.in results are from from the results in ai l and sheldy ombrosi and but the improvements in in the to and4 text results is the the theorem admits of weak type and to theorem 1. and a specific refined result with by the slightly case with by.in....                    ab ',\n"," ' the the q is a new of the invisible qcd axion model without domain wall and with the heavy heavy heavy are present inthe is is first in the contextxiv:19012..3.. the 2015st2019........     gngngn        adadadfbadfbfbfbbfbfbfbfbfbbb..fbfbfbfb..abfbabaware.....fbawarefbabaware.aware.........,..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:01,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 131, training loss: 3.222666025161743\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 132, training loss: 2.620044469833374\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 133, training loss: 2.6862337589263916\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 134, training loss: 2.9733831882476807\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 135, training loss: 2.6777865886688232\n","epoch 2, prediction loss: 3.589876890182495\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in aim presents the classification of irregular with by theodge theory and al by the which irregular3 type with product modental part.we are the related the t of these surfaces and their conditions answers to the questions related certain conditions.the main also the the classification of these surfaces is not not and that the state state of the art up  also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac.  results obtained can used to prove that t and mumford-tate conjectures for these surfaces.  proof also the support of inspiration and provide a overview of the current state',\n"," ' in inore of a but/ extensions of the theorem theorem of namely on the certain precise version of pointwise sparse domination 7.1 main of the theorem result compared the original theorem is that and and some is used how it result can used in a applicationsorems.1 proof also discusses some possibility to the theorem to a multilinear cas and and the the results obtained1essary and in the proof are pointed out. and the the original idea of the theorem theorem.1......    iiiiii            ab ',\n"," ' the the study of theooninivityverseal and.................ine,,,.,inefbfb,ineineinebiabia,,,ine,ibineineineine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ibibibiii,,ibib,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 136, training loss: 2.7103183269500732\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 137, training loss: 3.058712959289551\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 138, training loss: 2.8198904991149902\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 139, training loss: 2.4981696605682373\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 140, training loss: 2.859992027282715\n","epoch 2, prediction loss: 3.4843196868896484\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in e discusses a e -to-end e-health system which for includes molecular and electromagnetic wireless commun betweenthe-body and are d via a generic-assisted diffusion-based molecular communication system and while aomachransmissionters in a molecules inout relay node is be improve the link andout proposed model includes a- and and off-body communications via which a time of nan schemes and different symbol intervals. each communication type.theomachines/ as relay nod in which nearly free and molecular betweenthe proposed is includes a2out-off-body communication communications between aways. on communication between the body-health system.',\n"," ' the theac s2obi - are used models that are the a theoryac equations with a externalic function of of generate a set set with with a information and  structures are called in the context of the equations and are be used to the physical models. the of theolds and x latt.......igenigenigenigenigenigenigenigenigenigenigen.igenigenib..,,,,..,,,....fb,...,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the differenceauchy problem method is used to solving solution solving solvingolving of the on the auxiliary pseudo-time evolutionary problem.the a priori estimates are be obtained for solve numer problem. the the prior implicit two-level euler scheme. used.5 difference scheme is unconditionally stable with the initial dat pro5 applying these estimates recursively we  validity of the difference is proved.5im....,,,,,,,,,............ababab.ababababab.ababababababbbabab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 141, training loss: 3.5944159030914307\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:41,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 142, training loss: 3.168509006500244\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 143, training loss: 3.4464704990386963\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:48,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 144, training loss: 3.3012309074401855\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 145, training loss: 2.843615770339966\n","epoch 2, prediction loss: 2.7099108695983887\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the influence on a results test of the homogenized model of a perforated plate of the reissner-mindlin typ andthe results is to compare responses responses of the homogenized plate model with the of the associated 3d elastic structure withtheations boundary conditions and loading functions are used to the homogenized model and where the aimd elastic represented by the plate model described as a 2d structure,the deflections are computed for the models using the d of the 3d elastic and usingiscale simulations of the plat modelthe influence of the compliance on the loss in the waveguide is discussed bythe influence',\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the need of by the -rigid objects expressions and3act approaches for such the iterative closest point algorithm, can become to variations minima and3 approach to capturing a range of facial expressions for each subject and storing them with the subjects in each purposes but this are are 3 and storage are3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to overcome theness against facial expressions and in research have focused the to the multiple normals hist local',\n"," ' deep deep learning ( ability to high stakestakes decision problemsmaking is still challenging for it influence may uncertain and extensive test anditing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents and to their performance-making process. however these studies have focused on feedability of feedforward deep learning agents we studies focused interpret issue of more learning ( well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is a agents. in potential approach to to provide the in reinforcement learning agents by']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:57,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 146, training loss: 2.828010082244873\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 147, training loss: 2.794764518737793\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:03,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 148, training loss: 3.198101282119751\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 149, training loss: 2.8193366527557373\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:10,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 150, training loss: 3.2972939014434814\n","epoch 2, prediction loss: 3.3306081295013428\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in comb on theing the.- from the comb of the of the.in using the certain approachinatorial approach of we comb theorem for can proven to provepose the into i0,2-crystals accordinginch.........gngnadadgngngngngngngngdgdgdgdgd..vivalentadjadj.adjadjadjgiangianadjadenaden.adjadjadenadenadenadenadenadenadenadenadenaden..adenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenab',\n"," ' we weinstein of are transit transit study of to properties of the populations fromusing key function is used for determining bayesian theorem theorem and extract parameters parameters fromusing method distribution is modeled as a independent power -law distributions in period and rad using distribution that a single planetary population is made by assuming the distribution of this assumption is examined usingusing distribution is on multiple systems with thezes the effect effects introduced the and multipl distributionsusing distribution used to on previous studies to including planets by detection order andusing results show evidence on the factors detection order and show distribution parameters for this introduced the distribution distribution fun ( to this orderusing statistics are discussed to to',\n"," ' we we ke discusses the effects for incompleteness due ke planet occurrence rates due to transit multiplicity inwe ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data and  distribution also the statistics that affect the radius and period distributions of each detection ord and  results rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog.  results model is consistent with the studies but now includes an improved estimate of the multiplicity distribut and  average also']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 151, training loss: 3.003676414489746\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:18,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 152, training loss: 3.26529598236084\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 153, training loss: 3.330800771713257\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:25,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 154, training loss: 3.013803720474243\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 155, training loss: 3.14017391204834\n","epoch 2, prediction loss: 2.9621496200561523\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking and theories context.we is the possibility wall problem and theion models majoron models and proposes a to as the inflation and the warides-shafq and the the witten effect towe minimal minimal is proposed where the breaking of peq symmetry is arises at a newiral confining force and which the domain wall problem.the model of instantons interference effects also and solve the instant wall problem. introducing the peq symmetry by the cases.the model also discusses the issue of thebaryons in which heavy',\n"," ' in in lie on the lie algebra of type an with whichoted sl sln+ is which to the graphs..in main is the all n-colored edge in the crystal graph andin is discusses the the lieposition of the 4 is multiplicity-fre.inine.........  gn,..gg.giangiangiangiangiangiangiangiangiangianivalentivalentivalentadjivalentivalentivalentivalentantedivalent...awareawareawareawareawareawareawareawareawareawareivalentivalentadenawareawarepartyawareaware.ivalentawareawareawareawareawareaware,,aware',\n"," ' reinforcement reinforcementinforcement learning ( inspired by our brain s reward-based learning process allows artificial agents to learn a without detailed instructions or labeled training sets which given study is essential for supervised general-like intelligent agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are still incomprehensible andinparent decision with comprehensible internal-making processes are necessary to safely reinforcement learning agents into into high stakesstakesake problem. in on that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description and in of proposes a quasi-symbolic agent as a secondary agent and and can generalably to']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:33,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 156, training loss: 2.9574851989746094\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 157, training loss: 3.1764116287231445\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 158, training loss: 3.2820191383361816\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 159, training loss: 3.1442887783050537\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 160, training loss: 3.122624397277832\n","epoch 2, prediction loss: 3.365485191345215\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the study is thexiv:190. a detailed description of the results details of in the paper.ar includes the main features of discusses of were be discussed in including a a detailed overview of the is expect from the future section.arx-.........,,ib,,,  ......,....,pbpb.fbfbfb.....pbpb...fb........,,,,,,,,,,,,,,,,,,,,,,',\n"," ' we we distribution discusses the resultsolation of previous populations parameters to longer periods ofwe is the the results of not differ greatly from previous studies and discusses consistent with previous results ofwe. with found between theman-mackey et recent to uses the a specific functional form for theolation to using aussian process regression to determine the functions.weman-mackey et approach also a results pipeline in to does reports the highest signal to to- noiseise candidate around each st andwe results also discusses the detection order can bias the and in leadingcounting small planets and long periods and  text used by bur et a.@ used by the',\n"," ' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other with low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss such here analysis of that the for detection loss canens the need for an additional population to explain the of using inclusion presented suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with this notion that some populations share dynam dynam']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 161, training loss: 3.8384621143341064\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 162, training loss: 3.694093942642212\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:59,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 163, training loss: 2.9262232780456543\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 2, batch 164, training loss: 3.5035746097564697\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:06,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 3.1460234598679975\n","epoch {}'s average verification loss: {} 3.315636247396469\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [30:54<1:11:52, 616.08s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 0, training loss: 2.71821665763855\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 1, training loss: 3.0617051124572754\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:07,  3.51s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 2, training loss: 3.446000814437866\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.50s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 3, training loss: 3.3297119140625\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:14,  3.50s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 4, training loss: 2.6702370643615723\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.50s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 5, training loss: 2.9011292457580566\n","epoch 3, prediction loss: 2.9223902225494385\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we search presents a results of a ensemblene affinvariant ensemble sampl to explore the from towe bayesian framework is linear space uniform priors is used towe toors are used for the r ofbr and pbr. on the distribution sample samplewe casc prior for that f must must be larger than f parameter avoid trunc and- resulting is is for larger multiplicity systems to be more common than smaller multipl.-.......               adadadadadadadbbadadadbbbbb',\n"," ' in in method results a model is three different datasets shows that our method of sampling in able in im thebalanced datasets andthe results that to precision1 measure, precision andrec recall measurethe performance is performance on compared with sampling in and the in precision and in to higher false predictions predictions andthe overall accuracy of the model is also than sampling in with a improvement in precision and recall and and confusion accuracy.  model is that accuracyiz accuracy accuracy decrease in false negative due to the in. x.......ddddddddddddddddddddddddddddddddddddddabab',\n"," ' the theised features descriptors are used to the nasal region using the features in spherical ontheised from theabor wavelets filters are a featuresors and which to a dimensionality and reduced redundancy and and enableabilistic feature selection to reduce the to facial expressions while maintaining theinative part.the landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.the sphericalors are the use of the spherical on the nasal surface and when the selection selection andthe, theogonal planes toing with the nasal surface provide a on the evaluation evaluation.the.......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:22,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 6, training loss: 2.867393732070923\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 7, training loss: 2.575559616088867\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 8, training loss: 3.2163913249969482\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 9, training loss: 3.088559627532959\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 10, training loss: 3.8986403942108154\n","epoch 3, prediction loss: 3.320896625518799\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in traffic is a for the ever amount that in withifying the traces and applicationsifying applications is two tasks in with traffic tracingifications ( nts ) have classify anomalies in classify applications for however they methods have shown in the on ports in lack reasons. their ofingorithms have n classification classification have great in they solutions for however thebalanced datasets is networks-scale networks networks a challenging for deep due f.. inmentation is have machine learning are which as artificial artificial data for are be these imbalance issuesin novel approachmentation method is k dataensity andimation and kde )and litudinalestTerm memory ( lst',\n"," ' the the differenceauchy problem method is used to solving solution solving solvingolving of the on the auxiliary pseudo-time evolutionary problem.the a priori estimates are be obtained for solve numer problem. the the prior implicit two-level euler scheme. used.5 difference scheme is unconditionally stable with the initial dat pro5 applying these estimates recursively we  validity of the difference is proved.5im....,,,,,,,,,............ababab.ababababab.ababababababbbabab.',\n"," ' we wetic models have transit probability have double transit systems have presented knownknown for on the inclination andanaly, larger models models for larger multiplicity systems is more difficult and requires semi-analytic models.to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated towe account the distribution population of we non for m transit probability is some given semi-major axis value is created. this with other for the geometric of otheroplanet period. to address this related to the order, the against we non-uniform method method is used to the period popul to to such']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 11, training loss: 2.836134433746338\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 12, training loss: 2.835310935974121\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 13, training loss: 2.7770402431488037\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 14, training loss: 2.951850414276123\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 15, training loss: 2.984046220779419\n","epoch 3, prediction loss: 2.7271015644073486\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' deep deep learning ( ability to high stakestakes decision problemsmaking is still challenging for it influence may uncertain and extensive test anditing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents and to their performance-making process. however these studies have focused on feedability of feedforward deep learning agents we studies focused interpret issue of more learning ( well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is a agents. in potential approach to to provide the in reinforcement learning agents by',\n"," ' in inorem on theic surfaces3 surfaces of ch ch to chow motives of surfaces and1 is a proofposition of theow motives of surfacesic surfaces into aic and transcendental components and and by a comput and computations.it proofogenical decomposition of theelian varieties with group action is also in and to a is of the case example in1 proof is with a discussion on the specific example in a k of singular algebraic k3 partner of a minimal between kers surfaces and ch resolutions of which the importanceogenism between kental surfaces of1............',\n"," ' in in e of with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is conducted toin closed-form expression for the e error probability of concatenation of molecular two channels was derived andthe optimization problem was at minimize the e error probability was conc system was formulated to determine the symbol durations for both molecular of communication.the reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication.....              dd      ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:59,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 16, training loss: 2.8008370399475098\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 17, training loss: 2.6958119869232178\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 18, training loss: 2.632347583770752\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 19, training loss: 3.093421459197998\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 20, training loss: 2.985304117202759\n","epoch 3, prediction loss: 3.296616554260254\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' reinforcement reinforcementinforcement learning ( inspired by our brain s reward-based learning process allows artificial agents to learn a without detailed instructions or labeled training sets which given study is essential for supervised general-like intelligent agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are still incomprehensible andinparent decision with comprehensible internal-making processes are necessary to safely reinforcement learning agents into into high stakesstakesake problem. in on that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description and in of proposes a quasi-symbolic agent as a secondary agent and and can generalably to',\n"," ' * * studyaic - is a method to to calculatingson solds to which are used with which with a functions that@ is the the equations of a basis of create the. to the results.@x is is...pbpbpbpbigenigenigenpbpbigenigenigenigenigenigenigenigenfbfbfbfbfbfbfbfbfb,,,,,,,,,fb,,,,,,,,,,,,',\n"," ' in in point discusses a examples of the admitting admit thewise sparse domin.in main is the the of bounds are known known but but the unified approach simplified approach to provided to on theore 1. its variant.in results are from from the results in ai l and sheldy ombrosi. but the improvements in in the to and4 text results is the the theorem admits of weak type. to theorem 1. and a specific refined result with by the slightly case. by.in....  ad                 ab ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 21, training loss: 3.152892827987671\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 22, training loss: 3.3467206954956055\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:24,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 23, training loss: 2.8697009086608887\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 24, training loss: 2.5710339546203613\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:31,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 25, training loss: 2.6115338802337646\n","epoch 3, prediction loss: 3.7334952354431152\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the r of the behaviorogeneousization phase of with the with surfaces on the case structure of theaus inthe equations are the types such as the properties and the size and determine a descriptions for the the understanding the behavior. the systems.thex and and@...,,,fbivalentivalentivalentivalent...ivalent.......................fbfbfb...fbfb.....,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' we weorem on a proof of convergence theorem on the the monmma and using is the convergence of the pro of themma.. le to proof condition. shown in section previous bythe proof also a concept ft : the to themma 3. le proofotone convergence theorem.the, the is the ex for the with respect to the probability measure p the with section with showing the theoremms. lemmaps..the...........awareaware..........ababab.ababababab',\n"," ' the the q discusses a new of the invisible qcd axion model without domain wall. with the heavy heavy heavy are present inthe is is developed in the contextxiv:19012..3.. the 2015st2019.........    gergngn        adad.fb.fbfbfbbfbfbfbfbfbfbfb..fbfbfb...fbfbab.......awarefbaware,............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 26, training loss: 2.6267547607421875\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:39,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 27, training loss: 3.3956127166748047\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 28, training loss: 3.1829721927642822\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:46,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 29, training loss: 3.1250898838043213\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 30, training loss: 3.3676087856292725\n","epoch 3, prediction loss: 3.4759161472320557\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in concept discusses the -to-end communication error rate ( computing the types links of such the molecular communication channel model and a diffusive environment and a and relay and and receiver nodes placedto of the molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is computedimated by sim s rul.to orderpersmbol interference is ignored. the the of left to future work.to error error performance ( is also in the on- and and off-body communication channel. the the of the such the between motion ofto-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' boundary boundary this paper we we boundary is the boundary of boundary boundary value problem for the fractional power of the power power withthe is the boundary to solvingimating the boundary by the finite of finite finite element method.thex boundary boundary is..     ,gn           ....fbfbfbfbfbfbfbfbfbfbfbfbfbfb..fbfbfbawareaware..awareawareaware....awareawareaware,,,,,,,,,,,,,,,,,,,,',\n"," ' in in isisms are on the category of for in networks by for andfulerryerson andinisms preserve the context are the-fululkerson flows oninflows on networks network is defined by a inequalities andinflow is defined to minflowichai flowinperner showed original on that min ranks can satisfy hall s condition are to min naturalperne poset.in and har introduced hall s matching cond by prove rot. s conjecture. leading the category matching condition and a normalized of the normalized flow property.in category flo is with theyclic vertex-weighted networks and and aisms preserving these morphisms preserving']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:54,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 31, training loss: 2.926537036895752\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 32, training loss: 3.3939270973205566\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:01,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 33, training loss: 3.041428327560425\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 34, training loss: 3.105036497116089\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 35, training loss: 3.201564311981201\n","epoch 3, prediction loss: 3.8587284088134766\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the current discusses the impact of the matter ( d )ther density using using the thermalally averaged andaged annihilation annihilation cross- forwe current have the cross-averaged annihilation cross- for f types candidates including compare the results to compute the cos density constraintsthey direct are such as dermil-abs, hess are are sensitive to the types candidates andweihilation cross- are various types candidates are computed using pair with le leptons and photons usingthe results also discusses the on theider experiments to these operators for the on theh data.  results is on the detection experiments which d particleselectron scattering delastic',\n"," ' the the en model ( the context is the en and modeling into state vector and action a inputs and the the next state andthe this text we we network layer of a nodes is used to the env network tothe is shown using the squared error recurrent each episode of random learning (. a ensemble learning rate of 0.0...................ad.....adaddaddaddadd...........aware.bb..bbb,..,,bhbhbhbh.',\n"," ' we we effects discusses on the multipl effects multipl the parameters parameters from theoseismic data fromwe study of new updated allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat and to of also from the curves and thus periods need on the data keks data. to positives are removed using the thes to thus the planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in we a of on the and period cut. we with multiple positives are artificially removed to accuracy order in  inclusion detection multiplicity we in 7']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 36, training loss: 3.1309518814086914\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 37, training loss: 3.1120264530181885\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 38, training loss: 2.9785211086273193\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 39, training loss: 2.6856954097747803\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 40, training loss: 2.702505588531494\n","epoch 3, prediction loss: 3.076317548751831\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using thenating them key points between the and and then a robust fitting to to finding changes rotation. as rotation andthe, when we to stitch more result image with a third image using the will because the result will tries the black background as the image process.to happens is due by the that theofcv and so to a images. stitching more than two images usingto avoid this issue we open algorithm was implemented using openc. find this distortion problem by theofcv. translation. to effects.theac..',\n"," ' using using ke discusses the use of constructing a stellar sample for use a detection efficiency map using the data from the1q17.0 stellar is 86 parameters from theur et al.s ga stellar values from ga dr2.we the measurements have been been updated from the dr2, the has25 stellar parameters values have updated updated tousing ensure thatteness mapping we we star must have a stellar of its radius and mass measurementusing values for either fields result in omission weusing, the on placed on the cycle and fc >.5 )and time length ( light light curve (we final is the-varying noise',\n"," ' effective effective effective discusses the effective interactions of theermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the thermally averaged indirect indirect matter pair d )pair annihilation cross-section and the spin-independent d - with le and/or bound electron. and that with the data. -....,,,,,................     bbbb.bbbb.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 41, training loss: 2.9600775241851807\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 42, training loss: 2.739715099334717\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 43, training loss: 3.187925100326538\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 44, training loss: 2.858686923980713\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 45, training loss: 2.78865122795105\n","epoch 3, prediction loss: 2.8979227542877197\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in one discusses the thestation fractional power elliptic operator problems numerically using using equivalent local nonstationary initial value pseudo-parabolic problem.the such were the implicit backward and symmetrical euler method. while the paper proposes to the fourth-parameter family of three-level finite difference schemes forthe fourth-order approximation scheme is developed by optimal optimal weight paramizationthe resultsical analysis is are supplemented by extensive computational experiments......... .....  ..bbbb.bbbbbb',\n"," ' in in error results to that performance of the proposed e -to-end e sy for diff diffusive environment like blood wherethe channel coding is considered forthe error probability performance analyzed as on the parameters like including location and and at and and symbol velocity.the analyzing the parameters, the performance error probability ( ber )performance be improved.the trade-off between the conversion and channel rate time also between where the trade value -to-end ber e2e )berern performance when the the energy molecular channel ( dmc ) and errorstatic ( ec ). (in the velocity can the minimum2e berery performance increased increased the',\n"," ' we we we discusses the weence between doubleb-algebroid structures on d double lie algebroid and horizontal or vertical differentials on two of the threeil algebras and a well as ger gerstenhaber bracket on the th wear also discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras andar.......           ..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 46, training loss: 3.2037620544433594\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 47, training loss: 2.966391086578369\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:56,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 48, training loss: 3.012319803237915\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 49, training loss: 2.8577771186828613\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:03,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 50, training loss: 2.5697033405303955\n","epoch 3, prediction loss: 2.860588788986206\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the acoustic discusses the method analysis which the the acoustic acoustic pressure and the displacements and and rotation in a limit lay ofthe is is based for understanding understanding - and equations of vib vibroacoustic problem imposedthe convergenceymptotic analysis is based using the unfolding method which which developed for the seminal paper by elaborated elaborated further thin structures inthex......gggg           ....,.......,,,,,,,,,,,,,,,,,,',\n"," ' the thealar-tensor theories have among alternatives to general relativity and have had a large impact on cosmology andsc theories commonly variousar degrees of freedom in addition to the usual metric of general relativity and but to various phenomenology due to various coupling terms in their action.  two to choose the field variables while them the of the the j frame or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form, the relationship of to generalize the analysis of these relationship between these two to theories that higher spin fields such vectors insteadwe main of on theories',\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the need of by the -rigid objects expressions and3isting approaches for such the iterative closest point algorithm, can become to variations minima and3 approach to capturing a range of facial expressions for each subject and storing them with the subjects in each purposes but this are are 3 and storage are3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to address theness against facial expressions. in research have focused the to the multiple normals hist local']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 51, training loss: 2.7655508518218994\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:11,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 52, training loss: 3.1718637943267822\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 53, training loss: 2.995584011077881\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:18,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 54, training loss: 2.8483359813690186\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 55, training loss: 3.5821690559387207\n","epoch 3, prediction loss: 2.989189863204956\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we t discusses the t and mumford-tate conjectures for surfaces s connected components of the gieseker moduli space that contain a product-quotient surf sur.. and et....,,,,,antantivalent    iv.....................ableable...able......ableableable.............abababababaware',\n"," ' hom hom vib discusses the homogenization of thero-acoustic transmission on perforated plates andhom is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inthe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withthe homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation pericitythe nonlocal implicit implicit transmission conditions involve a',\n"," ' to to ability discusses the applications of thes agents to are secondary to evaluate a agents from r agents.q agents can evaluate used to specific-specific problems andq from to such as state multiple rewards and of state rewards or can be used to evaluate agents- andqizing the actual of state- can on the such coordinates and velocities can be agents performance of qs agents.qs agents can also multiple matching and value networks to evaluate agents values of.q proposed between p brain cortex and pfc ) hippocampus and and anterior cingulate cortex ( discussed for the andbased brain discusses that one of of q q cing']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:26,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 56, training loss: 2.4412100315093994\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 57, training loss: 3.290828227996826\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 58, training loss: 3.3858816623687744\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 59, training loss: 3.058600902557373\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 60, training loss: 2.833970546722412\n","epoch 3, prediction loss: 3.5742201805114746\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in internet discusses the long learning on packets in classify flow traffic patterns order imbalanced environment.has is a novel augmentation approach based longstm network for generating flow patterns and and kernel density estimation for replicating the features ofthe results is to improve the with which those network with less popul ofthe of all datasets demonstrates that performance of precision of precision, recall and and f1 measure for every classes classes.......adadbbadbbbadddddddddddddddddddddddddddababbbbbbbababbbbabbb',\n"," ' using using importance discusses a the in the measurement into a bayesian hierarchical model into occurrence for parameters into order context generation of occurrence fitt methodsusing importanceicity parameters derived here be in determining an eta earth measuremenas the importance of neighboring planets could the long of an earth analog is multiple multiple sy may important.using importance also that a injection experiments to study the eff across understanding the effects in the eff. ining data from missions will it as ke and t tess will will will essential to understanding occurrence measure of as for the detection effiencies across  method described here to incorporate these selection effects into producing a uniform distribution distribut.  method',\n"," ' transition transition continuity discusses the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  also provides the estimates for the transitionit surface that the surface measure on the domain is in the local kato class of the reflecting brownian mot.ar.........          .ad....adad..adadad....ad............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 61, training loss: 2.785712242126465\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 62, training loss: 3.2492198944091797\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 63, training loss: 3.662719249725342\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 64, training loss: 2.772686004638672\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 65, training loss: 3.20578670501709\n","epoch 3, prediction loss: 3.073714256286621\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using usinginstein of are transit transit study of to properties of the populations fromusing key function is used for determining bayesian theorem theorem and extract parameters parameters fromusing method distribution is modeled as a independent power -law distributions in period and rad using distribution that a single planetary population is made by assuming the distribution of this assumption is examined usingusing distribution focuses on multiple systems with examineszes the effect effects introduced the and multipl distributionsusing distribution used to on previous studies to including planets by detection order andusing results show evidence on the factors detection order and show distribution parameters functions this introduced the distribution distribution fun ( to this orderusing statistics are discussed to to',\n"," ' in in fraction discusses numerical numerical of fractional power equations in time models with solving applications. as sub, biology or finance finance.in is on the fraction involving fractional power elliptic operators. numerical based the elements method quadlov subspace method.in numerical to solve fractional powerin-space reaction-diffusion equations are analyzed and in the integral and adaptively preconditioned lzos method.in numerical also discusses theimations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic problems..in is with a results to the results. the',\n"," ' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.in results was tested with a sampled and augmented datasets and and compared results obtained that our proposed approach outperforms thenn in terms of overall, recall and and f...inx.......  ad  dddddddd.abdddddd...ababab...abab......ababababababababababababababababababbhbhab..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 66, training loss: 3.045383930206299\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:06,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 67, training loss: 3.057821273803711\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 68, training loss: 2.775099992752075\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:13,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 69, training loss: 3.0746726989746094\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 70, training loss: 2.978759765625\n","epoch 3, prediction loss: 3.2231948375701904\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we this context of study agentss and is q ) and interact with r learning ( r) agents and make model env ) agents. learn future actions.qs three are constructed using thetorch, an open-source machine learning toolkit.qsx-....,,,ionionibibib..gdgd.gd...........gd..b.....aden..............awareawareadenadenadenawareawareawareawareaware,awareawareawareawareawareawareaware.',\n"," ' in in goal we to use the drone to camera to take images images from a parking parking lot and blend them to create a large large image. the entire parking.to different were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to first was images images during certain points intervals during create the merging ofto this field test  we drone lot was divided into a 4x4 matrix matrix better the drone s movement and.the algorithm was using images at different and then them images together each column and and then merging them columns together afterto',\n"," ' the the ke discusses the effects for incompleteness due ke planet occurrence rates due to transit multiplicity inwe ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics that affect the radius and period distributions of each detection ord.  results rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog.  results model is consistent with the studies but now includes an improved estimate of the multiplicity distribut.  average also']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 71, training loss: 2.626943588256836\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 72, training loss: 3.111093759536743\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:28,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 73, training loss: 2.8197457790374756\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 74, training loss: 3.0094144344329834\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:35,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 75, training loss: 3.0302975177764893\n","epoch 3, prediction loss: 3.0537333488464355\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in author discusses the results in to the theory dir subsetets and andichlet forms and andotone class argument and andity and and domain and and and eigenfunction and and and and finini s theorem.the words are the thatity of the dirichlet form and the convergence of themma 1. proof. to le results.the section is discusses the sectionification theorem of the principaln t. l. the convergenceiteness of the*...........  .........  .',\n"," ' in in paper discusses a bounds for cal operators and harmonic analys.weization and sparseness are two ingredients in make them bounds especially tools quantitative norm inequ. in paper on sparse bounds for too and inars bounds for cal on- onymund operators are calizations domination principles are reviewed inin paper show a proof proof on means the main hypot of the them the weighted wq proper proper  result simpl the need for work with the grand maximal truncated operator mt which it sparse more convenient comparedthe proof also also as five. the proof of the theorem theorem and the and extensions and and proof t1-type result and and a',\n"," ' the the hom on the the homogenized vibroacoustic transmission model derived the text is be used for numerical simulation of acoustic waves using the two-scale in.the numerical is is to to the one considered the paper of where the zero neumann condition appl a same acoustic fluid and the solid are.the numericalscopic responses are computed in compared in fi. illustrate the model.the.....,,,,,,,,,,,..,..........dddd,,bbbb..b..abb..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 76, training loss: 3.2384233474731445\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 77, training loss: 2.972130060195923\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 78, training loss: 3.112804412841797\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 79, training loss: 3.164433717727661\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 80, training loss: 2.707353115081787\n","epoch 3, prediction loss: 3.13999342918396\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' well well well of the well -posedness properties for the wellard - equation the on the workorems on the of to the regular surfaces andthe proof involves from to as in the previous proof of.x.......       ad    ivalentivalentivalentivalentivalentivalentivalentivalent.ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent..ivalentawareaware..awareawareivalentawareawareivalentivalentivalentivalentivalentawareawareawareawareivalentivalentawareawareawareawareawareivalentawareaware',\n"," ' in in lie on the lie algebra of type an. whichoted sl sln+ is which to the graphs..in main is the all n-colored edge in the crystal graph andin is discusses the the lieposition of the 4 is multiplicity-fre.inx...........,,,.........gianadjgiangiangianivalentivalent.....ivalentantedivalent...awareaware...aware..awareawareivalentivalentadenawarepartyaware,,,,,aware,,',\n"," ' the the homogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation ofthe model of are the the referenceogenized and the models are constructed inthe response of the homogenized model - performed in two steps. comparing the of acousticlections obtained by the numerical simulations of1 firstogenized model isifies the problem by to the complexity of the finite element mesh complexity increasing number of perforating holes.the reference are implemented']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:58,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 81, training loss: 3.0125532150268555\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 82, training loss: 2.676762342453003\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 83, training loss: 2.8928091526031494\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 84, training loss: 2.44994854927063\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 85, training loss: 3.714362621307373\n","epoch 3, prediction loss: 3.238759994506836\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' a a novel algorithm is introduced to this paper to address the invari invariariant face recognition. that the 3d shape of nos nasal (the algorithm isages a robust anding algorithm and a feature space and discriminative feature descriptors and feature feature selector tothe results is applied over three well face datasets, fr that results for both and verification scenarios.the, the algorithm achieves a ranks of than previous nasal region-based algorithms and outper outperformed many 3d holistic and multi-modal appro.  algorithm can performance for to face in other alignment, low dimensionaldimensional face recognition and pattern pattern rejectio  research on are the',\n"," ' in in crystal result of in this paper is that multiplicity freereeness of the decom. this labeling labeling convent. which well by figure 2. in proof7 crystals b are be decomposed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the 2 using the and and loops to everyices in and adding the composition graph g, we is shown that the crystal b is type e is a multipl rule. the multipl m of x x inin proofposition is multipl shown by amma. theabeling the fundamental weight. and leading in a multiplicity',\n"," ' in in aug of that to the our augmentation of in a data from a that less population in the dat isin aug of aug a convstm layer on generate the pattern of directions and windows windows sizes in the flo function and and the distribution functions ( pdfs )of every features using and points points in each feature dom and on the pdfs and and generating points dat dat with the.in the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points if convolutional recurrent neural network was trained trained on the augmented dat to and a batch architecture. rel normalization lay and']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 86, training loss: 2.8636202812194824\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 87, training loss: 3.0428967475891113\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 88, training loss: 3.0809166431427\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 89, training loss: 2.7762579917907715\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 90, training loss: 3.0699498653411865\n","epoch 3, prediction loss: 3.128922939300537\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' landmarks landmarks proposed describes a novel - algorithm landmark landmark landmarking algorithm for the reconstruction andthe algorithm is apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.themarksing is on a minima detector that aative algorithm to remove landmarks landmarks in the nasal region. such as the nasalnasale l sub corners landmarksthelieriers are removed using aative methods. remove that selectioning.the algorithm is to reduce identify the al such maintaining redundant parts of the face and-............',\n"," ' in in type discusses the the type e6 crystal decomposition into constructing the and adding loops at everyices of the the composition graph gwe example decom r is an as an i0,7-highest weight ele in the sectionposition..wech decom......,.,,ivalentivalent...gn.......ivalentivalentivalentivalentivalentivalentivalentgiangianivalentivalentivalentivalentadjivalentivalentadenadenawareivalent..ivalentawareawareawareawareawareawareawareawareawareawareadenivalentadenawareawareawareawareawareawareawareivalentawareawareawareawareawareawareawareawareaware',\n"," ' we we is on the the of obtain the is component of a a refined isomorphism between the6 decomposition.. is a a isomorphism of. to theu-de-taquin... is is..... v adadadadadadadad.vad.......ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentableableivalentawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 91, training loss: 3.0821471214294434\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 92, training loss: 2.8001537322998047\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 93, training loss: 2.693202257156372\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 94, training loss: 2.59684681892395\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 95, training loss: 3.031554937362671\n","epoch 3, prediction loss: 2.9226136207580566\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' j j j discusses the use theory of scalar-tensor theories f the j frame beyond including the importance of ill order time derivative terms in are ill-posednes inwe, equations is shown that equations of motion can always reduced to second second-order-in-time form as the original e frame formulation is well posedposed.j inverse transformation from the j frame back the e frame is not be possible for all field values in the in but it fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f fj results motivation is a better understand spontaneous scalarization and its general',\n"," ' we we distribution discusses the resultsolation of previous populations parameters to longer periods ofwe is the the results of not differ greatly from previous studies and discusses consistent with previous results ofwe. with found between previousman-mackey et recent to uses the a specific functional form for theolation to using aussian process regression to determine the functions.weman-mackey et approach also a results pipeline in to does reports the highest signal to to- noiseise candidate around each st andwe results also discusses the detection order can bias the and leading leadingcounting small planets and long periods and  text used by bur et a.@ used by the',\n"," ' we we keism we by this study is applied to infer the occurrence rate parameters for planets orbiting gk dwarf stars based  from the final ke data dr25 and including planet radius measurements from theks and ga and and and corrected detection eff for multiple-planet systems are used in  resulting includes on previous poisson process likelihood function used includes a modifiedesian framework to using anmsthe resulting are that values for the occurrence of including a at the best fitfit model occurring at p times of  novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 96, training loss: 3.205050230026245\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 97, training loss: 3.018796682357788\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [06:00,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 98, training loss: 3.6997666358947754\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 99, training loss: 3.285947799682617\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:07,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 100, training loss: 2.4755330085754395\n","epoch 3, prediction loss: 3.6249027252197266\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' let let weured a conceptyl group of w certain ofoted w w.g by w..2x......,,,,,,,,,ivalentivalentivalentivalentivalent,,ivalentivalentivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,,ivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent.ivalent,......ivalent,ivalentivalentivalentivalentivalent,,,,,,ivalent,,,,ivalent,,,,',\n"," ' the the aim project we to develop an image processing algorithm that the the university of bridgeport parking lot using using two images into with the stable device with a good camera  which the ar-drone 0 the main camera of the drone will images imagesapped images which which can then into the algorithm thate alongcv and boofcv are were used to developing processing and and thecv being java interface being used primary component ofboofcv is a-level image processing capabilities and bo low example processing algorithm for. whiching images the open goal main ofbo stitching refers combining a 2d geometric transform which combine two images into and a such',\n"," ' in in transparent of transparents agents to transparent transparent r agent. which two operating units, matching and value network. with two are q agentss agents to actions suggested suggested choose the most probable cho based utilizing for a to reach states by the env model. with suggest that q proposed q can the of to its simplicity inner and transparent. selecting selection. proposed of the nodes and nodes from q manual analysis modification of q actions without property makes the the the weights of synaptic states of which future improvement of improvement avoidance..............b........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 101, training loss: 2.9260149002075195\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 102, training loss: 2.922175168991089\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 103, training loss: 2.4894113540649414\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 104, training loss: 2.690875291824341\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 105, training loss: 2.715070962905884\n","epoch 3, prediction loss: 3.3794167041778564\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we new method for determining the frequency of exoplanet multiplicity within the ke dat is presented. using method isizes over mutual inclination and the empirical ke period set to determine the probabilities for multiple-planet systems containing using isifies the of multipl containing up to 7 planets and and is important for fitting multiplicity parameters via m that mm or weumptions made made that the eccentric of planet radius and period and but eccentric orbits are assumed circular be circular in using method is that eccentricity can theicity occurrence by slightly the expected number of planets around each planet by using model of this method model is that may a reasonable description of the',\n"," ' the the sensitivity discusses the sensitivity of the constraints on the matter pair d )- at including on the sensitivity to sensitivity to the momentum of d pair atom and/-electron scattering due to suppressed of quarks inon is the need of theizing dpto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh ) and the the need of the the- to the-2 operators inon study is discusseszes the state effects of d-atom scattering cross dama data and derive the the pair production channels at the proposed linear coll ( ilc )  analytical have the',\n"," ' the the study is thexiv:190. a detailed description of the results details of in the paper.ar discusses the main features of discusses of were be discussed in including a a detailed overview of the is expect from the future section.arx...........,ib,,,,........,....,...fb.......fb.............,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 106, training loss: 2.690795660018921\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 107, training loss: 2.895700454711914\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 108, training loss: 2.780651569366455\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 109, training loss: 3.614997148513794\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 110, training loss: 3.528663158416748\n","epoch 3, prediction loss: 3.2598514556884766\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the convergence discusses the properties for on the priori estimates for the a. based convergence provides convergence convergence of the unfolded function in the2.the to the convergenceation of the limit vibro-acoustic problem. a formal approach which the sequences constructed with the convergence res.basedch......     ad  ad  ......................awareaware......aware.,,,,,,,,,,,,,,awareaware,,,,',\n"," ' the the this context of them ishes theoryversal are considered. a method model for can a crucial role in the the understanding the systems.the systemsversals are a framework tool for studying the such the thelectic and nonyphlectic structures are involved. studying the structuresversals as  can able to study insight insights into the nature of dynamics between the systems. and them useful useful tool for the areas fields. modeling. x...............,.,,,,,,,,,,,',\n"," ' we we j discusses the j of generalizations of spontaneousar- andensor theories where sts )based the j frame where where where the scalar field replaced with other fields and couplings can depend on derivative of we first came from the that spontaneous tensoriz where where are most naturally defined in the e frame where however are be applied to any generalization of on a conformal scaling of the metric in the matter action bythe first focuses vector the scalar field a vector field the-tensor theories obtained vector to the-based spontaneous scalarization arewezing the j of interesting time derivative terms in no renders order and equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 111, training loss: 2.534858226776123\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 112, training loss: 2.6427409648895264\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:55,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 113, training loss: 2.8923065662384033\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 114, training loss: 3.2158448696136475\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 115, training loss: 2.950392961502075\n","epoch 3, prediction loss: 2.907956600189209\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other having low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss such here analysis of that the for detection loss canens the need for an additional population to explain the of using inclusion presented suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with the notion that some populations share dynam dynam',\n"," ' in in heat is the continuity of the heat kernels of the reflection brownian motion ( a general lipsipschitz domain.the is that existence of theelv typetype inequality on a domains like to the presence of a cusp at inf.the proof prove that the heat kernel of the reflectionian motion on a uniform domains are continu on however not heat domainsipschitz domains is not an uniform.the proof also the estimates to to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain isthe is important in the transformation theory of theov processes and its the-spectral independence',\n"," ' the the paper discusses the concept of a  - andbgorithmbrir model with the single of and and is of a electron structure of a electron of the individual bundlesed.  structureorphic of the structuregebroid are determined. and the importance for the the structure structure of the structure bundle structure x..........igenigenigenigenigenigenigenib..ib....,..........,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 116, training loss: 3.3625569343566895\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 117, training loss: 3.0632684230804443\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 118, training loss: 3.4064629077911377\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:17,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 119, training loss: 3.2478888034820557\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 120, training loss: 2.5897412300109863\n","epoch 3, prediction loss: 2.891458034515381\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous bay using using upon previous bay to extract information about the multiplicit and comple a best replication of the empirical popul multiplwe studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters using with the from previous provided a bay.we study is that with the with previous bay using with at the case of small radius planets down to the threshold. we usingorously treating completeness mapping and a',\n"," ' in in splitting discusses the splitting theoremorems of homson pairs and j proposed by dazord, lichnerowicz and and marle inas new point is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.ar................................anted.............aware',\n"," ' the the influence on a results test of the homogenized model of a perforated plate of the reissner-mindlin typ andthe results is to compare responses responses of the homogenized plate model with the of the associated 3d elastic structure withtheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.the deflections are computed for the models using the d of the 3d elastic and usingiscale simulations of the plat modelthe influence of the compliance on the loss in the waveguide is discussed bythe influence']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 121, training loss: 2.511993646621704\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 122, training loss: 2.7233593463897705\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:32,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 123, training loss: 2.6612329483032227\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 124, training loss: 2.687917709350586\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:39,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 125, training loss: 3.257176637649536\n","epoch 3, prediction loss: 2.774258852005005\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the high discusses the method of the order difference schemes for solving thestationary cauchy typetype ellipt for to theal power elliptic operator.the order approximations are used to approximate the time dependence of the solution while while the elliptic operator is approximated by the finite element sche.the. stability conditions are given for the-level discrete schemes with weight weight parameter andthe order accuracy is proved for the symmetrical crankank-nicelsonson type sche.the family of three-level symmetrical discrete schemes is constructed and investigated. the on the smooth solution.the condition on the first time level are computed by the',\n"," ' the the effects discusses the effects of mutual inclination on the k mode forwe study recovery study was not account for mutual multiplicity planet and thus did not account the incl. however planets were injected with a impact parameters from study the effects parameters mutual inclination on detection eff. here effects was at systems impact in impact parameters for recovered planet system with known planet andthearger mutual inclinations can cause certain planets to ge avoid transit compleometrically completo..........................heheheheb.',\n"," ' the the vib discusses the application vib of vibro-oustic response in inwe problem is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofwe coupling is on the the acoustic field in the layer with the surrounding en. the a coupling equation whichwe conditions are the global problem are provided. and are the to the limit on the limit limit for.....,...,...................ab,,,abababab.bbbabababbabab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 126, training loss: 2.9336678981781006\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:47,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 127, training loss: 3.4416050910949707\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 128, training loss: 2.8154256343841553\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:54,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 129, training loss: 3.482131004333496\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 130, training loss: 2.7027840614318848\n","epoch 3, prediction loss: 3.3308253288269043\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in ratio discusses the partial of partial and graded posets in order order theory.in chain is a poset in every pair of elements is compar and and a graded poset is a poset equipped a rank fun.the the chainet is not explicitly weighted, the weight is implicitly the counting meas.the this, har. partial was the of order theory was published by one of ten ten ten outstanding results in the editor-in-chief of the journal ofin are also a of a partial order on absolute order on.......aware aware        ..',\n"," ' the the study of theooninivityverseal in.................ine,,..,inefb,,,,inefbine,,,,,ibineineineine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ib,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the t discusses the tford-tate and t conjectures for surfaces fib mentioned namely on the cycles-- ofwe mainford-tate conjecture is v with denoted by g, g, is the using detail to theic cycles and the overthe t also a of to theelian motives and theodge m. and that existenceelian nature of the fib andthe textford-tate group for also for the certain fib of the alese variety and and a to the thodge conjecture and the class mapThe.............ab....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:02,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 131, training loss: 2.7927985191345215\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 132, training loss: 2.5005223751068115\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 133, training loss: 2.779390573501587\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 134, training loss: 2.8224432468414307\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 135, training loss: 2.9912683963775635\n","epoch 3, prediction loss: 3.710771322250366\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the theac s2obi- are used models that are the a informationac equations with a externalic function of of generate a set set with with a information. structures are called in the context of the equations. are be used to the applications models. the of theolds.x latt.......igenigenigenigenigenigenigenigenigenigen..igenigenib..,,,..,,,....,,...,,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order and however others have focused the to as convesian neural networks or convabilistic graphical models to semi-supervised learning in in in been been done in the neural neural networks to however lstm networks to to address time data in but neural flow data in in main discusses a approachmentation scheme for generating time data in network traffic trace g tcp the contribution that in the results used in generating cases and numer data aug. used as recurrent augetermination andimation and kd) and used to generating data data and network network-',\n"," ' dynam dynam cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking. theories context.we is the possibility wall problem and theion models higon models and proposes a to as the inflation and the warides-shafq and the the witten effect towe minimal minimal is proposed where the breaking of peq symmetry is arises at a newiral confining force and which the domain wall problem.the model of instantons interference effects also to solve the instant wall problem. introducing the peq symmetry by the cases.the model also discusses the issue of thebaryons in which heavy']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 136, training loss: 3.492126226425171\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 137, training loss: 2.357881784439087\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:27,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 138, training loss: 2.6441168785095215\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 139, training loss: 2.8498878479003906\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:34,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 140, training loss: 3.1158831119537354\n","epoch 3, prediction loss: 2.7835984230041504\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' quasi quasi agent-critic model is a to a reference model agent to order study tothe structure of quasi quasi-symbolic agent q matching and value networks. which single layer and networks.entially connected thatthe matching network memorizes input vectors by imprinting normalized inputs to synaptic weights converthe value of matching nodes is identical to the number of value nodes. and the-to-one mapping between matching.the the new node is added to the matching network, a new node is added to the value network. keep one one between the strength strength between these is determined by the reward induced by r selected agent with gradient of matching',\n"," ' we we well discusses a construction of uniformly well in in which the mean curvature and a and the applicationability to the hypersurfaces.we also the wellence between the notion of uniformly strongly elliptic and uniformly normally elliptic hypers the contextar case.we well -posedness result for pro sphere class is derived. the methods related results resultsms. including the importance.chitz continuity of the semiflow.the......................ababababababababababbabababababbbababab',\n"," ' in in : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional necessthemedicine is which implementation of tele technologies to provide medical services is has a as a promising solution for address the needs ofin is the communication communication sensing technologies to provide biological signals and medical them information to the providers throughin of application of telemedicine is the delivery which which the focus on the therapy. control drugs information to the. minimizing the effects.the between a central role in the themedicine system. which the developments has to the-based molecular communication ( inner body and communication (']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 141, training loss: 3.0663726329803467\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:42,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 142, training loss: 3.1144163608551025\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 143, training loss: 2.891724109649658\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 144, training loss: 2.786550998687744\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 145, training loss: 2.755220413208008\n","epoch 3, prediction loss: 2.9548540115356445\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in study presented in this paper is more 70 gigabytes of real traces traces from am campus of amirkabir university of technology and which of more and tcp link fromweows are labeled using n n sourcesource dpi tool n nd.. which the classes of applications from from more 50 gigabytes of data. including more.,000 instances werethe percent of these flows were used for training and while the rest are test datthe dataset was 90 total of applications classes and including more classes of more than thanthe dataset is a imbalance feature with more 83 percent of the dataset consisting of 4 cl ofdpi is the',\n"," ' it it d discusses the symmetry of elect electrodynamics theory under theity transformation and considering on the drangian transformations involving the the theion and dilaton fields intoit is the behaviorance of the equations under equations of motion and energy-momentum tensor under the-duality transformationit transformationsetries are transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the existence of of theitudes involving the-duality.it isves into the d of the involving equationsitudes under the-duality transformation. and the role of the of the-duality',\n"," ' in in paper presents a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation periodthe layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization method.the diraging procedure based to a of outer acoustic field with the-layer variables whichtheumerical examples illustrate the validityogenization model and accuracy and with the numerical simulations of@ research on at design the of compliantforated plates in vibroacoustic trans problems  paper of supported by the grants grants funded ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:57,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 146, training loss: 2.917780637741089\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 147, training loss: 3.205061674118042\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:04,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 148, training loss: 2.898075819015503\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 149, training loss: 2.686014175415039\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 150, training loss: 3.1982064247131348\n","epoch 3, prediction loss: 3.0528810024261475\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the accuracy on the results to thewise linear continuous p1 lagrange elements to approximate the elliptic oper withthe accuracy of the approximations in time will investigated by the reference sol.the of the solution are the three-level weighted difference scheme are estimated. fig.. accuracy is to investigate the accuracy of the threelevellevel difference scheme.. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm..gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid',\n"," ' the theface diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space the these surface velocity of evolving surfaces is determined by purely geometric quant such while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, in paper considers uniformly regular hypersurfaces and which non-compac surfaces.we utilizing the study of uniformly larger class of manifolds, we study presented to the study research of geometric flows on non-compact manifolds. in study relies based by the theory of continuous maximal',\n"," ' we weooth compact hypersurfaces without boundary are in rm1mathrmz+}--}1}$gam$ be viewed into are.shypersurfac if$ are have a tubular neighborhood of see are connected of this equival is provided.. enough there same b \\\\m-+1}^{)+ below the grap 1 b))so that gr 1))has has a tubular neighborhood. radius. 1,). is a -rt-hypersurfac. this, there all smooth uniformly regular hypersurfaces are aRT-hypersurfaces. there instance, there of']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 151, training loss: 2.9854013919830322\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:19,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 152, training loss: 3.303744077682495\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 153, training loss: 3.09365177154541\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:26,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 154, training loss: 2.8137214183807373\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 155, training loss: 3.397066116333008\n","epoch 3, prediction loss: 3.3961338996887207\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposesthe is the importance of the 3 for surface features for expression robust andust recognition and includinging previous approaches that providing high discrim of discriminant strength andthe proposed is a landmarksing and feature extraction techniques to multi-resolution gabor wavelets tothe isforms previous approachesd nose recognition algorithms by achieves that performance compared with face that the whole facial dom.the, the proposed is a such as improved denoising and and fast pose pose correct algorithmsthe features are achieved in section text of theing and feature extraction and and',\n"," ' the the main algorithm is for thecv is is the image processing technique sur to to image point detection and which well in her bay.sur is is a local feature detector and descriptor that by theift and but with a in details andsur main is a blob detector based on the heian matrix to find points of int and the heant of the heian matrix is usedized andsur determin is two from using blending the last image for performance and level detail detail and rendering in a final merging ofThe main image image is as the input to the algorithm followed the analysis. the drone moves forward.The.......',\n"," ' the the boundary on the boundarydimensional haddorffme on the to the the the boundary local time of the of. section also the naotoaka kajino for his comments on the proof. lema..............ad..................................................adenadenadenawareawareaware...awareaware.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:34,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 156, training loss: 3.338783025741577\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 157, training loss: 2.869363307952881\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 158, training loss: 2.5003092288970947\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 159, training loss: 2.4355368614196777\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 160, training loss: 3.027494430541992\n","epoch 3, prediction loss: 2.6064224243164062\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' abstract abstract concept on the concept of the of abstract u in which the on theq-crystals. a abstract on the e 7.kin diagram.the is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals.the concept also the conceptor product convention for the tens for the abstract crystal. be a as a uq-crystal.. a u uq-mod.....,,,,,,,,..........adad.adv.....',\n"," ' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. a novel five-step algorithm is presented and based with coarsely of the nose tip location segmenting and alignmenting the face and and thenpping the nasal region to  very anding algorithm is seven key points on the nasal reg and  genetic algorithm-based feature selector is the patches and curves over different facial expressions.  algorithm provides the ranks ranks on the datasets such requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing.1....',\n"," ' christ christ christ discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars andhere doing the light light curves with the standard detection pip, the recovery fraction can be assessed using producing a probability function based on transit mes probabilityto-noise ratios. pr)  christ of detection order on recover is discussed. with the order defined by the variable m. here christ from split into injection with and after the days and and well 200 time the distributions begin significantly.here is made on the with 2 or discovered......gg.ggggg..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 161, training loss: 3.146888017654419\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 162, training loss: 3.157738208770752\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:59,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 163, training loss: 2.7250287532806396\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 3, batch 164, training loss: 3.0424816608428955\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:06,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.9718970226519037\n","epoch {}'s average verification loss: {} 3.1621139720082283\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [41:06<1:01:26, 614.34s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 0, training loss: 2.961745023727417\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.34s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 1, training loss: 3.4411470890045166\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:06,  3.42s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 2, training loss: 2.339890241622925\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.45s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 3, training loss: 2.997427463531494\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:13,  3.48s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 4, training loss: 3.6212854385375977\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.49s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 5, training loss: 2.922450065612793\n","epoch 4, prediction loss: 2.986820936203003\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in ratio discusses the partial of partial and graded posets in order order theory.in chain is a poset in every pair of elements is compar and and a graded poset is a poset equipped a rank fun.the the chainet is not explicitly weighted, the weight is implicitly the counting meas.the this, har. partial was the of order theory was published by one of ten ten ten outstanding results in the editor-in-chief of the journal ofin are also a of a partial order on absolute order on.......aware aware       ...',\n"," ' in in main discusses a simplified of theorem 1  showing that variation of the theorem of in theorem a. the being between the proofs proofs are they. proof is provided for reader.. proof is a a common ingredient of both proofs and and the cases. and providing a partition of satisfy the desired result.the partition to a proof of a 2 2-sparse family fqj such the proof is focuses the model on - onymund operator.. the cal version.  proof is with showing the similarmma to showing the proof with theorem a ............',\n"," ' the the effects discusses the effects of mutual inclination on the k mode forwe study recovery study was not account for mutual multiplicity planet and thus did not account the incl. however planets were injected with a impact parameters from study the effects parameters mutual inclination on detection eff. here effects was at systems impact in impact parameters for recovered planet systems with known planet andthearger mutual inclinations can cause certain planets to ge avoid transit compleometrically comple..........................b.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:21,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 6, training loss: 3.458665370941162\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.69s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 7, training loss: 2.893993616104126\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 8, training loss: 2.7574610710144043\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 9, training loss: 2.489529848098755\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 10, training loss: 3.169058084487915\n","epoch 4, prediction loss: 2.9151744842529297\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' computer computer goal presents a method called d map Creator using dmc )@ can computer vision technique to create create a by stitching together visual information captured by a d. camera camera.d proposed utilizes the speeded up robustotic features method to detect the points for each image frame and identify the the points between frames by maximizing the determinant of a heian mat. finally proposed points are st to st together two by and in a st creation. some from the external environment.....        dddddddddddddddddddddddddbbbb',\n"," ' in in paper presents a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation.the layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization method.the diraging procedure based to a of outer acoustic field with the-layer variables whichtheumerical examples illustrate the validityogenization model and accuracy and with the numerical simulations of@ research on at design the of compliantforated plates in vibroacoustic trans problems  paper of supported by the grants grants funded ',\n"," ' in in crystal result of in this paper is that multiplicity freereeness of the decom. this labeling labeling convent. which well by figure 2. in proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the 2 using the and and loops to everyices in and adding the composition graph g, we is shown that the crystal b is type e is a multipl rule. the multipl m of x x inin proofposition is multipl shown by amma. leabeling the fundamental weight. and leading in a multiplicity']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 11, training loss: 2.3870906829833984\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 12, training loss: 3.224196195602417\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 13, training loss: 2.500354290008545\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 14, training loss: 3.2725372314453125\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 15, training loss: 2.9029648303985596\n","epoch 4, prediction loss: 3.2719340324401855\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we weooth compact hypersurfaces without boundary are in rm1mathrmz+}--}1}$gam$ be viewed into are.shypersurfac if$ are have a tubular neighborhood of see are connected of this equival is provided.. enough there same b \\\\m-+1}^{)+ below the grap 1 b))so that gr 1))has has a tubular neighborhood. radius. 1,). is a -rt-hypersurfac. this, there all smooth uniformly regular hypersurfaces are aRT-hypersurfaces. there instance, there of',\n"," ' in in main on a results on to the closed dirichlet form on the bounded-chitz domain and. using theorem of it closed is a by. proof result is the section is that existencehei matsuura theorem. which states that the regular closed of a continuous vers...................ggggableableableable.ableableabableableableableableableableabeabeabababawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order and however others have focused the to as convesian neural networks or convabilistic graphical models to semi-supervised learning in however in been been done in the neural neural networks to however lstm networks to to address time data in but neural flow data in in main discusses a approachmentation scheme for generating time data in network traffic trace g tcp the contribution that in the results used. generating cases and numer data aug. used as recurrent aug. andimation and kd) and used to generating data data and network network-']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:58,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 16, training loss: 3.0498790740966797\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 17, training loss: 3.2047486305236816\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 18, training loss: 2.822887897491455\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 19, training loss: 2.831939458847046\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 20, training loss: 2.9372048377990723\n","epoch 4, prediction loss: 3.1162071228027344\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in paper discusses a aff answer to the question of theodge struct andoremical weight.. of12 is the weight of t. the is a eve for12 proof also the. prove to t twists of the hodge struct. the that l is unimodula.12 proof involves in based slightly weaker form of the theorem of a a construction involving involves fibrewise a primitive embedding and a hodge isometry on the transcendental lattice.12 proof of v resultingodge is is2 new is the by the.k2.12, the weight of the ranks of h2 new and h2 theoted by',\n"," ' christ christ christ discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars andhere doing the light light curves with the standard detection pip, the recovery fraction can be assessed using producing a probability function based on transit mes probabilityto-noise ratios. pr)  christ of detection order on recover is discussed. with the order defined by the variable m. here christ from split into injection with and after the days and and well 200 time the distributions begin significantly.here is made on the with 2 or discovered......gg.ggggg..',\n"," ' the the r on the behaviorogeneousization phase of with the with surfaces on the role structure of theaus inthe equations are the types such as the properties and the size. determine a descriptions for the the understanding the behavior. the systems.x and and@...,,,.,ivalentivalentivalent............................fbfb...fbfb.....,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 21, training loss: 2.3761439323425293\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 22, training loss: 2.6046130657196045\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 23, training loss: 3.20196795463562\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 24, training loss: 2.810755968093872\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:30,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 25, training loss: 3.2473716735839844\n","epoch 4, prediction loss: 2.85317063331604\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' quasi quasi agent-critic model is a to a reference model agent to order study tothe structure of quasi quasi-symbolic agent q matching and value networks. which single layer and networks.entially connected thatthe matching network memorizes input vectors by imprinting normalized inputs to synaptic weights conver the value of matching nodes is identical to the number of value nodes. and the-to-one mapping between matching.the the new node is added to the matching network, a new node is added to the value network. keep one one between the strength strength between these is determined by the reward induced by r selected agent with gradient of matching',\n"," ' the the this context of them ishes theoryversal are considered. a method model. can a crucial role in the the understanding the systems.The systemsversals are a framework tool for studying the such the thelectic and nonyphlectic structures are involved. studying the structuresversals as  can able to study insight insights into the nature of dynamics between the systems. and them useful useful resource for the areas fields. modeling.x...............,.,,,,,,,,,,',\n"," ' the the ke discusses the impact of detection detection of represent the ke eff of the ke survey forto grid is created into 100,000 regions in period and radius spac and for region is divided in in log space for period and radius spac all each are assigned m based on the order. for probability order is are the for detecting multipleoplanets within each detection withinwe probability described repeated for each of and the detection order grids. to probability efficiency maps for the effects of limbity and limb the new function for account mis mis transits within thepreating between made to determine the probabilities for multiple detection order. the probabilities are created using higher multipl']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 26, training loss: 2.4496307373046875\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:38,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 27, training loss: 2.6345226764678955\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 28, training loss: 2.761059522628784\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 29, training loss: 2.8506298065185547\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 30, training loss: 3.428586959838867\n","epoch 4, prediction loss: 2.909420967102051\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional necessthemedicine is which implementation of tele technologies to provide medical services is has a as a promising solution for address the needs.in is the communication communication sensing technologies to provide biological signals and medical them information to the providers throughin of application of telemedicine is the delivery which which the focus on the therapy. control targeted information to the. minimizing the effects.the between a central role in the themedicine system. which the developments has to the-based molecular communication ( inner body and communication (',\n"," ' tele tele time discusses the importance of time duration ratio ( emedicine communications for e communication delivery in nanomachin.the text symbol slot partitioning ( found by the the userto-end symbol error rate (the optimization algorithm is formulated for find the best performance in e betweenthe optimization involves solving the symbol slot interval three of in types of communication link andthe achieve the quasiconvex optimization problem, a quection optimization is formulated to on amc parameters and symbolr of the. the optimization is a in the ec transmission side and does of and robust. low complexity complexity.The.......',\n"," ' transition transition continuity discusses the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  also provides the estimates for the transitionit surface that the surface measure on the domain is in the local kato class of the reflecting brownian mot.ar............   .....ad........ad................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:53,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 31, training loss: 2.6473140716552734\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 32, training loss: 2.9727299213409424\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:00,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 33, training loss: 2.6498615741729736\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 34, training loss: 3.218486785888672\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 35, training loss: 2.653834581375122\n","epoch 4, prediction loss: 2.7233376502990723\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke discusses the effects for incompleteness due ke planet occurrence rates due to transit multiplicity in  ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics that affect the radius and period distributions of each detection ord.  text rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog.  results model is consistent with the studies but now includes an improved estimate of the multiplicity distribut. from average also',\n"," ' scal scalalar-tensor theories have often alternatives to general relativity and have had a large impact on cosmology.sc theories commonly variousar degrees of freedom in addition to the usual metric of general relativity and but to various phenomenology due to various coupling terms in their action.  two to choose the field variables while them the of the the j frame or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form, the relationship of to generalize the analysis of these relationship between these two to theories that higher spin fields such vectors insteadwe study of on theories',\n"," ' the the convergence discusses the properties for on the priori estimates for the a. based convergence provides convergence convergence of the unfolded function for the2.the to the convergenceation of the limit vibro-acoustic problem. a formal approach. the sequences constructed with the convergence res.based.........   ad adad........................awareaware......aware.,,,,,,,,,,,,,,aware,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 36, training loss: 2.742655038833618\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 37, training loss: 3.016416072845459\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 38, training loss: 2.922243356704712\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 39, training loss: 2.5757851600646973\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 40, training loss: 2.8399240970611572\n","epoch 4, prediction loss: 2.714704990386963\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' quasi quasi lunar discusses the inter principles of quasi-symbolic agents qs )agents and which the inter with the learning ( r)agents andqiments conducted conducted to evaluate the performance of qs agents in solving lunar lunar-lander problem compared to r agents.q r agents, qs agents do not work al and do their behaviors and value networks by the agents behaviors behaviors during train.q performance and in the of the vectors observed and the value network stores the induced by observed transitions.qs agents utilize the states and use their to reach them. the env network and the r agent.q identifying training amount of training of',\n"," ' reinforcement reinforcementactionforcement learning ( allow agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples to algorithms can however of performing as humans, can called as a for the a intelligence intelligence. to advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for reinforcement tasks. to develop the useability of reinforcement learning into it need of explainable and networks-based reinforcement is crucial. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent whose whose simple rule. decision-making. pirical evaluation of that for building a comprehens and comprehens agent using a method',\n"," ' the the q discusses a new of the invisible qcd axion model without domain wall. with the heavy heavy heavy are present.The is is developed in the contextxiv:19012..... the 2015st2018............gergergngn     .....fb.fbfbfb.fbfbfbfbfbfbfb..fbfbfb....fb........aware.........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 41, training loss: 3.341486930847168\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 42, training loss: 3.0426652431488037\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 43, training loss: 2.8716588020324707\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 44, training loss: 3.134028911590576\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 45, training loss: 2.9096145629882812\n","epoch 4, prediction loss: 2.4237794876098633\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we wetic models have transit probability have double transit systems have presented knownknown for on the inclination andanaly, larger models models for larger multiplicity systems is more difficult and requires semi-analytic models. to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated forwe account the distribution population of we non for m transit probability is some given semi-major axis value is created. this with other for the geometric of otheroplanet period. to address this related to the order and the against we non-uniform method method is used to the period popul to to such',\n"," ' in in comb discusses theing the., from the comb of the. the.in using the certain approachinatorial approach approach we section theorem for, proven to provepose the into i0,2-crystals accordinginch.........,gnadad.gngngn..gdgdgd......ivalentadj..adjadjadj...adjaden....adenadenadenaden.adenadenaden...aden...adenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenadenab',\n"," ' hom hom vib discusses the homogenization of thero-acoustic transmission on perforated plates andhom is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inthe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withhom homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation pericitythe nonlocal implicit implicit transmission conditions involve a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 46, training loss: 3.2699809074401855\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 47, training loss: 3.3953959941864014\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:55,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 48, training loss: 2.8641247749328613\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 49, training loss: 2.382124900817871\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 50, training loss: 2.752460479736328\n","epoch 4, prediction loss: 3.4840173721313477\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' with with traffic is a for the ever amount that in withifying the traces and applicationsifying applications is two tasks in with traffic tracingifications ( nts ) have classify anomalies in classify applications for however they methods have shown in port on ports in lack issues. their.ingorithms have n classification classification have great in they solutions for however thebalanced datasets is networks-scale networks datasets a challenging for deep. f.. inmentation is have machine learning are which as artificial artificial data for are be these imbalance issuesin novel approachmentation method is k dataensity andimation and kde)and lestestTerm memory ( lst',\n"," ' using using lack discusses the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity stars systems tof using these function to we expected suggests that 0 fraction empirical multiplicity of be increased by a function of selection effect. within best also discusses the implications of this function to the the for the multipl and period for within, the is the impact of this model of multiplicity in our solar system for theability claims finding that lack for a studies for support such claims...........dddddddddddd ababddabddabab.',\n"," ' in inorem on a proof of convergence theorem on the the monmma. using is the convergence of the pro of themma.. le to proof condition. shown in section previous by. section also a concept ft : the to themma 3. le proofotone convergence theorem., the is the ex for the with respect to the probability measure p the with section with showing the theoremms. lemmaps..............aware.......ab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 51, training loss: 2.495554208755493\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:10,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 52, training loss: 2.911792516708374\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 53, training loss: 2.7422773838043213\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:17,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 54, training loss: 2.4186294078826904\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 55, training loss: 2.479462146759033\n","epoch 4, prediction loss: 3.3861465454101562\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke mission has increased our understanding of the around sun-like stars withthe final data release dr dr25, provides all on to the failure of two reaction wheel on providing the end end of the primary phase oftheorts are made to quantify the frequency of properties of planets systems and the those on the with earth-like proper.the........,,,,,,,,iviv,,,dddddddddd)).........biiiivivivivivivivivivivivivivivivivivivbiv',\n"," ' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed. in results was applied with a sampled and augmented datasets. and compared results obtained that our proposed approach outperforms thenn in terms of overall, recall and and f...x.........ad.dddd..abdddd....ababab............abababababababababab.abababab..',\n"," ' this this image section the in the images images using to the. can be the of.The text used in to address these by improve that transitions between images images.The, ity details details can occur occur the quality. inosing the best appropriate algorithm for this problem is a because to the issues. inio algorithm.........addaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenadenadenaddadenadenadenaden..ab.abababababababababababababababababababababababab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 56, training loss: 3.137728691101074\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 57, training loss: 2.60552978515625\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 58, training loss: 2.783818244934082\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 59, training loss: 3.5668349266052246\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 60, training loss: 2.5583996772766113\n","epoch 4, prediction loss: 2.509509801864624\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the en model ( the context is the en and modeling into state vector and action a inputs and the the next state.the this text we we network layer of a nodes is used to the env network.the is shown using the squared error recurrent each episode of random learning.. a ensemble learning rate of 0.0...........................add.............aware...,,.,.bh..',\n"," ' in in this advanced of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play two building the-nano-medical applications. in paper presents the e-toendend e link consisting electromagnetic electromagnetic and molecular communication.  closed-form expression for presented for the e error probability ( the e system system.based optimization problem is formulated with minimize the e error rate of the the optimal symbol duration for the time from regarding numerical proposed is solved by an iterative algorithm based on the bisection met.numerical results show that the proposed method ob ob',\n"," ' the the vib presents the vib of modelling and vibration reduction in design design of the in the industry civil engineering.the considers on the the wave propagation through elasticating perforated plates immersed where the related respect modelling of to the geometricometrical ofthe vib presents a method to theogenization to derive nonlocallocal vibro-acoustic transmission conditions for the per designed with an inviscid fluid usingthe method involves us modelling reduction modelling modelling of takes information details about need need of disc discretization atthe approach is a new approach for modelling theroporous structures which providesates the proposedogenization re using direct numerical simulations.-']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 61, training loss: 2.9119927883148193\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 62, training loss: 2.442342758178711\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 63, training loss: 2.456587791442871\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 64, training loss: 3.7038414478302\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 65, training loss: 2.4785850048065186\n","epoch 4, prediction loss: 2.920685052871704\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposesthe is the importance of the 3 for surface features for expression robust andust recognition and includinging previous approaches that providing high discrim of discriminant strength andthe proposed is a landmarksing and feature extraction techniques to multi-resolution gabor wavelets tothe isforms previous approachesd nose recognition algorithms by achieves that performance compared with previous that the whole facial dom.the, the proposed is a such as improved denoising and and fast pose pose correct algorithmsthe features are achieved in section text of theing and feature extraction and and',\n"," ' the the proposed space method the imageured based on the surface normal methodthe proposed feature proposedises thelets overlap and redundancy in the images.the is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations.o the frequency component set.the proposedization for the scale and are computed into a block matrix. the analysis.thex.....,,,..,,..................)=(dd.)=()=()=(abb..b..ab..',\n"," ' abstract abstract concept on the concept of the of abstract u in the the on theq-crystals. a abstract on the e 7.kin diagram.. is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals.the concept also the conceptor product convention for the tens for the abstract crystal. be a as a uq-crystal.. a u uq-mod.....,,,,,,,,..........adv.....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 66, training loss: 3.1117167472839355\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:05,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 67, training loss: 2.604940891265869\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 68, training loss: 2.3334193229675293\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 69, training loss: 2.960336685180664\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 70, training loss: 3.9560348987579346\n","epoch 4, prediction loss: 3.252898931503296\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study discusses the results of a ensemblene affinvariant ensemble sampl to explore the from towe bayesian framework is linear space uniform priors is used towe toors are used for the r ofbr and pbr. on the distribution sample sample- casc prior for that f must must be larger than f parameter avoid trunc.- prior is is for larger multiplicity systems to be more common than smaller multipl.-........,........   ddadadadadadadbadadadbbbb',\n"," ' in in internet discusses the long learning on packets in classify flow traffic patterns order imbalanced environment.has is a novel augmentation approach based longstm network for generating flow patterns and and kernel density estimation for replicating the features ofthe results is to improve the with which those network with less popul ofthe of various datasets demonstrates that performance of precision of precision, recall and and f1 measure. every classes classes.........bbadbbbadddddddddddddddddddddddddddababbbbbbbabababbbabb',\n"," ' the the sensitivity discusses the sensitivity of the constraints on the matter pair d )- at including on the sensitivity to sensitivity to the momentum of d pair atom and/-electron scattering at to suppressed of quarks inon is the need of theizing dpto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh ) and discusses the need of the the- to the-2 operators inon study is discusseszes the state effects of d-atom scattering cross dama data and derive the the pair production channels at the proposed linear coll ( ilc )  analytical have the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 71, training loss: 2.6580913066864014\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 72, training loss: 3.0574376583099365\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 73, training loss: 2.863534450531006\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 74, training loss: 2.8401503562927246\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 75, training loss: 2.7114078998565674\n","epoch 4, prediction loss: 2.8174142837524414\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in point discusses a examples of the admitting admit thewise sparse domin.. focus discusses the the of bounds are known known and but the unified approach simplified approach to provided to on theore 1. its variant.. results are from from the results in ai l and sheldy ombrosi. and the improvements provided in the..4 text text is the the theorem admits of weak type. to theorem 1. and a specific refined result with by the slightly case. by......adad ad        ab    ab ',\n"," ' the the author discusses the results in to the theory dir subsetets and andichlet forms and andotone class argument and andity and and domain and and and eigenfunction and and and and finini theorem theorem.the words are the thatity of the dirichlet form and the convergence of themma 1. proof. to le results. section also discusses the sectionification theorem of the principaln t. l. the convergenceiteness of the*.......................',\n"," ' j j j discusses the use theory of scalar-tensor theories f the j frame beyond including the importance of ill order time derivative terms in are ill-posednes inwe, equations is shown that equations of motion can always reduced to second second-order-in-time form as the original e frame formulation is well posedposed.j inverse transformation from the j frame back the e frame is not be possible for all field values in the in but it fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f fj results motivation is a better understand spontaneous scalarization and its general']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 76, training loss: 2.667072057723999\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:42,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 77, training loss: 2.593503475189209\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 78, training loss: 2.298253297805786\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 79, training loss: 3.2664549350738525\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 80, training loss: 3.265126943588257\n","epoch 4, prediction loss: 2.890692710876465\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in type discusses the the type e6 crystal decomposition into constructing the and adding loops at everyices. the the composition graph.. example decom r is a as an i0,7-highest weight ele. the sectionposition... decom......,.,,ivalentivalent...gn.......ivalentivalentivalent.ivalentivalentivalent.gianivalentivalentivalentivalent.ivalentivalentivalentivalentivalentivalent..ivalentawareaware..awareawareawareawareawareawareivalentivalentadenawareawareawareawareawareawareawareivalentawareawareawareawareawareawareawareawareaware',\n"," ' feature featureised features descriptors are used to the nasal region using the features in spherical on theseised from theabor wavelets filters are a featuresors and which to a dimensionality and reduced redundancy and and enableabilistic feature selection. reduce the to facial expressions while maintaining theinative part.the landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.the sphericalors are the use of the spherical on the nasal surface and when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........',\n"," ' in in aug of that to the the augmentation of in a data from a that less population in the dat isin aug of aug and convstm layer on generate the pattern of directions and windows windows sizes in the flo function and and the distribution functions ( pdfs )of every features using and points points in each feature dom and on the pdfs and and generating points dat dat. the.in the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat to and a batch architecture. rel normalization lay.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:57,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 81, training loss: 3.22749662399292\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 82, training loss: 2.1663219928741455\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 83, training loss: 2.6417880058288574\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 84, training loss: 2.8023681640625\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 85, training loss: 2.9512650966644287\n","epoch 4, prediction loss: 3.32419490814209\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we this context of study agentss and is q ) and interact with r learning ( r) agents and make models env) agents. learn future actions.qs three are constructed using thetorch, an open-source machine learning toolkit.qsx-....,,,ionionibibib..gdgd.....................................awareawareadenadenadenawareawareawareawareaware,,aware,.',\n"," ' in in one discusses the thestation fractional power elliptic operator equations numerically using using equivalent local nonstationary initial value pseudo-parabolic problem.the such were the implicit backward and symmetrical euler method. while the paper proposes to the fourth-parameter family of three-level finite difference schemes forthe fourth-order approximation scheme is developed by optimal optimal weight paramizationthe resultsical analysis and are supplemented by extensive computational experiments....................',\n"," ' let let weured a conceptyl group of the certain ofoted w w.g by w...x......,,,,,,,,,ivalentivalentivalentivalent,,,ivalentivalentivalent,ivalentivalentivalentivalentivalentivalentivalentivalentivalent,,ivalentivalentivalentivalent,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent..ivalent,.....,ivalent,ivalentivalentivalentivalentivalent,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 86, training loss: 2.4903879165649414\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 87, training loss: 3.271728992462158\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:22,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 88, training loss: 2.6918129920959473\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 89, training loss: 2.5552937984466553\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:29,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 90, training loss: 2.577092170715332\n","epoch 4, prediction loss: 2.695453405380249\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in paper of a proof of the theorem of the themma  and le the. show the theoremollary.. proof of that that the text u u \" is unounded. and the proof involves based by using the arguments to in the proof of theorem theorem.. theorem.........gadj,..gadjadjivalentadj..ivalentivalentadj..ababivalentivalent..ababababab.abababab..ab..ababababababababababababababababababababababab',\n"," ' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other with low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss. using analysis suggests that the for detection loss canens the need for an additional population to explain the of using inclusion presented suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with this notion that some populations share dynam dynam',\n"," ' we we j discusses the j of generalizations of spontaneousar- andensor theories where sts )based the j frame where where where the scalar field replaced with other fields and couplings can depend on derivative of specifically study came from the that spontaneous tensoriz where where are most naturally defined in the e frame where however are be applied to any generalization of on a conformal scaling of the metric in the matter action bythe first focuses vector the scalar field a vector field the-tensor theories obtained vector to the-based spontaneous scalarization arezing the j of interesting time derivative terms in no renders order and equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 91, training loss: 2.763432502746582\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:37,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 92, training loss: 2.3846726417541504\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 93, training loss: 2.561647653579712\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:44,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 94, training loss: 2.6426503658294678\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 95, training loss: 2.2192375659942627\n","epoch 4, prediction loss: 3.5836024284362793\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' splitting splitting splitting discusses the splitting theoremorems of homson pairs and j proposed by dazord, lichnerowicz and and marle inas. point is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.ar................................anted.............aware',\n"," ' the the paper discusses the concept of a - andbgorithmbrir model with the single of. and is of a electron structure of a electron of the individual bundlesed. structureorphic of the structuregebroid are determined. and the importance for the the behavior structure of the structure bundle structurex...........igenigenigenigenigenigen.............,,,,,,,,,,',\n"," ' using using ke discusses the use of creating a stellar sample for use a detection efficiency map using the data. the1q17.0 stellar is a parameters from theur et..s ga stellar values from ga dr2. the values have been been updated from ga dr2 the the has25 stellar parameters values have updated updated tousing ensure thatteness mapping of we star must have a stellar of its radius and mass measurementusing values for either fields result in omission.using, the on placed on the cycle and fc >.5 )and time length ( light light curve (we final includes the-varying noise']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 96, training loss: 2.8351142406463623\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 97, training loss: 2.402947425842285\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [05:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 98, training loss: 3.2551462650299072\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 99, training loss: 3.175158977508545\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:06,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 100, training loss: 2.7829947471618652\n","epoch 4, prediction loss: 2.5242347717285156\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in goal we to use the quad to camera to take images images from a parking parking lot and blend them to create a large image image. the entire parking. to approaches were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to field was images images during certain points intervals during create the merging of to this field test  we image lot was divided into a 4x4 matrix matrix better the drone s movement and. algorithm was taking images at different and then them images together each column and and then merging them columns together afterto',\n"," ' in in e discusses with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is conducted.in closed-form expression for the e error probability of concatenation of molecular two channels was derived.The optimization problem was at minimize the e error probability was conc system was formulated to determine the symbol durations for both molecular of communication.The reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication.......      .',\n"," ' ch chorem discusses theic surfaces3 surfaces of ch ch to chow motives of surfaces.1 is a proofposition of theow motives of surfacesic surfaces into aic and transcendental components. and by a comput and computations.1 sectionogenical decomposition of theelian varieties with group action is also. and to a proof of the specific example.1 section discusses with a discussion on the specific example in a k of singular algebraic k3 partner of the minimal between theers surfaces. ch resolutions of which the importanceogenism between theental surfaces of1............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 101, training loss: 2.9563989639282227\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 102, training loss: 2.8581371307373047\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 103, training loss: 3.382274627685547\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 104, training loss: 3.085336446762085\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 105, training loss: 2.6234724521636963\n","epoch 4, prediction loss: 3.238391160964966\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in well discusses a construction of uniformly well and and which the mean curvature and a and the applicationability to the hypersurfaces.we also the wellence between the concept of uniformly strongly elliptic and uniformly normally elliptic hypers the contextar case.we well -posedness result for pro sphere class is derived. the methods. results resultsms. including the importance.chitz continuity of the semiflow.......................ababababababababababbabababababbbababab',\n"," ' the the study. thexiv:190. a detailed description of the results details of in the paper.ar discusses the main features of discusses. were be discussed in including a a detailed overview of the is expect from the future section.arx..........,,ib,,,,........,....,.................,......,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the thefaces diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space the these surface velocity of evolving surfaces is determined by purely geometric quant such while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, these paper considers uniformly regular hypersurfaces. which non-compac surfaces.we utilizing the study of uniformly larger class of manifolds, we study presented to the study research of geometric flows on non-compact manifolds. in study relies based by the theory of continuous maximal']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:29,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 106, training loss: 3.018569231033325\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 107, training loss: 2.424119472503662\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 108, training loss: 3.131077766418457\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 109, training loss: 3.649462938308716\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 110, training loss: 2.935952663421631\n","epoch 4, prediction loss: 3.020145893096924\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' eccentric eccentric eccentric discusses the eccentricity into our model system is increase the detection efficiencywe is the eccentricity models for including the modified gamma distribution used to a beta distribution usedwe from that significant differences between theity between the planet multi-planet systems. the same & mur eccentric. however, using with the eccentricities reveals significant between. bias is theity occurrence using leading multi-planet systems producing more low eccentricity detections than analysis suggest that differences between the empirical ofation of detection eff is crucial for determiningity occurrence measurement.  evidence for needed to determine if these populationsity populations exist between the and multi-planet systems.',\n"," ' effective effective effective discusses the effective interactions of darkermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the thermally averaged indirect indirect matter pair d)pair annihilation cross-section and the spin-independent d - with le and/or bound electron. and that with the data......,,,,,..,..............b..',\n"," ' the the t discusses the tford-tate and t conjectures for surfaces surfaces mentioned namely on the cycles-- ofwe mainford-tate conjecture is v with denoted by g, g, is the using detail to theic cycles and the.The t also a of to theelian motives and theodge m. and that existenceelian nature of the fib and textford-tate group is proven for the certain fib of the alese variety and and a to the thodge conjecture and the class mapThe.............ab...']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 111, training loss: 2.153238534927368\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 112, training loss: 2.8818917274475098\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:54,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 113, training loss: 3.01359224319458\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 114, training loss: 2.821037530899048\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:01,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 115, training loss: 2.769014596939087\n","epoch 4, prediction loss: 2.694007396697998\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in fraction discusses numerical numerical of fractional power equations in time models with solving applications. as sub, biology or finance finance.in is on the fraction involving fractional power elliptic operators. numerical based the elements method quadlov subspace method.in numerical to solve fractional powerin-space reaction-diffusion equations are analyzed. in the integral and adaptively preconditioned lzos method.in numerical also discusses theimations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic operator.. is with a results. the results. the',\n"," ' the the differenceauchy problem method is used to solving solution solving solvingolving. the on the auxiliary pseudo-time evolutionary problem.. a priori estimates are be obtained for solve numer problem. the the prior implicit two-level euler scheme. used.. difference scheme is unconditionally stable with the initial dat.. applying these estimates recursively we the validity of the difference is proven.5im....,,,,,,,,,.............ab...abababab..ababab.abababab..',\n"," ' in in transparent of transparents agents to transparent transparent r agent. which two operating units, matching and value network. with two are q agentss agents evaluate actions suggested suggested choose the most probable cho based utilizing for a to reach states by the env model. with suggest that q proposed q can the of to the simplicity inner and transparent. selecting selection. proposed of the nodes and nodes from q manual analysis modification of q actions. property makes the the the weights and synaptic states. which future improvement of improvement avoidance........................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 116, training loss: 2.9575722217559814\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:09,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 117, training loss: 2.904741048812866\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 118, training loss: 2.346329689025879\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:16,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 119, training loss: 2.23453950881958\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 120, training loss: 2.468991756439209\n","epoch 4, prediction loss: 2.9717862606048584\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' double double study discusses theinc s lie bundles and a are the to the lie algebroids and text was been in applications with other fields systems., it text discusses the splitting of double vector bundles into. et et.......,,,,,,ivalent,,,giangianivalentivalentivalentivalent....abivalentaware...ababaware..awareawareivalentawareababivalentbyabbyabab,,abawareaware',\n"," ' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using findingating them key points between the and and then a robust fitting to to finding changes rotation. as rotation.the, when we to stitch more result image with a third image using the will because the result will tries the black background as the image process.to distortion is due by the that theofcv. so to a images. stitching more than two images. to avoid this issue we open algorithm was implemented using openc. find this distortion issue by theofcv. translation. to..ac..',\n"," ' the the textogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation.the model of are the the referenceogenized and the models are constructed inthe response of the homogenized model is performed in two steps. comparing the of acousticlections obtained by the numerical simulations of- firstogenized model andifies the problem by to the complexity of the finite element mesh complexity increasing number of holesforating holes.the reference are implemented']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:24,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 121, training loss: 2.134084939956665\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 122, training loss: 2.95205020904541\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:31,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 123, training loss: 3.0017895698547363\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 124, training loss: 2.794593572616577\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:38,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 125, training loss: 2.603350877761841\n","epoch 4, prediction loss: 3.0746469497680664\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the hom discusses the the homogenized vibroacoustic transmission model derived the text is be used for numerical simulation of acoustic waves using the two-scale in.the numerical is is to to the one considered section section of where the zero neumann condition appl a same acoustic fluid and the solid..the numericalscopic responses are computed in compared in fi. illustrate the model.the.....,,,,,,,,,,,..,,........,,,,.....',\n"," ' in in index on theasipinear inequalities with aity -ity and whereizing the index j sub acritical and the certain inequality is satisfied. critical if equality holds in case certain case.wex........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,....,,,.,,,,...ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent.ivalentivalentivalentivalentivalent.ivalent........,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the surface discusses the relation of the in a presence of the diffusion flows. focusing the theore 2. for for the process of flow. well as........,,,,,,fterantingadadadadivalentivalent....adj.....adj..................aware.............ababivalentababababababababababab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 126, training loss: 3.683764934539795\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:46,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 127, training loss: 2.8110811710357666\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 128, training loss: 3.054090976715088\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:53,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 129, training loss: 2.6285269260406494\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 130, training loss: 2.647221088409424\n","epoch 4, prediction loss: 2.821047306060791\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke discusses the modeling soft the from the keomult soft soft extract the ke population parameters determine constraints. in analysis modeling presented each of planets according on the parameters and and each randomly to of detection basedbased probability parameters the population parameters are is a weak in the radius population around however due by a unique population planet and population population.-planet systems are also and comparison analysis. and that population dependence. forward model is from bayesian analysis shows compared and with that in the parameters due uncertainty due. best parametersiates between multiple- and systems and single-planet systems. showing the implications future studies of planet period and radius',\n"," ' the the influence discusses a results test of the homogenized model of a perforated plate of the reissner-mindlin typ.the results is to compare responses responses of the homogenized plate model with the of the associated 3d elastic structure withtheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.the deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat modelthe influence of the compliance on the loss in the waveguide is discussed bythe influence',\n"," ' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the reconstruction andthe algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.themarksing is on a minima detector operator isative algorithm to remove landmarks landmarks in the nasal region. such as the nasalnasale l sub corners landmarkslieriers are removed using aative methods. remove that selectioning. algorithm is to reduce identify the al such maintaining redundant parts of the face.............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:01,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 131, training loss: 2.692357063293457\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 132, training loss: 3.0035600662231445\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 133, training loss: 2.46071720123291\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 134, training loss: 2.3301191329956055\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 135, training loss: 2.7503037452697754\n","epoch 4, prediction loss: 3.529937267303467\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in concept discusses the -to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes.to of the molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is computedimated by sim s rul.to orderpersmbol interference is ignored. the the of left to future work. to error error performance ( is also. the on- and and off-body communication channel. the the of the such the between motion of-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' * * studyaic - is a method to to calculatingson solds to which are used with which to a functions.The involves the the equations of a basis of create the. to the results.Thex method.......igenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,',\n"," ' the the study of theooninivityverseal and................,,,,,,,,,,,,ine,,,,,,,ineine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 136, training loss: 2.9035727977752686\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 137, training loss: 3.1460800170898438\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:26,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 138, training loss: 2.8619368076324463\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 139, training loss: 2.736386775970459\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:33,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 140, training loss: 2.9733922481536865\n","epoch 4, prediction loss: 3.6890830993652344\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the current discusses the impact of the matter ( d)ther density using using the thermally averaged andaged annihilation annihilation cross- forwe current have the cross-averaged annihilation cross- for f types candidates including compare the methods to compute the cos density constraints. direct are such as dermil-abs, hess are are sensitive to the types candidates.lihilation cross- are various types candidates are computed using pair with le leptons and photons. the results also discusses the on theider experiments to these operators for the on theh data. text is on the detection experiments involving d particleselectron scattering delastic',\n"," ' the the datasetsd face are used to evaluate the face recognition algorithm proposed thegc vbosphorus and and bu-3de. the proposedgc dataset is 5 with 5 sets expressions are and the bosphorus dataset includes samples of six prototypic expressions andThe b was performanceing accuracy and accuracy were evaluated using and that accuracy for thegc than to the samples andThe robustors were inabor wavelets and the g scale were for each recognition are.The results was a accuracy rates for the b al and the samples. with aness for the-neutral samples. probes.Theisons results was the algorithms is also. showing',\n"," ' in in lie on the lie algebra of type an. whichoted sl sln+ is which to the graphs..in main is the all n-colored edge in the crystal graph.in is discusses the the lieposition of the 4 is multiplicity-fre.......,,,,,,,,,........adj.............,,.......ivalent,,,ab,,.,,,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 141, training loss: 2.6799442768096924\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:41,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 142, training loss: 2.9867358207702637\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 143, training loss: 2.8285701274871826\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:48,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 144, training loss: 2.815423011779785\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 145, training loss: 2.8575382232666016\n","epoch 4, prediction loss: 3.136516571044922\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we effects discusses on the multipl effects multipl the parameters parameters provided theoseismic data fromwe study of new updated allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat and to of also from the curves and thus periods need on the data keks.. to positives are removed using the thes to thus are planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in including a of on the and period cut. we with multiple positives are artificially removed to accuracy order accuracy  detection detection multiplicity we in 7',\n"," ' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. a novel five-step algorithm is presented and based with aly of the nose tip location segmenting and alignmenting the face and and thenpping the nasal region.  very anding algorithm is seven key points on the nasal reg.The genetic algorithm-based feature selector is the patches and curves over different facial expressions.  algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and does does not require a training step for theing.1....',\n"," ' the the we on thet and algebra and the weil algebra. 16 55.2........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent..ivalentivalentivalentivalentawareawareivalentaware....awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalentawareivalentawareawareivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:56,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 146, training loss: 2.4509034156799316\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 147, training loss: 3.076632022857666\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:03,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 148, training loss: 2.6442861557006836\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 149, training loss: 3.1713545322418213\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:10,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 150, training loss: 2.892866849899292\n","epoch 4, prediction loss: 3.5524163246154785\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the aim discusses with the algorithm developed by us authors is a best candidate for creating a bigger image from small images using and theofcv can results to fit two images with better accuracy.after algorithm also the theofcv can results are be imp for the mapping because to the it.he algorithm concludes the the algorithm developed short of achieving goal of create the parking lot and and the in the stitching and the ar-drone 0.0.0 also that the different version of the ar with even different camera with a 1080p camera. this image.The, the issues with the ar were to the results stitching results.The text',\n"," ' the the aim project we to come an image processing algorithm that the the university of bridgeport parking lot using using two images into with the stable device with a good camera. such the ar-drone 0 the main camera of the drone will images imagesapped images which which can then into the algorithm that. alongcv and boofcv are were used to developing processing. and thecv being java interface being used primary component ofboofcv is a-level image processing capabilities and bo low example processing algorithm.. whiching images the open goal main. stitching refers combining a 2d geometric transform which minimize two images into and a such',\n"," ' the the feature selection step is the engineeringgorithm ( ga)is to select thoseets of curves vectors extracted curves and patches patches extracted are more against facial expression.The modified vector is used to select select those most robust curves from remove the features. the varying the value vector b the subs and patches can selected or omitted based depending reducing the rates. reducing the selection. the appro. fisher fisher analysis analysis..- algorithmgorithm is to in the non dimensionaldimensional binary high-convex optimization process. with a high nsga-ii. elitism over the individuals high individuals..- feature assignments for the are are explained in section']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 151, training loss: 3.0359907150268555\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:18,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 152, training loss: 3.0435144901275635\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 153, training loss: 2.3120994567871094\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:25,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 154, training loss: 2.489438056945801\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 155, training loss: 2.4788906574249268\n","epoch 4, prediction loss: 2.679854393005371\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in aim discusses the classification of irregular with by theodge theory and specifically by the which irregular3 type. product modental part.. are the related the group of these surfaces and their conditions answers to the questions. certain conditions.the main also the the classification of these surfaces is not not and that the state state of the art up. also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac. finally results obtained can used to prove that t- mumford-tate conjectures for these surfaces. proof also the support of inspiration and provide a overview of the current state',\n"," ' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous bay using focusing upon previous bay and extract information about the multiplicit. comple a best replication of the empirical popul multipl we studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters using with the from previous provided previous bay. we study is that with the with previous bay. with at the case of small radius planets down to the threshold. we usingorously treating completeness mapping and a',\n"," ' the the high discusses the method of the order difference schemes for solving thestationary cauchy typetype ellipt. to theal power elliptic operator. the order approximations are used to approximate the time dependence of the solution while while the elliptic operator is approximated by the finite element sche. the. stability conditions are given for the-level discrete schemes with weight weight parameter.the order accuracy is proved for the symmetrical crankank-nicelsonson type sche.The family of three-level symmetrical discrete schemes is constructed and investigated. the on the smooth solution.The condition on the first time level are computed by the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:33,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 156, training loss: 2.464543342590332\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 157, training loss: 2.4123752117156982\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 158, training loss: 2.7937028408050537\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 159, training loss: 3.0439252853393555\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 160, training loss: 2.55655574798584\n","epoch 4, prediction loss: 2.9513187408447266\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in order difference-level difference difference scheme are constructed. this paper. they stability condition for the initial the scheme is woted by w1 isis to be computed with a symm levellevel numerical algorithm. the same accuracy as of main scheme. themmetrical scheme are the with the order accur. suff smooth solutions. in conditions for derived for the symm-level scheme. the that stability with respect to the dat. high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy. the schemes can be constructed to this condition w they restrictions are that using.',\n"," ' the the main algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the heant of the heian matrix is usedized.sur determin is two from using blending the last image for performance and level detail detail and rendering in a final merging.The algorithm image image is as input input to the algorithm. the analysis. the drone moves forward.The.......',\n"," ' in in minimal discusses the minimal domin1 theoremthe singular for which the minimal assumptionsity conditions on the singular t. which the singular holds.on is that the proof on which minimal hold not unknown. discusses are they theorem dini cond can be relaxed to. section also the minimal assumptions on t k yielding yield thewise sparse domin. text are in results and le the sectionmma. le. the. to the weak. also with showing that the the bounded extension of the t is l2 to itself if then bounded condition on hold on.......... ad     ']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 161, training loss: 2.7733800411224365\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 162, training loss: 2.6917450428009033\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:58,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 163, training loss: 2.5592684745788574\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 4, batch 164, training loss: 2.9018383026123047\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:05,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.8289709062287303\n","epoch {}'s average verification loss: {} 3.020704746246338\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [51:19<51:09, 613.99s/it]  "]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 0, training loss: 3.2005975246429443\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.79s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 1, training loss: 3.037350654602051\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 2, training loss: 2.7068116664886475\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 3, training loss: 2.830054998397827\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:14,  3.53s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 4, training loss: 2.1513495445251465\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.51s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 5, training loss: 2.7888996601104736\n","epoch 5, prediction loss: 3.1042072772979736\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous bay using focusing upon previous bay and extract information about the multiplicit. comple a best replication of the empirical popul multipl. studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a bay maximization technique to a the distributions for a parameters using with the from previous provided previous bay. we study is that with the with previous bay. with at the case of small radius planets. to the threshold.. usingorously treating completeness mapping and a',\n"," ' we we effects discusses on the multipl effects multipl the parameters parameters provided theoseismic data fromwe study of new updated allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat and to of also from the curves and thus periods need on the data keks.. to positives are removed using the thes to thus are planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in including a of on the and period cuts. we with multiple positives are artificially removed to accuracy order accuracy  detection detection multiplicity we in 7',\n"," ' in in text on a results on to the closed dirichlet form on the bounded-chitz domain.. using theorem of it closed is a by. text result is the section is that existencehei matsuura theorem. which states that the regular closed of a continuous vers...................ggggableableable..ableableabableableableableableableableabeabeabababawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:22,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 6, training loss: 3.4054853916168213\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 7, training loss: 3.2332472801208496\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:29,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 8, training loss: 2.4482028484344482\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 9, training loss: 3.006608009338379\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:36,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 10, training loss: 2.770345687866211\n","epoch 5, prediction loss: 2.875034809112549\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in aug of that to the the augmentation of in a data from classes that less population in the dat isin aug of aug and convstm layer on generate the pattern of directions and windows windows sizes in the flo function and and the distribution functions ( pdfs )of every features using and points points in each feature dom and on the pdfs and and generating points dat dat. the.The the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat. and a batch architecture. rel normalization lay.',\n"," ' in inore discusses the but/ extensions of the theorem theorem of point on the specific precise version of pointwise sparse domination 7.1 text of the theorem result compared the original theorem is that. and some is used how it result can used in a applicationsorems.1 text also discusses a use to the theorem to a multilinear cas. and the the results.1essary changes in the proof are made out. and the the original idea of the theorem theorem.1........  iiiiii.',\n"," ' the thefaces diffusion and willmore flows are considered for uniformlyurfaces parameterized over uniformly uniformly regular reference manifold with uniform tubular neighborhood withThe the are in a fourth-order quasilinear parabolic equation with non singular structures. the formlinear terms satisfying. and..........ger  ...................able..............,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 11, training loss: 2.87974214553833\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:44,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 12, training loss: 2.2230606079101562\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 13, training loss: 2.64500093460083\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:51,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 14, training loss: 2.58429217338562\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 15, training loss: 2.5925183296203613\n","epoch 5, prediction loss: 3.175450086593628\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in inrones are getting being in various fields fields such the such google and facebook, amaz amaz. their own drone technology.dron are used in various journalism so obtain videos of areas toto-access areas.dcopter are which quad of quad that four rotorors are are one used in and the spinors working clockwise and two other two spin counterclockclockwise. balance that.dron are be autonomously based on a-entered program without and without with a resolutionresolution video and image processing and computer vision techniques. in, such of when a or or satellite-captured satellite maps are not. in research',\n"," ' the the impact discusses thely interacting dark matter ( ( their interactions with focusing are be motivated from various detection indirect detection experiments.the u physics extensions of standard standard model ( sm) and been proposed to provide the matter candidates d) candidates or whose as uly interactingacting neutral (ons ( wimps )  detection experiments have shrunk the parameter space of the models where theimps to with the visible world via however constrained of sm particles sm model particles are encaps in the lagrangian approach where where the of the dimensional effective operators constructed thesestrained on these higher are discussed from various data. estimate the the u models. the sensitivity',\n"," ' it it d discusses the symmetry of the electrodynamics theory under theity transformation. considering on the drangian transformations involving the the theion and dilaton fields.it is the behaviorance of the equations under equations of motion and energy-momentum tensor under the-duality transformationit transformationsetries are transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the existence of of theitudes involving the-duality. isves into the implications of the involving equationsitudes under the-duality transformations. focusing the need of the of the-duality']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:59,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 16, training loss: 3.168390989303589\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 17, training loss: 2.692669630050659\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:06,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 18, training loss: 2.901668071746826\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 19, training loss: 3.2993717193603516\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 20, training loss: 2.8786745071411133\n","epoch 5, prediction loss: 3.1184091567993164\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in goal we to use the quad to camera to take images images from a parking parking lot and blend them to create a large image image. the entire parking. to approaches were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to field was images images during certain points intervals during create the merging of to this field test  we image lot was divided into a 4x4 matrix matrix better the drone. movement.. algorithm was using images at different and then them images together each column and and then merging them columns together after to',\n"," ' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposesThe is the importance of the 3 for surface features for expression robust andust recognition and includinging previous approaches that providing high discrim of discriminant strength andthe proposed is a landmarksing and feature extraction techniques to multi-resolution gabor wavelets tothe isforms previous approachesd nose recognition algorithms by achieves that performance compared with previous that the whole facial dom.the, the proposed is a such as improved denoising and and fast pose pose correct algorithms features are achieved in section text of theing and feature extraction and and',\n"," ' in in transparent of transparents agents to transparent transparent r agent. which two operating units, matching and value network. with two are q agentss agents evaluate actions suggested suggested choose the most probable cho based utilizing for a to reach states. the env model. with suggest that q proposed q can the of to its simplicity inner and transparent. selecting selection. proposed of the nodes and nodes from q manual analysis modification of q actions. property makes the the the weights and synaptic states. which future improvement of improvement avoidance........................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 21, training loss: 3.171539783477783\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 22, training loss: 2.492860794067383\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:24,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 23, training loss: 3.0765514373779297\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 24, training loss: 2.654681921005249\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:31,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 25, training loss: 2.4895694255828857\n","epoch 5, prediction loss: 3.0935146808624268\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we distribution discusses the resultsolation of previous populations parameters to longer periods andwe discusses the the results of not differ greatly from previous studies. discusses consistent with previous findings.. with found between previousman-mackey et recent to uses the a specific functional form for theolation to using aussian process regression. determine the functions.man-mackey et approach also a results pipeline in to does reports the highest signal to to- noiseise candidate around each st. results also discusses the detection order can bias the. leading leadingcounting small planets and long periods. text used by bur et al.@ used by the',\n"," ' the the acoustic discusses the method analysis for the the acoustic acoustic pressure and the displacements and and rotation in a limit lay ofThe result is based for understanding understanding - and equations of vib vibroacoustic problem imposedThe convergenceymptotic analysis is based using the unfolding method. which developed for the seminal paper by elaborated elaborated further thin structures inThex.......ggg     ...,....,,......,,,,,,,,,,,,,,,,,',\n"," ' the the sensitivity discusses the sensitivity of the constraints on the matter pair d)- at including on the sensitivity to sensitivity to the momentum of d pair atom and/- electronron scattering due to suppressed of quarks inon is the need of theizing dpto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh) and discusses the need of the the- to the-2 operators.on study is discusseszes the state effects of d-atom scattering cross dama data. derive the the pair production channels at the proposed linear coll ( ilc )  analytical have the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 26, training loss: 2.5643632411956787\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:39,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 27, training loss: 2.9057538509368896\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 28, training loss: 2.615440607070923\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:46,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 29, training loss: 2.8743631839752197\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 30, training loss: 2.3494839668273926\n","epoch 5, prediction loss: 3.323519468307495\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' with with traffic is a for the ever amount that in withifying the traces and applicationsifying applications is two tasks in with traffic tracingifications ( nts ) have classify anomalies in classify applications for however they methods have shown. port on ports in lack issues. their. ingorithms have n classification classification have great in they solutions for however thebalanced datasets is networks-scale networks datasets a challenging for deep. f.. inmentation is have machine learning have which as artificial artificial data for are be these imbalance issuesin novel approachmentation method is k dataensity andimation and kde)and lestestTerm memory ( lst',\n"," ' using using study discusses the use of constructing a stellar sample for use a detection efficiency map using the data. the1q17.0 stellar is a parameters derived theur et..s ga stellar values from ga dr2. the values have been been updated from the dr2 the the has25 stellar parameters values have updated updated forusing ensure thatteness mapping of we star must have a stellar of its radius and mass measurementusing values for either fields result in omission.using, the on placed on the cycle and fc >.5 )and time length ( light light curve (we final includes the-varying noise',\n"," ' in in one discusses the thestation fractional power elliptic operator equations numerically using using equivalent local nonstationary initial value pseudo-parabolic problem.The such were the implicit backward and symmetrical euler method. while the paper introduces to the fourth-parameter family of three-level finite difference schemes forthe fourth-order approximation scheme is developed by optimal optimal weight paramizationthe resultsical analysis and are supplemented by extensive computational experiments.......,..........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:54,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 31, training loss: 2.9571993350982666\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 32, training loss: 2.4266135692596436\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:01,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 33, training loss: 2.116856575012207\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 34, training loss: 2.2582011222839355\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:08,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 35, training loss: 2.6513993740081787\n","epoch 5, prediction loss: 2.6714789867401123\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in well discusses a construction of uniformly well and and which the mean curvature and a. the applicationability to the hypersurfaces.we also the wellence between the concept of uniformly strongly elliptic and uniformly normally elliptic hypers the contextar case.we well -posedness result for pro sphere class is derived. the methods. results resultsms. including the importance.chitz continuity of the semiflow..........,............ababababababababababbabababababbbababab',\n"," ' in in e discusses a e -to-end e-health system mode for includes molecular and electromagnetic wireless communications betweenThe-body and are considered via a generic-assisted diffusion-based molecular communication system and while aomachransmissionters and receivers molecules.out relay node is be improve the link andout proposed model includes a-body and off-body communications. which a time of nan schemes. different symbol intervals. each communication type.Theomachines/ as relay nodes. which nearly free and molecular. proposed is includes a2out-off-body communication communications. aways. on communication. the body-health system.',\n"," ' the the accuracy discusses the results to thewise linear continuous p1 lagrange elements to approximate the elliptic oper.the accuracy of different approximations in time will investigated. the reference sol.. of the solution are the three-level weighted difference scheme are estimated. fig.. accuracy is to investigate the accuracy of the threelevellevel difference scheme. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm.gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 36, training loss: 2.7091543674468994\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:16,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 37, training loss: 2.5302963256835938\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 38, training loss: 2.8982081413269043\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:23,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 39, training loss: 2.6501293182373047\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 40, training loss: 2.5688822269439697\n","epoch 5, prediction loss: 2.869244337081909\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this advanced of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play key building the-nano-medical applications. in paper presents the e-toendend e link consisting electromagnetic electromagnetic and molecular communication.  closed-form expression for presented for the e error probability ( the e system system.based optimization method is formulated with minimize the e error rate of the the optimal symbol duration for the time from. numerical proposed is solved by an iterative algorithm based on the bisection met.numerical results show that the proposed method ob ob',\n"," ' in in text discusses the -to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes.to of the molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is computedimated by sim s rul.The orderpersmbol interference is ignored. the the of left to future work. to error error performance ( is also. the on- and and off-body communication channel. the the of the such the between motion of-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' well well well section the well -posedness properties for the wellard - equation the on the workorems on the. to the regular surfaces andThe text involves from proofs as in the previous proof.x........ ger   adad   ivalentivalentivalentivalent.ivalentivalent.ivalentivalentivalentivalentivalentivalent..ivalentivalentivalentivalent...ivalentivalent.ivalent...awareaware...awareawareivalentivalentawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:31,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 41, training loss: 2.5823731422424316\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 42, training loss: 2.5884077548980713\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 43, training loss: 2.6181397438049316\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 44, training loss: 3.1061525344848633\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 45, training loss: 2.611342191696167\n","epoch 5, prediction loss: 2.802926778793335\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in paper discusses a bounds for cal operators and harmonic analys.weization and sparseness are two ingredients in make them bounds especially tools quantitative norm inequ. in text on sparse bounds for too and inars bounds for cal on- onymund operators are calizations domination principles are reviewed. in text show a proof proof on means the main hypot in the them the weighted weightedq proper proper  result simpl the need for work with the grand maximal truncated operator mt which it sparse more efficient.. text also organized as five. the proof and the theorem theorem and the and extensions and and. t1-type result and and a',\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the need of by the -rigid objects expressions and3isting approaches for such the iterative closest point algorithm and can become to variations minima and3 approach to capturing a range of facial expressions for each subject and storing them with the subjects in each. but this are are 3 and storage are3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to address theness against variations expressions. in research have focused the to the multiple normals hist point',\n"," ' in in ratio discusses the partial of partial and graded posets. order order theory.The chain is a poset in every pair of elements is compar. and a graded poset is a poset equipped a rank fun.The the chainet is not explicitly weighted, the weight is implicitly the counting meas.The this, har. partial was the of order theory was published by one of ten ten ten outstanding results in the editor-in-chief of the journal of in are also a of a partial order, absolute order,.......aware.aware  .   ...']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 46, training loss: 3.5450491905212402\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 47, training loss: 2.826331615447998\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:56,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 48, training loss: 2.232322931289673\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 49, training loss: 2.822643280029297\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:03,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 50, training loss: 2.4743247032165527\n","epoch 5, prediction loss: 3.1170995235443115\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order and however others have focused the to as convesian neural networks or convabilistic graphical models. semi-supervised learning in however in been been done in the neural neural networks to however lstm networks to to address data data. however neural flow data. however main discusses a approachmentation approach for generating time data in network traffic trace g tcp the contribution that in the results used. generating cases and numer data aug. used as recurrent aug. andimation and kd) and used to generating data data and network network-',\n"," ' in in aim discusses the classification of irregular with by theodge theory and specifically by the which irregular3 type. product modental part.. are the related the group of these surfaces and their conditions answers to the questions. certain conditions. main also the the classification of these surfaces is not not and that the state state of the art up. also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac. results obtained can used to prove that t- mumford-tate conjectures for these surfaces. proof also the support of inspiration and provide a overview of the current state',\n"," ' in in continuity discusses the continuity of the heat kernels of the reflection brownian motion ( a general lipsipschitz domain.. is that existence of theelv typetype inequality on a domains like to the presence of a cusp at inf.. text prove that the heat kernel of reflection reflectionian motion on a uniform domains are continu. however not heat domainsipschitz domains is not an uniform.. proof also the estimates estimates to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain isThe is important in the transformation theory of theov processes. its the-spectral independence']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 51, training loss: 2.6894443035125732\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:11,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 52, training loss: 2.9851081371307373\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 53, training loss: 2.6820404529571533\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:18,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 54, training loss: 3.430199146270752\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 55, training loss: 2.5742759704589844\n","epoch 5, prediction loss: 2.9716603755950928\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the reconstruction.the algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.themarksing is on a minima detector operator isative algorithm. remove landmarks landmarks in the nasal region. such as the nasalnasale l sub corners landmarkslieriers are removed using aative methods. remove the selectioning. algorithm is to reduce identify the al such maintaining redundant parts of the face.............',\n"," ' eccentric eccentric eccentric discusses the eccentricity into the model system is enhance the detection efficiencywe is the eccentricity models for including the modified gamma distribution used to a beta distribution usedwe from that significant differences between theity between the planet multi-planet systems. the same & mur eccentric. however, using with the eccentricities reveals significant in bias is theity occurrence using leading multi-planet systems producing more low eccentricity detections than significance suggest that differences between the empirical ofation of detection eff is crucial for determiningity occurrence measurement.  evidence for needed to determine if there populationsity populations exist between the and multi-planet systems.',\n"," \" k krillov-reshetikhin modules k)cry are a-dimensional representations for affne lie algebras. by their drinfel'd polynomials. have mathematical. such as solutions of the q-system.k k for to determine a uniform model for k modules. which are been achieved for br,1 by kashiwara s construction of.aito and sagaki have constructed k construction brceptional affne br using lmibai-seshadri paths.. crystals are perfect for the physic and have connected to mathematical k mathematics subject class 05e10,17b\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:26,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 56, training loss: 2.373955249786377\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 57, training loss: 2.535767078399658\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:33,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 58, training loss: 3.3378963470458984\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 59, training loss: 3.096898078918457\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:40,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 60, training loss: 2.6143007278442383\n","epoch 5, prediction loss: 2.8021316528320312\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the influence discusses a results test of the homogenized model of a perforated plate of the reissner-mindlin typ.the results is to compare responses responses of the homogenized plate model with the of the associated 3d elastic structure withtheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.The deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat modelthe influence of the compliance on the loss in the waveguide is discussed.The influence',\n"," ' the the we discusses the weence of doubleb-algebroid structures on d double lie algebroid and horizontal or vertical differentials on two of the threeil algebras and a well as ger gerstenhaber bracket on the th we also discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras.ar.............. ',\n"," ' sn sn paper discusses that super is normalized normalized matching property. which that sn is indeed sperne.. is a by the example on. the normalized case is trivia.. the baseive step is the permutations from the copies of sn. the collapsing the n of we new network is constructed. be the normalized matching cond. which to the conclusion that sn is indeed sperner. well satisfies normalized normalized flow property.im..................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 61, training loss: 2.6406409740448\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:48,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 62, training loss: 2.462027072906494\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 63, training loss: 2.4312362670898438\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 64, training loss: 2.3016538619995117\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 65, training loss: 2.7317442893981934\n","epoch 5, prediction loss: 2.896097421646118\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' reinforcement reinforcementactionforcement learning ( have agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples to algorithms can however of performing as humans, can called as a for the a intelligence intelligence. to advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for reinforcement tasks. to develop the useability of reinforcement learning into it need of explainable and networks-based reinforcement is crucial. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent whose whose simple rule. decision-making. pirical evaluation of that for building a comprehens and comprehens agent using a method',\n"," ' using using lack discusses the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity stars systems. within using these function to we expected suggests that 0 empirical empirical multiplicity of be increased by a function of selection effect. within best also discusses the implications of this function to the the for the multipl and period., the is the impact of this model of multiplicity in our solar system for theability. finding that lack for a studies for support such claims.............ddddddabababab.',\n"," ' splitting splitting splitting discusses discusses on the splitting of double vector bundles in the context of splitting to discusses to the vector. including well in section text...42x text..........,antantivalent, ivalentivalentivalent.ivalentivalentivalentivalent..ivalent.awareawareaware...awareaware....awareawareawareawareaware..,,,,.,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:03,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 66, training loss: 2.698866367340088\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:06,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 67, training loss: 2.4687340259552\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 68, training loss: 2.6533615589141846\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:13,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 69, training loss: 2.882221221923828\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 70, training loss: 2.5675175189971924\n","epoch 5, prediction loss: 3.3795511722564697\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the paper discusses the concept of a - andbgorithmbrir model with the single of. and is of a electron structure of a electron of the individual bundlesed. sectionorphic of the structuregebroid are determined. and the importance. the the behavior structure of the structure bundle.x...........igenigenigenigenigenigen..,,,,,,,,,',\n"," ' to to ability discusses the applications of thes agents to are able to evaluate a agents from r agents.q agents can evaluate used in specific- specific problems.q from for such as state multiple rewards and of state rewards and can be used to evaluate agents- andqizing the actual of state- can on the such coordinates and velocities can enhance agents accuracy of qs agents.s agents can also multiple matching and value networks to evaluate agents values of. proposed between p brain cortex and pfc ) hippocampus and and anterior cingulate cortex ( explored for the. brain discusses that one of of q q cing',\n"," ' transition transition continuity discusses the continuity of the densities of reflecting brownian motions on lipsipschitz domains.  also provides the estimates for the transitionit surface that the surface measure on the domain is in the local kato class. the reflecting brownian mot.ar.............  ..........................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 71, training loss: 2.94152569770813\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 72, training loss: 2.5943400859832764\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:28,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 73, training loss: 2.902177095413208\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 74, training loss: 3.5112051963806152\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 75, training loss: 3.2487030029296875\n","epoch 5, prediction loss: 3.1322872638702393\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the main algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the heant of the heian matrix is usedized.sur determin is two from using blending the last image for performance and level detail detail and rendering in a final merging.The algorithm image image is as input input for the algorithm. the analysis. the drone moves forward.The.......',\n"," ' the the point. section improved version of the pointwise sparse domination principle established by the first author in. allows allows us determining singular singular assumptions on for a singular integral operator to admit a sparse domin..........  gn,   gn.  ..........................................aware.,..,,.,,,.,,.',\n"," ' computer computer goal presents a method called d map Creator using dmc )@ can computer vision technique to create create a by stitching together visual information captured by a d. camera camera.d proposed utilizes the speeded up robustotic features method to detect the points for each image frame. identify the the points between frames. maximizing the determinant of a heian mat. finally proposed points are st to st together two by and in a st creation. some from the external environment.m..... ad     dddddddddddddddddd']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 76, training loss: 3.2244620323181152\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:43,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 77, training loss: 2.631492853164673\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 78, training loss: 2.603255033493042\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:50,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 79, training loss: 2.5642921924591064\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 80, training loss: 2.8610610961914062\n","epoch 5, prediction loss: 2.846931219100952\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' quasi quasi agent-critic model is a to a reference model agent to order study.The structure of quasi quasi-symbolic agent q matching and value networks. which single layer and networks.entially connected.the matching network memorizes input vectors by imprinting normalized inputs to synaptic weights conver the value of matching nodes is identical to the number of value nodes. and the-to-one mapping between matching.the the new node is added to the matching network, a new node is added to the value network. keep one one between the strength strength between these is determined by the reward induced by r selected agent with gradient of matching',\n"," ' we we study discusses the study of a ensemblene affinvariant ensemble sampl to explore the sets toThe bayesian framework is linear space uniform priors is used toThe toors are used for the r ofbr and pbr. on the distribution sample. casc prior for that f must must be larger than f parameter avoid trunc.- prior is is for larger multiplicity systems to be more common than smaller multipl.-........,.........  adadad.adadb.',\n"," ' * * studyaic - is a method to to calculatingson solds to which involves used with which and a functions.The involves the the equations of a basis. create the. to the results.x method.......igenigenigenigenigenigenigenigenigen,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:58,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 81, training loss: 2.3703958988189697\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 82, training loss: 2.8409271240234375\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:05,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 83, training loss: 3.625389337539673\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 84, training loss: 2.607451915740967\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 85, training loss: 2.4684689044952393\n","epoch 5, prediction loss: 2.6034703254699707\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in surface discusses the concept of uniformly regular manifolds and and the importance properties. for the the diffusion flows. will willmore flow.. structuresolds are definedodesically complete, of positive positive injectivity radius and are are allant derivatives of the curvature tensor are.lyolds are boundary are uniformly regular. and well the surfacesolds considered in. text. surfaceally uniformly a defined tens compactly supported tensor fields is the base base manifold is identifying it with zero outside their original dom is used. text also discusses the bcs and bcs. in a similar manner. am.....',\n"," ' the the study. a concept of ant antichain a a pos connected set. aet ) and no two elements are compar.The. and et.......,,,,,,,,,,,,,ivalentivalent,,,.,,,,,,,,,,,,,,.,,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentadenadenawareadenawareawareawareawareawareawareawareawareaware.awareawareawareawareawareadenadenivalentadenaden,,,,,,,,,,,,,,,,',\n"," ' ke ke ke mission has increased our understanding of the around sun-like stars.the final data release dr dr25, provides all on to the failure of two reaction wheel. providing the end end of the primary phase oftheorts are made to quantify the frequency of properties of planets systems and including the on the with earth-like proper.the........,,,,,,,,iv,,,,.................iviviviviviviviviviviviviv...iviviv..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 86, training loss: 2.2035114765167236\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 87, training loss: 2.49699330329895\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 88, training loss: 2.1812312602996826\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 89, training loss: 2.717999219894409\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 90, training loss: 2.1465675830841064\n","epoch 5, prediction loss: 2.4608917236328125\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the textogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated plat structurethe model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation.the model of are the the referenceogenized and the models are constructed inthe response of the homogenized model is performed in two steps. comparing the of acousticlections obtained by direct numerical simulations of- firstogenized model andifies the problem by to the complexity of the finite element mesh complexity increasing number of holesforating holes. reference are implemented',\n"," ' abstract abstract concept on the concept of the of abstract u. the the on theq-crystals. a abstract on the e 7.kin diagram.. is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals. concept also the conceptor product convention for the tens for the abstract crystal. be a as a uq-crystal.. a u uq-mod.....,,,,,,,,,..........',\n"," ' deep deep learning ( ability to high stakesstakes decision problemsmaking is still challenging for it influence may uncertain. extensive test. whileing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents, provide their performance-making process. however such studies have focused on feedability of feedforward deep learning agents we studies focused interpret issue of more learning. well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is transparent agents. in potential approach can to provide the in reinforcement learning agents.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 91, training loss: 2.716550588607788\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:38,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 92, training loss: 2.958153486251831\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 93, training loss: 2.5808446407318115\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 94, training loss: 2.9751040935516357\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 95, training loss: 2.691840887069702\n","epoch 5, prediction loss: 3.0933122634887695\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this text section the in the images images. to the. can be the of.The text used in to address these by improve that transitions between images images.The, ity details details can occur occur the quality.Theosing the best appropriate algorithm for this problem is a. to the issues.Theio algorithm.........addadd..addaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenadenaddadd.adenadenaden..ab.abababababababababababababababababababababababab',\n"," ' the the study of theooninivityverseal and...............,,,,,,,,,,,,,,,,,,,,,ine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' feature featureised features descriptors are used to the nasal region using the features in spherical on theseised from theabor wavelets filters are a featuresors. which to a dimensionality and reduced redundancy and and improvedabilistic feature selection. reduce the to facial expressions while maintaining theinative part.The landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.The sphericalors are the use of the spherical on the nasal surface. when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 96, training loss: 2.8707220554351807\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 97, training loss: 2.5713438987731934\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [06:00,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 98, training loss: 2.328096389770508\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 99, training loss: 2.9567761421203613\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 100, training loss: 2.9182209968566895\n","epoch 5, prediction loss: 2.5557518005371094\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' double doubletic models have transit probability have double transit systems have presented knownknown for on the inclination and however, larger models models for larger multiplicity systems is more difficult and requires semi-analytic models. to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated for to address the distribution population of we non for m transit probability is some specific semi-major axis value is created. this with other for the geometric of otheroplanet period. to address this related to the order and the against a non-uniform method method is used to the period popul to such',\n"," ' in in index discusses theasipinear inequalities with aitycommity. whereizing the index j sub acritical. the certain inequality is satisfied. critical in equality holds in case certain case.x........ivalentivalentivalent,,,ivalentivalentivalent,ivalentivalentivalent,,,,,,,,,,,,,,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalent.ivalentivalentivalentivalent..ivalent,......,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' splitting splitting splitting discusses the splitting theoremorems of homson pairs and j proposed by dazord, lichnerowicz and and marle inas. point is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.ar...................................,,....aware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 101, training loss: 2.2853899002075195\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 102, training loss: 2.782351493835449\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 103, training loss: 2.1281416416168213\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 104, training loss: 2.923513412475586\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 105, training loss: 3.4109718799591064\n","epoch 5, prediction loss: 3.0654890537261963\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the vib presents the vib of modelling and vibration reduction in design design of the in the industry civil engineering.The considers on the the wave propagation through elasticating perforated plates. where the related respect modelling of to the geometricometrical ofthe vib presents a method to theogenization to derive non-local vibro-acoustic transmission conditions for the per designed with acoustic inviscid fluid.the method involves us modelling reduction modelling modelling of takes information details about need need of disc discretization atthe text is a new approach for modelling theroporous structures which providesates the proposedogenization re using direct numerical simulations.-',\n"," ' the the proposed space method the filter is based on the surface normal methodthe proposed feature proposedises thelets overlap and redundancy in the images.The is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations.o the frequency component set. proposedization for the scale and are computed into a block matrix. the analysis.x....,,,,,,,,..................dd.b,.,.,.',\n"," ' the the q discusses a new of the invisible qcd axion model without domain wall. with the heavy heavy heavy are present.The is is developed in the contextxiv:19012..... the 2018,2018.............gergngn. .......fb.fbfbfbfbfbfbfbfb..fbfbfb....fb........aware,,,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 106, training loss: 2.4258155822753906\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 107, training loss: 2.6140027046203613\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 108, training loss: 2.1474950313568115\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 109, training loss: 2.6284823417663574\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:44,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 110, training loss: 2.928049325942993\n","epoch 5, prediction loss: 3.3975329399108887\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the surface discusses the relation of the in a presence of the diffusion flows. focusing the theore 2. for for the process of flow. well asThe.......,,,,,,fteragingadadadadivalentivalent......................aware.............ababivalentabababab,,',\n"," ' in in : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional necessinmedicine is which implementation of tele technologies to provide medical services is has a as a promising solution for address the needs.in is the communication communication sensing technologies to provide biological signals and medical them information to the providers.in of application of telemedicine is the delivery which which the focus on the therapy. control targeted information to the. minimizing the effects.the between a central role in the themedicine system. which the developments has to the-based molecular communication ( inner body and communication.',\n"," ' the the r on the behaviorogeneousization state of with the with surfaces on the role structure of theaus inThe equations are the types such as the properties and the size. determine a descriptions for the the understanding the behavior. the..x and is....,,,,,,ivalentivalent,,,........,.....,,fbfb..fb,...,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 111, training loss: 2.5852386951446533\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:52,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 112, training loss: 2.2964324951171875\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:55,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 113, training loss: 2.8418173789978027\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 114, training loss: 2.7377238273620605\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 115, training loss: 2.920414924621582\n","epoch 5, prediction loss: 2.8190674781799316\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in inorem discusses a proof of convergence theorem on the the monmma. using is the convergence of the pro of themma.. le to proof condition. shown in section section by section also a concept ft : the to themma 3. le sectionotone convergence theorem., the introduces the ex for the with respect to the probability measure p the with section with proving the theoremms. lemmaps..............aware.....',\n"," ' the the en model ( the context is the en. modeling into state vector and action a inputs and the the next state.The this text we the network layer of 300 nodes is used to the network network.The is shown using the squared error recurrent each episode of random learning.. a ensemble learning rate of 0.0........................addadd.............,,,,,,.',\n"," ' in in type discusses the the type e6 crystal decomposition into constructing the and adding loops at everyices. the the composition graph.The example decom r is a as an i0,7-highest weight ele. the sectionposition..The......,,,,,,ivalent,..........ivalentivalentivalent.ivalentivalentivalent.gianivalentivalentivalentivalent.ivalentivalentivalentivalentivalentivalent..ivalentawareawareawareawareawareawareawareawareawareawareivalentivalentadenawareawareawareawareawareawareawareivalentawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:07,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 116, training loss: 2.705808639526367\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 117, training loss: 2.3964643478393555\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 118, training loss: 2.938793182373047\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:17,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 119, training loss: 2.7456490993499756\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 120, training loss: 2.970947027206421\n","epoch 5, prediction loss: 3.1370062828063965\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' dynam dynam cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking. theories context.we is the possibility wall problem and theion models higon models and suggests a to as the inflation and the warides-shafq and and the witten effect. minimal model is proposed where the breaking of peq symmetry is arises at a newiral confining force. leading the domain wall problem. model of instantons interference effects explored to address the domain wall problem. introducing the peq symmetry. the.. model also discusses the issue of thebaryons and which heavy',\n"," ' in inooth compact hypersurfaces without boundary are in rm1mathrmz+}--}1}$gam$ be viewed into hypers.shypersurfac.$ are have a tubular neighborhood. see are connected of this equival is provided. enough there text b \\\\)-+1}))+ below the grap 1 b))so that gr 1))has has a tubular neighborhood. radius. 1,). is a -RT-hypersurfac., there all smooth uniformly regular hypersurfaces have connectedRT-hypersurfaces. there instance, there of',\n"," ' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using findingating them key points between the and and then a robust fitting to to finding changes transformations. as rotation.The, when we to stitch more result image with a third image using the will. the result will tries the black background as the image process. to distortion is due by the that theofcv. so to a images. stitching more than two images. to avoid this issue we open algorithm was implemented using openc. find this distortion issue by theofcv. translation. to.....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 121, training loss: 2.7300007343292236\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 122, training loss: 3.2604897022247314\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:32,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 123, training loss: 2.9579436779022217\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 124, training loss: 2.7074501514434814\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 125, training loss: 2.660274028778076\n","epoch 5, prediction loss: 2.143831729888916\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.The results was tested with a sampled datasets augmented datasets. and compared results show that our proposed approach outperforms thenn. terms of accuracy, recall, and f...........dd...dddd....ababab............abababababababab..',\n"," ' the thefaces diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space the these surface velocity of evolving surfaces is determined by purely geometric quant. while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, these paper considers uniformly regular hypersurfaces. which non-compac surfaces.. utilizing the study of uniformly larger class of manifolds and we study presented to the study research of geometric flows on non-compact manifolds. in study relies based by the theory of continuous maximal',\n"," ' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. a novel five-step algorithm is presented. based with aly of the nose tip location segmenting and aligning the face and and thenpping the nasal region.  very anding algorithm is seven key points on the nasal reg.The genetic algorithm-based feature selector is the patches and curves over different facial expressions.  algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing.1....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 126, training loss: 2.049604892730713\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 127, training loss: 2.3647043704986572\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 128, training loss: 2.6504814624786377\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:54,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 129, training loss: 2.5454320907592773\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 130, training loss: 3.1210036277770996\n","epoch 5, prediction loss: 2.7512474060058594\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the datasetsd face are used to evaluate the face recognition algorithm proposed thegc vbosphorus and and bu-3de. the proposedgc dataset is 5 with 5 sets expressions and and the bosphorus dataset includes samples of six prototypic expressions.The b was performanceing accuracy and accuracy were evaluated using and that accuracy for thegc subjects to the samples andThe robustors were inabor wavelets and the g scale were for each recognition..The results was a accuracy rates for the b al and the samples. with aness for the-neutral samples. probes.Theisons results was the algorithms is also. showing',\n"," ' in in order difference-level difference difference scheme are constructed. this paper. they stability condition for the initial the scheme is woted by w, isis to be computed with a symm levellevel numerical algorithm. the same accuracy as of main scheme. themmetrical scheme are the with the order accur. suff smooth solutions.. conditions for formulated for the symm-level scheme. the that stability with respect to the dat. high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy. the schemes can be used to solving condition w they restrictions are that using.',\n"," ' in in lie discusses the lie algebra of type an. whichoted sl sln+ is which to the graphs..in section is the all n-colored edge in the crystal graph. also discusses the the decomposition of the 4 is multiplicity-fre.......,,,,,,,,,,..................,,,......,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:02,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 131, training loss: 2.4319040775299072\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 132, training loss: 2.402691602706909\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 133, training loss: 2.868905544281006\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 134, training loss: 2.4853641986846924\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 135, training loss: 2.7608728408813477\n","epoch 5, prediction loss: 2.8968558311462402\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation.the layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization..The diraging procedure based to a of outer acoustic field with the-layer variables.Theumerical examples illustrate the validityogenization model and accuracy and with the numerical simulations of research on at improve the of compliantforated plates in vibroacoustic trans problems paper of supported by the grants grants funded',\n"," ' in in isisms are on the category of for and networks by for andfulerryerson.Theisms preserve the context are the-fululkerson flows onTheflows on networks network is defined by a inequalities.Theflow is defined to minflowichai.perner showed original on that min ranks can satisfy hall s condition are to min naturalperne poset. and har introduced hall s matching cond by prove rot. s conjecture. leading the category matching condition. a normalized of the normalized flow property. category flo is with networksyclic vertex-weighted networks. and morphisms preserving these morphisms preserving',\n"," ' the the current discusses the impact of the matter ( d)ther density using using the thermalally averaged andaged annihilation annihilation cross- forwe current have the cross-averaged annihilation cross- for f operators candidates including compare the results to compute the cos density constraint. direct are such as dermil-abs, hess are are sensitive to the types candidates.ihilation cross- are various types candidates are computed using various with le leptons and photons. results also discusses the on theider experiments to these operators for their on theh.. text is on the detection experiments involving d particleselectron scattering delastic']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 136, training loss: 2.9195804595947266\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 137, training loss: 2.66972279548645\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 138, training loss: 2.5723862648010254\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 139, training loss: 2.744291305541992\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 140, training loss: 2.598787307739258\n","epoch 5, prediction loss: 3.211794376373291\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the aim project we to come an image processing algorithm that the the university of bridgeport parking lot using using two images into with a stable device like a good camera. such the ar-drone 0 along main camera of the drone will images imagesapped images which which can then into the algorithm that. alongcv and boofcv are were used to developing processing. and thecv being java interface being used primary component ofboofcv is a-level image processing capabilities. bo low example processing algorithm.. whiching images the open goal main. stitching refers combining a 2d geometric transform which minimize two images into and a like',\n"," ' the the acoustic discusses the propagation acoustic of thero-oustic response in inwe text is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofwe coupling is on the the acoustic field in the layer with the surrounding en. the a coupling equation. conditions are the global problem are provided. and are the to the limit on the specific limit for.....,,..,...,.............,,,,ab,.,,,.',\n"," ' error error error results to that performance of the proposed e toto-end error sy for diff diffusive environment like blood.The channel coding is considered forThe performance probability performance analyzed as on the parameters like including location and and at and and symbol velocity. analyzing the parameters, the performance error probability ( ber)performance be improved. trade-off between the conversion and channel rate time also. where the trade value-to-end ber e2e)berert performance when the the energy molecular channel ( dmc) and errorstatic ( ec).. the velocity can the minimum2e berery performance increased increased the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 141, training loss: 2.518413543701172\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:42,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 142, training loss: 2.776992082595825\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 143, training loss: 2.5355918407440186\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 144, training loss: 2.4007866382598877\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 145, training loss: 2.6945531368255615\n","epoch 5, prediction loss: 3.105578660964966\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the study of a detailed overview of theson sld. a on the only and in the text of also as a guide reference for the the features in thei geometryometry. the problems.x........igenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in paper discusses numerical numerical of fractional power equations in time models with solving applications. as sub, biology or finance finance.in is on the fraction involving fractional power elliptic operators. numerical based the elements. quadlov subspace method.in numerical to solve fractional powerin-space reaction-diffusion equations are analyzed. in the integral and adaptively preconditioned lzos method. accuracy also discusses theimatingations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic operator.. is with a experiments. the results. the',\n"," ' the the effects discusses the effects of mutual inclination on the k recovery forThe study recovery study was not account for mutual multiplicity planet and thus did not account mutual incl. however planets were injected with a impact parameters from study the effects parameters mutual inclination. detection eff. here effects was at systems impact in impact parameters for recovered planet systems with known planet and. mutual inclinations can cause certain planets to ge avoid transit compleometrically comple...................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:57,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 146, training loss: 2.57080340385437\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 147, training loss: 2.560145378112793\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:04,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 148, training loss: 2.877610683441162\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 149, training loss: 2.7362866401672363\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:11,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 150, training loss: 2.4697399139404297\n","epoch 5, prediction loss: 2.558311700820923\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses the the homogenized vibroacoustic transmission model derived the text is be used for numerical simulation of acoustic waves using the two-scale in.the text is is to to the one considered section text. where the zero neumann condition appl a same acoustic fluid and the solid.. numericalscopic responses are computed in compared in fi. illustrate the model......,,,,,,,,,,,,,,,.......,,,,...',\n"," ' the the we on thet and algebra and the weil algebra. 16 55.2........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,..ivalentivalentivalentivalentawareawareivalentaware...awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalentawareivalentawareawareivalentivalentivalentivalentivalentivalentivalent',\n"," ' hom hom vib discusses the homogenization of thero-acoustic transmission on perforated plates.The is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inThe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withThe homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation pericityThe nonlocal, implicit transmission conditions involve a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 151, training loss: 3.0455713272094727\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 152, training loss: 2.396510601043701\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 153, training loss: 2.600675344467163\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 154, training loss: 2.6558327674865723\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 155, training loss: 2.671274185180664\n","epoch 5, prediction loss: 2.7953367233276367\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the differenceauchy problem method is used to solving solution solving solvingolving. the on the auxiliary pseudo-time evolutionary problem.. a priori estimates are be obtained for solve numer numer. the the prior implicit two-level euler scheme. used.. difference scheme is unconditionally stable with the initial dat.. applying these estimates recursively we the validity of the difference is proven.im....,,,,,,,,,,............ab...,abab,..ab,.ababab..',\n"," ' let let we discusses a conceptyl group of the certain ofoted w w.g by w...x.....,,,,,,,,,,,ivalentivalentivalent,,,ivalentivalent,,,ivalentivalentivalent,ivalentivalentivalent,,,,,,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,ivalentivalentivalentivalentivalentivalent.,ivalent,,..,,,,,ivalentivalentivalentivalent,,,,,,,,,,,,,,,,,',\n"," ' in in crystal result of in this paper is that multiplicity freereeness of the decom. this labeling labeling convent. which well by section 2. proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the  using the and adding loops to everyices in and adding the composition graph g, we is shown that the crystal b is type e. a multipl rule. the multipl m of x x in proofposition is multipl shown by amma. leabeling the fundamental weight. and leading in a multiplicity']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:34,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 156, training loss: 3.085205554962158\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 157, training loss: 2.450234889984131\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 158, training loss: 2.4806158542633057\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 159, training loss: 3.0368940830230713\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 160, training loss: 2.3550922870635986\n","epoch 5, prediction loss: 2.7591395378112793\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we is on the the of obtain the is component of a a refined isomorphism between the6 decomposition.The is a a isomorphism of. to theu-de-taquin.. is..........,,ad.....v.........ivalentivalentivalent.ivalentivalentivalentivalent.ivalentivalentivalent...ableableawareaware.awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other with low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss. using analysis suggests that the for detection loss canens the need for an additional population to explain the of using inclusion also suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with this notion that some populations share dynam dynam',\n"," ' in in minimal discusses the minimal domin1 theoremty singular for which the minimal assumptionsity conditions on the singular t. which the singular holds.. is that the proof on which minimal hold similar unknown. discusses are they theorem dini cond can be relaxed to. section also the minimal assumptions on t k yielding yield thewise sparse domin. text are in results and le the sectionmma. le. the. to the weak. also with showing that the the bounded extension of the t is to2 to itself if then bounded condition on hold on.......... ad ..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 161, training loss: 2.202436923980713\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 162, training loss: 2.3925726413726807\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:59,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 163, training loss: 2.614722490310669\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 5, batch 164, training loss: 2.5089807510375977\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:06,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.7020176193930885\n","epoch {}'s average verification loss: {} 2.922942563891411\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [1:01:31<40:52, 613.04s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 0, training loss: 2.4278903007507324\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.33s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 1, training loss: 2.38938307762146\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:06,  3.42s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 2, training loss: 2.630110740661621\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.45s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 3, training loss: 3.166607141494751\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:13,  3.47s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 4, training loss: 2.5447638034820557\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.48s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 5, training loss: 2.7099623680114746\n","epoch 6, prediction loss: 2.8264377117156982\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the feature selection step involves the engineeringgorithm ( ga)is to select thoseets of curves vectors extracted curves and patches patches extracted are more against facial expression.The modified vector is used to select select those most robust curves from remove the features.The varying the value vector b the subs and patches can selected or omitted based depending reducing the rates. reducing the selection. the appro. fisher fisher analysis analysis..- algorithmgorithm is to in the non dimensionaldimensional binary high-convex optimization process. with a high nsga-ii. elitism over the individuals healthy individuals..- feature assignments for the are are explained in section',\n"," ' in in continuity discusses the continuity of the heat kernels of the reflection brownian motion ( a general lipsipschitz domain.The is that existence of theelv typetype inequality on a domains like to the presence of a cusp at inf.. text prove that the heat kernel of reflection reflectionian motion on a uniform domains are continu. however not heat domainsipschitz domains is not a uniform.. text also the estimates estimates to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain isThe is important in the transformation theory of theov processes. its the-spectral independence',\n"," ' we we new method for determining the frequency of exoplanet multiplicity within the ke dat is presented. using method utilizesizes over mutual inclination and the empirical ke period set to determine the probabilities for multiple-planet systems. using isifies the of multipl containing up to 7 planets and and is important for fitting multiplicity parameters via methods like mm.umptions made made that the eccentric of planet radius and period. but eccentric orbits are assumed circular be circular. using model also that eccentricity can theicity occurrence by slightly the expected number of planets around each system. using model of this method model is that may a reasonable description of the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:21,  3.85s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 6, training loss: 2.7076807022094727\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.69s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 7, training loss: 2.424773931503296\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 8, training loss: 2.270775556564331\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 9, training loss: 2.7058238983154297\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 10, training loss: 2.653646945953369\n","epoch 6, prediction loss: 2.740006446838379\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' splitting splitting splitting discusses discusses on the splitting of double vector bundles in the context of splitting to discusses to the fields. including well in section text...42x text..........,antant,, ivalentivalentivalent.ivalentivalentivalentivalent...awareawareaware..awareaware...awareawareawareaware,,,,,,,,,,,',\n"," ' in inrones are getting being in various fields fields. the such google, facebook, amaz amaz. their own drone technology.dron are used in various journalism so obtain videos of areas toto-access areas.dcopter are which quad of quad that four rotorors are are one used in and the spinors working clockwise and two other two spin counterclockclockwise. balance that.dron are be autonomously based on a-entered program without and without with a resolutionresolution video. image processing and computer vision techniques. in, such of when a or or satellite-captured satellite maps are not. in research',\n"," ' in in text of that to the the augmentation of in a data from a with less population in the dat isin aug of aug and convstm layer on generate the pattern of directions and windows windows sizes in the flo function and and the distribution functions ( pdfs )of every features using and points points in each feature dom and on the pdfs and and generating points dat dat. the.The the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat. and a batch architecture. rel normalization lay.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 11, training loss: 2.4683496952056885\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 12, training loss: 2.3243770599365234\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 13, training loss: 2.5444982051849365\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 14, training loss: 2.2940421104431152\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 15, training loss: 2.3994572162628174\n","epoch 6, prediction loss: 2.8777177333831787\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[\" k krillov-reshetikhin modules k)cry are a-dimensional representations for affne lie algebras. by their drinfel'd polynomials. are mathematical. such as solutions of the q-system.k k for to determine a uniform model for k modules. which are been achieved for br,1. kashiwara. construction of.aito and sagaki have constructed k construction brceptional affne br using lmibai-seshadri paths.. crystals are perfect for the physic and have connected to mathematical q mathematics subject class 05e10,17b\",\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the need of by the-rigid objects expressions.3isting approaches for such the iterative closest point algorithm and can become to variations minima and3 approach to capturing a range of facial expressions for each subject and storing them with the subjects in each. but this are are capturing and storage.3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to address theness against variations expressions. in research have focused the to the multiple normals hist local',\n"," ' the the high discusses the method of the order difference schemes for solving thestationary cauchy typetype ellipt. to theal power elliptic operator.The order approximations are used to approximate the time dependence of the solution while while the elliptic operator is approximated by the finite element sche.The. stability conditions are given for the-level discrete schemes with weight weight parameter.The order accuracy is proved for the symmetrical crankank-nicelsonson type sche.The family of three-level symmetrical discrete schemes is constructed. investigated. and on the smooth solution.The condition on the first time level are computed by the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:58,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 16, training loss: 2.2980661392211914\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 17, training loss: 2.546807050704956\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 18, training loss: 2.578432083129883\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 19, training loss: 2.817296028137207\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 20, training loss: 2.799013376235962\n","epoch 6, prediction loss: 2.5890655517578125\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in type discusses the the type e6 crystal decomposition into constructing the and adding loops at everyices. the the composition graph.The example decom r is a as an i0,7-highest weight ele. the sectionposition........,,,,,,,,..........ivalentivalentivalent.ivalentivalentivalent..ivalentivalentivalentivalent.ivalentivalentivalentivalentivalentivalent..ivalentawareawareawareawareawareawareawareawareawareawareivalentivalentadenawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' in in text discusses the -to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes.to of the molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is computedimated by sim s rul.The orderpembol interference is ignored. the the of left to future work. to error error performance ( is also. the on- and and off-body communication channel. the the of the such the between motion of-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' j j j discusses the use theory of scalar-tensor theories f the j frame beyond focusing the importance of ill order time derivative terms in are ill-posednes in however, equations is shown that equations of motion can always reduced to second second-order-in-time form as the original e frame formulation is well posedposed. inverse transformation from the j frame back the e frame is not be possible for all field values in the in but it fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f. text motivation is a better understand spontaneous scalarization and its general']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 21, training loss: 2.539926767349243\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 22, training loss: 2.6869454383850098\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:23,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 23, training loss: 2.363708972930908\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 24, training loss: 2.612088918685913\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 25, training loss: 2.297795057296753\n","epoch 6, prediction loss: 3.001519203186035\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the convergence discusses the properties for on the priori estimates for the a. based text provides convergence convergence of the unfolded function. the2.i to the convergenceation of the limit vibro-acoustic problem. a formal approach. the sequences constructed with the convergence res.based............ad...........................,,......,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in crystal result of in this paper is the multiplicity freereeness of the decom. this labeling labeling convent. which well by section 2. proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the  using the and adding loops to everyices in and adding the composition graph g, we is shown that the crystal b is type e. a multipl rule. the multipl m of x x. proofposition is multipl shown by amma. leabeling the fundamental weight. and leading in a multiplicity',\n"," ' in in paper discusses numerical numerical of fractional power equations in time models with solving applications. as sub, biology or finance finance.in is on the fraction involving fractional power elliptic operators. numerical based the elements. quadlov subspace method.in numerical to solve fractional powerin-space reaction-diffusion equations are analyzed. in the integral and adaptively preconditioned lzos method. accuracy also discusses theimatingations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic operator.. is with a experiments. the results. the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 26, training loss: 2.686224937438965\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 27, training loss: 2.6147778034210205\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 28, training loss: 2.609557867050171\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 29, training loss: 2.967755079269409\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 30, training loss: 2.348027229309082\n","epoch 6, prediction loss: 3.259272813796997\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study discusses on the multipl effects multipl the parameters parameters provided theoseismic data fromwe study of new updated allows the radius measurements andwe explore thelier systems in the ga data we we measurements are tested against the ke dr25 cat. to of also from the curves and thus periods need on the data keks.. to positives are removed using the thes to thus are planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in with a of on the and period cuts. when with multiple positives are artificially removed to accuracy order accuracy with detection detection multiplicity we in 7',\n"," ' the the boundary discusses the boundarydimensional haddorffme on the to the the the boundary local time of the.. section also the naotoaka kajino for his comments on the proof. lema.............ad...............................................',\n"," ' the the impact discusses thely interacting dark matter ( interactions their interactions with focusing are be motivated from various detection indirect detection experiments.The u physics extensions of standard standard model ( sm) and been proposed to provide the matter candidates d) candidates or whose as uly interactingacting neutral (ons ( wimps)  detection experiments have shrunk the parameter space of the models where theimps to with the visible world viaThe constrained of sm particles sm model particles are encaps in the lagrangian approach. where the of the dimensional effective operators constructed thesestrained on these higher are discussed from various data. estimate the the u models.The sensitivity']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 31, training loss: 2.2039380073547363\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 32, training loss: 3.078695058822632\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:00,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 33, training loss: 2.394331216812134\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 34, training loss: 2.812356948852539\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 35, training loss: 2.5301311016082764\n","epoch 6, prediction loss: 2.597811460494995\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the keism we by this study is applied to derive the occurrence rate parameters for planets orbiting gk dwar stars.  from the final ke data dr25 and including planet radius measurements from theks and ga and, and corrected detection eff for multiple-planet systems are used.  resulting includes on previous poisson process likelihood function used includes a modifiedesian framework to using anm.The resulting are that values for the occurrence of including a in the best fitfit model occurring at p times of novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m',\n"," ' abstract abstract concept on the concept of the of abstract u. the the on theq-crystals. a abstract on the e 7.kin diagram.The is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals. concept also the conceptor product convention for the tens for the abstract crystal. be a as a uq-crystal.. a u uq-mod.....,,,,,,,,,..........',\n"," ' in in text results a model is three different datasets shows that the method of sampling in able in handling thebalanced datasets.The results are to precision1 measure and precision and and recall measureThe performance is performance on compared with sampling in and the in precision and in to higher false predictions predictions and overall accuracy of the model is also than sampling in with a improvement in precision and recall and and confusion accuracy. model also that accuracyiz accuracy accuracy decrease in false negative. to the..mp........dddddddddddddddddddddddddd,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 36, training loss: 2.539173126220703\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 37, training loss: 2.3668019771575928\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 38, training loss: 2.392669200897217\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 39, training loss: 2.8552818298339844\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 40, training loss: 2.6315603256225586\n","epoch 6, prediction loss: 2.2584972381591797\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' scal scalalar-tensor theories have commonly alternatives to general relativity and have had a large impact on cosmology.sc theories commonly variousar degrees of freedom in addition to the usual metric of general relativity. but to various phenomenology due to various coupling terms in their action. the relationship to choose the field variables while them the of the the j frame or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form. the relationship focuses to generalize the analysis of these relationship between these two to theories that higher spin fields such vectors instead. study of on theories',\n"," ' in inore discusses the but/ extensions of the theorem theorem of point on the specific precise version of pointwise sparse domination 7. text of the theorem result compared the original theorem is that. and applications is used how it result can used in a applicationsorems. text also discusses a use to the theorem to a multilinear cas. and the the results.essary changes in the proof are made out. and the the original idea. the theorem theorem......... iii',\n"," ' the the acoustic discusses the method analysis for the the acoustic acoustic pressure and the displacements and and rotation in a limit lay.The result is based for understanding understanding- and equations of vib vibroacoustic problem imposedThe convergenceymptotic analysis is based using the unfolding method. which developed for the seminal paper by elaborated elaborated further thin structures inThex........gg.   ,.,....,,....,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 41, training loss: 2.8822388648986816\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 42, training loss: 2.75982403755188\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 43, training loss: 3.26796817779541\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 44, training loss: 2.8724632263183594\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 45, training loss: 2.597865104675293\n","epoch 6, prediction loss: 2.2419168949127197\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the tree discusses the tree-matal amplitude and d3-brane couplings in the on the thelevellevel s-matrix elements of one ramond-ramond and three open strings. imposing symmetry symmetry the tree-level s-matrix elements of one kb-ramond and three open string.. also discusses a effective invariant form of the d3-brane effective action containing derivative gauge fields with derivative corrections that from one-loop level four-point amplitud. text with derivative corrections at found at expansion the nonlinear sl invariant structures. the more gauge fields.x..',\n"," ' ch chorem discusses theic surfaces3 surfaces of ch ch to chow motives of surfaces.1 also a proofposition of theow motives of surfacesic surfaces into aic and transcendental components. and by a comput. computations.The sectionogenical decomposition of theelian varieties with group action is also. and to a proof of the specific example.The section discusses with a discussion on the specific example in a product of singular algebraic k3 partner of the minimal between theers surfaces. ch resolutions. showing the importanceogenism between theental surfaces of............',\n"," ' reinforcement reinforcementactionforcement learning ( have agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples to algorithms can however of performing as humans, can called as a for the a intelligence intelligence. to advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for reinforcement tasks. to develop the useability of reinforcement learning into it need of explainable and networks-based reinforcement is crucial. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent. whose simple rule. decision-making.pirical evaluation of that for building a comprehens and comprehens agent using a method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 46, training loss: 2.461104154586792\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 47, training loss: 2.36250901222229\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:55,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 48, training loss: 3.0469348430633545\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 49, training loss: 2.7948784828186035\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 50, training loss: 2.5958149433135986\n","epoch 6, prediction loss: 2.831192970275879\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' deep deep learning ( ability to high stakesstakes decision problemsmaking is still challenging for it influence may uncertain. extensive test. whileing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents, provide their performance-making process. however such studies have focused on feedability of feedforward deep learning agents we studies focused interpret issue of more learning. well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is transparent agents. in potential approach can to provide the in reinforcement learning agents.',\n"," ' internet internet internet discusses the deep learning on network in analyze flow traffic patterns order imbalanced environment.has proposes a novel augmentation approach based longstm network for generating flow patterns and and kernel density estimation for replicating the features of The results is to improve the with which internet network with less popul of. of datasets datasets demonstrates that performance of precision of precision, recall, and f1 measure. every classes classes.......,,,,,b,,,ddddddddddddddddddddddddabbb',\n"," ' a a study discusses auscule represent with the to the weight uq-crystals.The. weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. thex...........,,,......................................adenadenadenaden,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 51, training loss: 2.267472505569458\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:10,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 52, training loss: 3.7836413383483887\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 53, training loss: 2.7397475242614746\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:17,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 54, training loss: 2.8010737895965576\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 55, training loss: 2.633592367172241\n","epoch 6, prediction loss: 2.8193235397338867\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses the classification of irregular with by theodge theory. specifically the the which irregular3 type. product modental part.. are the related the group of these surfaces and their conditions answers to the questions. certain conditions. text also the the classification of these surfaces is not not. that the state state of the art. also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac. results obtained can used to prove that t- mumford-tate conjectures for these surfaces. proof also the support of inspiration. provide a overview of the current state',\n"," ' in in text discusses a construction of uniformly well and and and the mean curvature and a. the applicationability to the hypersurfaces.The also the wellence between the concept of uniformly strongly elliptic and uniformly normally elliptic hypers the contextar case. well -posedness result for the sphere class is derived. the methods. results textms. including the importance.chitz continuity of the semiflow.........,,............abababababababababababab',\n"," ' the the main algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the heant of the heian matrix is usedized.sur determin is two from using blending the last image for performance and level detail detail and rendering in a final merging.The algorithm image image is as input input for the algorithm. the analysis. the drone moves forward.The.......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 56, training loss: 2.6270508766174316\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 57, training loss: 2.7130868434906006\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 58, training loss: 3.081308126449585\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 59, training loss: 2.6633474826812744\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 60, training loss: 2.6977574825286865\n","epoch 6, prediction loss: 3.319502830505371\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using using study discusses the use of creating a stellar sample for use a detection efficiency map using the data. the1q17.0 stellar includes a parameters from theur et..s ga stellar values from ga dr2. the values have been been updated from the dr2 the the has25 stellar parameters values have updated updated. ensure thatteness mapping of we star must have a stellar of its radius and mass measurement values for either fields result in omission., the on placed on the cycle and f) >.5)and time length ( light light curve ( final includes a-varying noise',\n"," ' the the comb discusses the comb of a7 crystals weight elements from decom the7 highest weight elements. a decom computation..The proofposition into e7 crystals is multiplicity free and is discussed to the comb that to the one of proposition conjecture inThe proofinatorial r-matrix must used to its ability to map classical components to classical components. and the weights are k k are k. computed. a function.The is can as a proof towards proving a conjecture regarding proving a construction of a7crysta value. the certain way.....             ',\n"," ' the the sensitivity discusses the sensitivity of the constraints on the matter pair d)- at including on the sensitivity to sensitivity to the momentum of d pair atom and/- electronron scattering. to suppressed of quarks inon is the need of theizing dpto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh) and discusses the need of the the- to the-2 operators.on study is discusseszes the state effects of d- atom scattering cross dama data. derives the the pair production channels at the proposed linear coll ( ilc)  analytical also the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 61, training loss: 2.638528823852539\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 62, training loss: 2.6225879192352295\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 63, training loss: 2.6685826778411865\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 64, training loss: 2.316470146179199\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 65, training loss: 2.6144790649414062\n","epoch 6, prediction loss: 2.7525956630706787\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this context of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play crucial building the-nano-medical applications. in paper presents the e-to-end communication link consisting electromagnetic electromagnetic and molecular communication.  closed-form expression for presented for the e error probability ( the e system system.based optimization method is formulated with minimize the bit error rate of the the optimal symbol duration for the time from. numerical proposed is solved by an iterative algorithm based on the bisection met.umerical results show that the proposed method ob ob',\n"," ' in in text discusses a examples of the admitting admit thewise sparse domin.The focus discusses the the of bounds are known known. but the unified approach simplified approach to provided to on theore 1. its variant. results are from from the results. consideringi l and sheldy ombrosi. and the improvements provided in section..4 text text is the the text admits of weak type. to theorem 1. and a specific refined result with by the slightly case. by.......ad,.ab,.',\n"," ' molecular molecular : the the performance increase in the demand for health services is rapidlyacing the increase in health health services and professional necessinmedicine is which implementation of tele technology to provide medical services is has a as a promising solution for address the needs.in is the communication communication sensing technologies to provide biological signals and medical them information to the providers.in of application of telemedicine is the delivery which which the focus on the therapy. control targeted information to the. minimizing the effects.in between a central role in the themedicine system. which the developments has to the-based molecular communication ( inner body and communication.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 66, training loss: 3.3259458541870117\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:05,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 67, training loss: 2.5923116207122803\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 68, training loss: 2.991382122039795\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 69, training loss: 2.5172231197357178\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 70, training loss: 2.503790855407715\n","epoch 6, prediction loss: 2.605689764022827\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the study. a study of ant antichain a a pos connected set. aet ) and no two elements are compar.The. and et....,,,,,,,,,,,,,,,,ivalentivalent,,,,,,,,,,,,,,,,,,,,,,,,ivalentivalentivalentivalentivalentivalentawareivalentawareivalentawareawareawareawareadenawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware,adenivalentadenaden,,,,,,,,,,,,,,,,',\n"," ' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other with low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss. using analysis suggests that the for detection loss canens the need for an additional population to explain the of using inclusion also suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with the notion that some populations share dynam dynam',\n"," ' the thefaces diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space. these surface velocity of evolving surfaces is determined by purely geometric quant. while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, these paper considers uniformly regular hypersurfaces. which non-compac surfaces.. utilizing the study of uniformly larger class of manifolds and we study presented to the study research of geometric flows on non-compact manifolds.. study relies based by the theory of continuous maximal']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 71, training loss: 2.268690824508667\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 72, training loss: 2.7840943336486816\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:27,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 73, training loss: 2.367461681365967\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 74, training loss: 2.5443263053894043\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 75, training loss: 2.8780503273010254\n","epoch 6, prediction loss: 2.377652168273926\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. a novel five-step algorithm is presented. based with aly of the nose tip location segmenting and aligning the face and and thenpping the nasal region.The very anding algorithm is seven keypoints on the nasal reg.The genetic algorithm-based feature selector is the patches and curves over different facial expressions.The algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing.....',\n"," ' the the textogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated solid structure. model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation.. model of are the the referenceogenized and the models are constructed in responses of the homogenized model is performed in two steps. comparing responses of acousticlections obtained by direct numerical simulations of- firstogenized model andifies the problem by to the complexity of the fe element mesh complexity increasing number of holesforating holes. reference are implemented',\n"," ' the the this context model section agentss and is q) and interact with r learning ( r) agents and make models env) agents. learn future actions.qs three are constructed using thetorch, an open-source machine learning toolkit.qx,....,,,,,ibib,.............................,........awareaware,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 76, training loss: 2.6798691749572754\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:42,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 77, training loss: 2.9818785190582275\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 78, training loss: 2.5586884021759033\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 79, training loss: 2.3160390853881836\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 80, training loss: 2.5975089073181152\n","epoch 6, prediction loss: 3.1226325035095215\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the reconstruction.The algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.themarksing is on a minima detector operator isative algorithm. remove landmarks landmarks in the nasal region. such as the nasalnasale l sub corners landmarkslieriers are removed using aative methods. remove the selectioning. algorithm is to reduce identify the al such maintaining redundant parts. the face.............',\n"," ' stars stars lack discusses the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity stars systems.The using these function to we expected suggests that 0 empirical empirical multiplicity of be increased by a function of selection effect. best also discusses the implications of this function to the the for the multipl and period., the is the impact of this model of multiplicity in our solar system for theability. highlighting that lack for a studies for support such claims............ddddab.',\n"," ' in in study study in this paper is more 70 gigabytes of real traces traces from am campus of amirkabir university of technology. which of more and tcp link.Theows are identified using n n sourcesource dpi tool n nd.. which the classes of applications from for more 50 gigabytes of data. including more.,000,.The percent of these flows were used for training and while the rest are test datThe dataset includes 90 total of applications classes and including more classes of more than thanThe dataset also a imbalance feature with more 83 percent of the dataset consisting of 4 cl ofdpi, the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:57,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 81, training loss: 2.850992441177368\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:01,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 82, training loss: 2.5776150226593018\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 83, training loss: 2.7207257747650146\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 84, training loss: 1.9113495349884033\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 85, training loss: 2.2303292751312256\n","epoch 6, prediction loss: 3.592618227005005\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the theac s2obs- are used models that are the a textac equations with a externalic function.. create a set set with with a information. structures are called in the context of the equations. are be used to various applications models. the of theolds.x........igenigenigenigenigenigenigenigenigenigen.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.The results was tested with a sampled datasets augmented datasets. and compared results show that our proposed approach outperforms thenn. terms of accuracy, recall, and f..........dd..abdd....ababab............ababab..',\n"," ' this this text section the in the images images. to the. can be the of.The text used in to address these by improve that transitions between images images.The, ity details details can occur occur the quality.Theosing the best appropriate algorithm for this problem is a. to the issues.Theio algorithm.........addadd..addaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenaddaddadd.adenadenaden..ab.ababababababababababababababababababababab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 86, training loss: 2.244889974594116\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 87, training loss: 2.7187249660491943\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 88, training loss: 2.2899460792541504\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 89, training loss: 2.801009178161621\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 90, training loss: 2.584754705429077\n","epoch 6, prediction loss: 3.0475966930389404\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses the the homogenized vibroacoustic transmission model derived the text is be used for numerical simulation of acoustic waves using the two-scale in.The text is is to to the one considered section text. where the zero neumann condition appl a same acoustic fluid and the solid.. numericalscopic responses are computed in compared in fi. illustrate the model......,,,,,,,,,,,,,,,.......,,,,',\n"," ' the the study discusses a detailed overview of theson sld. a on the only and in the text. also as a guide reference for the the concepts in thei geometryometry. the problems.x........igenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' ke ke ke mission has increased our understanding of the around sun-like stars.the final data release dr dr25, provides all on to the failure of two reaction wheel. providing the end end of the primary phase ofTheorts are made to quantify the frequency of properties of planets systems and with the on the with earth-like proper........,,,,,,,,,iv,,,,,.................iviviviviviviviv.iviviv...iviviv..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 91, training loss: 2.181594133377075\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:37,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 92, training loss: 2.8507187366485596\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 93, training loss: 2.1837334632873535\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:44,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 94, training loss: 2.8716132640838623\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 95, training loss: 2.970395088195801\n","epoch 6, prediction loss: 2.589334011077881\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous bay using focusing upon previous bay and extract information about the multiplicit. comple a best replication of the empirical popul multipl. studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a larger maximization technique to a the distributions for a parameters. with the from previous provided previous bay. we study is that with the with previous studies. with with the case of small radius planets. to detection threshold. usingorously treating completeness mapping and a',\n"," ' in in goal aims to create the quad to camera to take images images from a parking parking lot and blend them to create a large image image. the entire parking. to approaches were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to field was images images during certain points intervals during create the merging of to this field test  we image lot was divided into a 4x4 matrix matrix better the drone. movement.. algorithm was using images at different and then them images together each column, and then merging them columns together after to',\n"," ' the the ke discusses the impact of detection detection of represent the detection eff of the ke mission forto grid is created into 100,000 regions in period and radius spac and for region is divided in in log space for period and radius spac all each are assigned m based on the order. for probability order is are the for detecting multipleoplanets within each detection within. probability described repeated for each of and the detection order grids. to probability efficiency maps for the effects of limbity and limb the new function for account mis mis transits within thepreating between made to determine the probabilities for different detection order. the probabilities are created using higher multipl']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 96, training loss: 2.4573476314544678\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 97, training loss: 3.127866744995117\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [05:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 98, training loss: 2.2244246006011963\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 99, training loss: 2.604721784591675\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:06,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 100, training loss: 2.4324188232421875\n","epoch 6, prediction loss: 2.791334867477417\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the acoustic discusses the propagation acoustic of thero-oustic response in inThe text is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofThe text is on the the acoustic field in the layer with the surrounding en. the a coupling equation. conditions are the global problem are provided. and are the to the limit on the specific limit for.....,,,,,..,,.............,,,,,,,,',\n"," ' using usinginstein of are transit transit study have to properties of the populations fromusing key function is used for determining bayesian theorem theorem and extract parameters parameters. using method distribution is assumed as independent independent power lawlaw distributions in period and rad. using distribution that a single population population is made assuming assuming the distribution of this assumption is examined.using distribution focuses on multiple systems with examineszes the effects effects introduced the and multipl. distribution used to on previous studies to utilizing planets by detection order. results show insight on the factors detection order. show distribution parameters functions this introduced the distribution distribution fun. to this. statistics are discussed for to',\n"," ' the the influence discusses a results test of the homogenized model of a perforated plate of the reissner-mindlin typ.The impact is to compare responses responses of the homogenized model model with the of the associated 3d elastic structure withTheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.The deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat modelThe influence of the compliance on the loss in the waveguide is discussed.The influence']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 101, training loss: 2.3252251148223877\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 102, training loss: 3.1870601177215576\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 103, training loss: 2.266402006149292\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 104, training loss: 2.9648938179016113\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:25,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 105, training loss: 2.273102283477783\n","epoch 6, prediction loss: 2.7598400115966797\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in order difference-level difference difference scheme are constructed. this paper. they stability condition for the initial the scheme is woted by w, isis to be computed with a symm levellevel numerical algorithm. the same accuracy as of main scheme. themmetrical scheme are the with the order accur. suff smooth solutions.. conditions for formulated for the symm-level scheme. the that stability with respect to the dat. high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy. the schemes can be constructed to solving condition w they restrictions are that using.',\n"," ' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using findingating them key points between the and and then a robust fitting to to finding changes transformations. as rotation.The, when we to stitch more result image with a third image using the will. the result will tries the black background. the image process. to distortion is caused by the that theofcv. so to a images. stitching more than two images. to avoid this issue we open algorithm was implemented using openc. find this distortion issue by theofcv. translation. to.....',\n"," ' boundary boundary this paper we we boundary discusses the boundary of boundary boundary value problem for the fractional power of the power power.The is the boundary to solvingimating boundary boundary by the finite of finite finite element method.x boundary boundary....,,,,,,,,,,,,,...,,,,,,,,fbfb,.,,awareaware.,,,aware..,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:29,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 106, training loss: 2.6085963249206543\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 107, training loss: 2.2447798252105713\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 108, training loss: 2.5365238189697266\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 109, training loss: 2.427037000656128\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 110, training loss: 2.5168986320495605\n","epoch 6, prediction loss: 2.837236166000366\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' computer computer proposed presents a method called d map Creator using dmc), can computer vision technique to create create a by stitching together visual information captured by a d. camera camera.The proposed utilizes the speeded up robustotic features method to detect the points for each image frame. identify the the points between frames. maximizing the determinant of a heian mat.The proposed points are st to st together two by and in a st creation. some from the external environment...... ad     dddddddddddd',\n"," ' in in index discusses theasipinear inequalities with aitycommity. whereizing the index j sub acritical. the certain inequality is satisfied. critical in equality holds in case certain case.x.........ivalentivalent,,,,ivalent,,ivalentivalent,,,,,,,,,,,,,,,,,,,ivalentivalentivalentivalentivalent,ivalentivalent.ivalentivalentivalentivalent..,,.....,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the ke discusses the impact for incompleteness due ke planet occurrence rates due to transit multiplicity in. ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics affecting affect the radius and period distributions of each detection ord. text rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog. results model includes consistent with the studies but now includes an improved estimate of the multiplicity distribut. from average discusses']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:48,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 111, training loss: 2.168064832687378\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 112, training loss: 2.151843786239624\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:54,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 113, training loss: 2.6890268325805664\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 114, training loss: 2.507106304168701\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:01,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 115, training loss: 2.6385815143585205\n","epoch 6, prediction loss: 3.225994348526001\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' image image use discusses with the algorithm developed by us authors is a best candidate for creating a bigger image from small images. and theofcv can results to fit two images with better accuracy.after algorithm also the theofcv can results would be imp for the mapping because to the it.he algorithm concludes the the algorithm developed short of achieving goal of create the parking lot. and the in the stitching and the ar-drone 0.0.0 also that the different version of the ar with even different camera with a 1080p camera. this image.The, the issues with the ar were to the results stitching..The text',\n"," ' in inorem discusses a proof of convergence theorem on the the monmma. is the convergence of the pro. themma.. le to text condition. shown in section section by section also a concept ft : the to themma 3. le sectionotone convergence theorem., the introduces the ex for the with respect to the probability measure. the with section with proving le textms. lemmaps..............aware.....',\n"," ' double double study discusses theinc s lie bundles and a are the to the lie algebroids. text was been in applications to other fields systems., it text discusses the splitting of double vector bundles into-....,,,,,,,,,,,ivalentaware,,,awareawareivalent,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 116, training loss: 2.4875848293304443\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:09,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 117, training loss: 3.174159526824951\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 118, training loss: 3.1952781677246094\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:16,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 119, training loss: 2.3830995559692383\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 120, training loss: 3.0600223541259766\n","epoch 6, prediction loss: 2.6614885330200195\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' splitting splitting splitting discusses the splitting theoremorems of homson pairs and j proposed by dazord, lichnerowicz and and marle inas. point is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.............,,.....,,,...,........,,,..',\n"," ' in in first discusses the thestation fractional power elliptic operator equations numerically. using equivalent local nonstationary initial value pseudo-parabolic problem.The such were the implicit backward and symmetrical euler method. while the paper introduces to the fourth-parameter family of three-level finite difference schemes forThe fourth-order approximation scheme is developed by optimal optimal weight paramizationThe resultsical analysis and are supplemented by extensive computational experiments......,,,......',\n"," ' using using importance discusses a the in the measurement into a bayesian hierarchical model. occurrence for parameters. order context generation of occurrence fitt methodsThe importanceicity parameters derived here be in determining an eta earth measuremen the importance of neighboring planets could the long of an earth analog is multiple multiple sy may important. importance also that a injection experiments to determine the eff across understanding the effects. detection eff.ining data from missions will it as ke and t tess will will will essential to understanding occurrence measure. as for the detection effiencies across method described here to incorporate these selection effects into maintaining a uniform distribution distribut. method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:24,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 121, training loss: 2.9407413005828857\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 122, training loss: 2.7260286808013916\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:31,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 123, training loss: 2.918867349624634\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 124, training loss: 2.222342014312744\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:38,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 125, training loss: 2.638658046722412\n","epoch 6, prediction loss: 2.9076294898986816\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' feature featureised features descriptors are used to the nasal region using the features in spherical. theseised from theabor wavelets filters are a featuresors. which to a dimensionality and reduced redundancy and and improvedabilistic feature selection. reduce the to facial expressions while maintaining theinative features.The landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.The sphericalors are the use of the spherical on the nasal surface. when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........',\n"," ' the the text discusses the results in to the theory dir subsetets and andichlet forms and andotone class argument, andity and and domain,, and eigenfunction, and and and finini theorem theorem.The words are the thatity, the dirichlet form, showing convergence of themma 1. proof. to le results. section also discusses the sectionification theorem. the principaln t. l. the sectioniteness of the*.................',\n"," ' the the t discusses the t- mumford-tate conjectures for surfaces s connected components of the gieseker moduli space that contain a product-quotient surf sur. and....,,,,,,,antivalent,,....................................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 126, training loss: 2.1775965690612793\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:46,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 127, training loss: 2.962944269180298\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 128, training loss: 2.275620698928833\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:53,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 129, training loss: 2.8562142848968506\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:57,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 130, training loss: 2.536830425262451\n","epoch 6, prediction loss: 3.27323842048645\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the is on the the of obtain the is component of a a refined isomorphism between the6 decomposition.The is a a isomorphism of. to theu-de-taquin.. is.......,,,,,ad.....v.......ivalentivalentivalentivalentivalentivalent....ableableawareaware.awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' the the t discusses the tford-tate and t conjectures for surfaces surfaces mentioned and on the cycles-- ofThe textford-tate group is v is denoted by g, g, is the using detail to theic cycles and motiv.The t also a of to theelian motives and theodge m. and that existenceelian nature of the fib. textford-tate group is proven for the certain fib. the alese variety. and a to the thodge conjecture. the class.The............',\n"," ' the the proposed space method the filter is based on the surface normal methodThe proposed feature proposedises thelets overlap and redundancy in the images. is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations.o the frequency component set. proposedization for the scale and are computed into a block matrix. the analysis.x....,,,,,,,,,.................,,,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:01,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 131, training loss: 2.35229754447937\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:04,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 132, training loss: 2.550368309020996\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 133, training loss: 2.362872362136841\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:11,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 134, training loss: 2.708671808242798\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 135, training loss: 2.598745107650757\n","epoch 6, prediction loss: 2.5240204334259033\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in e discusses with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is conducted.The closed-form expression for the e error probability of concatenation of molecular two channels was derived.The optimization problem was at minimize the e error probability was conc system was formulated to determine the symbol durations for both molecular of communication.The reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication.......,,,,',\n"," ' hom hom text discusses the homogenization of thero-acoustic transmission on perforated plates.The is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inThe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withThe homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness which which to the plate thickness and toforation pericityThe nonlocal, implicit transmission conditions involve a',\n"," ' the the aim project we to come an image processing algorithm that the the university of bridgeport parking lot using using two images into with a stable device with a good camera. such the ar-drone. along ar camera of the drone will images imagesapped images which which can then into the algorithm that. alongcv and boofcv are were used to developing processing. and thecv being java interface being used primary component ofboofcv is a-level image processing capabilities. bo low example processing algorithm.. whiching images the open goal main. stitching refers combining a 2d geometric transform which minimize two images into and a like']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:19,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 136, training loss: 2.7255301475524902\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 137, training loss: 2.6822903156280518\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:26,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 138, training loss: 2.80049729347229\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 139, training loss: 2.321467876434326\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:33,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 140, training loss: 2.3459181785583496\n","epoch 6, prediction loss: 3.0836548805236816\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' we we study discusses the study of a ensemblene affinvariant ensemble sampl to explore 13 sets toThe bayesian framework is linear space uniform priors is used toThe toors are used for the 13 ofbr and pbr. on the distribution sample. casc prior is that f must must be larger than f parameter avoid trunc. prior is is for larger multiplicity systems to be more common than smaller multipl......,,,,,,....... ',\n"," ' the the this context section themology andarticles theoryversal are considered. a method model. can a crucial role in the the understanding the systems. systemsversals are a framework tool for studying the such the thelectic and nonyphlectic structures are involved. considering the structuresversals as  can able to study insights insights into the nature of dynamics between the systems. and them useful valuable resource for understanding areas fields. modeling.x...........,,,,,,,,',\n"," ' the the j discusses the j of generalizations of spontaneousar- andensor theories where sts)based the j frame where where where the scalar field replaced with other fields and couplings can depend on derivative. specifically study came from the that spontaneous tensoriz where where are most naturally defined in the canonical frame where however are be applied to any generalization of on a conformal scaling of the metric in the matter action by first focuses vector the scalar field a vector field the-tensor theories obtained vector to the-based spontaneous scalarization arezing the j of interesting time derivative terms in no renders orderorder equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 141, training loss: 2.3526318073272705\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:41,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 142, training loss: 2.9973597526550293\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 143, training loss: 2.681609869003296\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:48,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 144, training loss: 2.6391520500183105\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 145, training loss: 2.5894205570220947\n","epoch 6, prediction loss: 3.447845458984375\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' effective effective effective discusses the effective interactions of darkermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the effectiveally averaged indirect indirect matter pair d) pair annihilation cross-section and the spin-independent d - with le and/or bound electron. and that with the data......,,,,,,,,,...,........',\n"," ' in in text discusses a aff answer to the question of theodge struct andoremical weight...12 is the weight of the. the is a eve for12 proof also the. prove to t twists of the hodge struct. the that l is unimodula. text involves in a slightly weaker form of theorem theorem of a a construction involving involves similarrewise a primitive embedding and a hodge isometry on the transcendental lattice. proof of v resultingodge is is2 new is the by the.k2.12, the weight of the ranks of h2 new and h is theoted by',\n"," ' with with traffic is a for the ever amount that in withifying the patterns and applicationsifying applications is two tasks in with traffic tracingifications ( nt)) have classify anomalies in classify applications for however they methods have shown. port on ports in lack issues. their. ingorithms have these classification classification have promise in they methods for however thebalanced datasets is networks-scale networks datasets a challenging for deep. f.. inmentation is have machine learning have such as artificial artificial data for are address these imbalance issues, novel approachmentation method is k dataensity andimation ( kde)and lestestTerm memory ( lst']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:56,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 146, training loss: 2.497776508331299\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 147, training loss: 3.035240650177002\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:03,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 148, training loss: 2.3576996326446533\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 149, training loss: 2.6045684814453125\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:10,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 150, training loss: 2.6848483085632324\n","epoch 6, prediction loss: 3.1426098346710205\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the en model ( the context is the en. modeling into state vector and action a inputs and the the next state.The this text, the network layer of 300 nodes is used to the model network.The is shown using the squared error regression each episode of random learning.. a ensemble learning rate of 0.0................dddd.dddddd.ddaddaddaddaddaddadd.,add.......,,,,,.',\n"," ' error error error results to that performance of the proposed e toto-end error sy for diff diffusive environment like blood.The channel coding is considered forThe performance probability performance analyzed as on the parameters like including location and and at and and symbol velocity. analyzing the parameters, the performance error probability ( ber)performance be improved. trade-off between the conversion and channel rate time also. where the trade value-to-end ber e2e)berert performance when the the energy molecular channel ( dmc) and errorstatic ( ec).. the velocity can the minimum2e berery performance increased increased the',\n"," ' let let we discusses a conceptyl group of the certain ofoted w w.g by w..Thex.....,,,,,,,,,,,ivalentivalent,,,,,ivalent,,,ivalentivalentivalent,ivalentivalent,,,,,,,,ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,ivalent,ivalentivalentivalentivalentivalent,ivalent,,,.,,,,,ivalentivalentivalent,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 151, training loss: 2.333430290222168\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:18,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 152, training loss: 2.660412311553955\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:21,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 153, training loss: 2.5618128776550293\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:25,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 154, training loss: 2.641788959503174\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:28,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 155, training loss: 2.6641509532928467\n","epoch 6, prediction loss: 2.649571418762207\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the point. the improved version of the pointwise sparse domination principle established by the first author in. allows allows us obtaining singular singular assumptions on for a singular integral operator to admit a sparse domin...........,gn,,,,,,,..............................aware.......aware,,,,,,,,,,',\n"," ' the the text. thexiv:190. a detailed description of the results details of in the text.ar discusses the main points of discusses. were be discussed. including a a detailed overview of the is expect from the future section.arx.......,,,,,,,,,,,,,,.,,,,,,,,..,,,,,...,,,,..,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," \" reinforcement reinforcementinforcement learning ( inspired by brain brain's reward-based learning process allows artificial agents to learn a without detailed instructions or labeled training sets which given study is essential for supervised general-like intelligence agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are not incomprehensible and inparent decision with comprehensible internal-making processes are necessary for safe reinforcement learning agents into into high stakesstakesake problem. in on that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description. in of proposes a quasi-symbolic agent as a secondary agent and and can generalably to\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:33,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 156, training loss: 2.6774098873138428\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:36,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 157, training loss: 2.5770316123962402\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 158, training loss: 2.5926551818847656\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:43,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 159, training loss: 3.095242977142334\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 160, training loss: 2.3176350593566895\n","epoch 6, prediction loss: 2.293417453765869\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this e discusses a e userto-end e-health system with for includes molecular and electromagnetic wireless communications betweenThe-body and are considered via a generic-assisted diffusion-based molecular communication system. while aomachransmissionters and receivers molecules.off relay node is be improve the link andThe proposed model includes a-body and off-body communications. which a time of molecules schemes. different symbol intervals. each communication type.Theomachines/ as relay nodes. which nearly free and molecular. proposed is includes a2out-off-body communications communications. aways. on communication. the system-health system.',\n"," ' the the accuracy discusses the results to thewise linear continuous p1 lagrange elements to approximate the elliptic oper.The accuracy of different approximations in time will investigated. the reference sol.The of the solution are the reference-level weighted difference scheme are estimated. fig.. accuracy is to investigate the accuracy of the threelevellevel difference scheme. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm.gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid',\n"," ' the the text discusses the definitionence of doubleb-algebroid structures on d double lie algebroid and horizontal or vertical differentials on two of the threeil algebras and a well as ger gerstenhaber bracket on the th we also discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras.ar.....,,.......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:51,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 161, training loss: 2.613839626312256\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 162, training loss: 2.2902300357818604\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:58,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 163, training loss: 2.093997001647949\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 6, batch 164, training loss: 2.313732862472534\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:05,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.6052710966630417\n","epoch {}'s average verification loss: {} 2.8452582731842995\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [1:11:41<30:36, 612.29s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 0, training loss: 2.907604217529297\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.33s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 1, training loss: 3.200134515762329\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:06,  3.41s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 2, training loss: 2.8754467964172363\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.44s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 3, training loss: 2.92446231842041\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:13,  3.46s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 4, training loss: 2.1726911067962646\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.47s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 5, training loss: 2.2495322227478027\n","epoch 7, prediction loss: 2.7740609645843506\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the differenceauchy problem method is used to solving solution solving solvingolving. the on the auxiliary pseudo-time evolutionary problem.. a priori estimates are be obtained for solve numer problem. the the prior implicit two-level euler scheme. used.. difference scheme is unconditionally stable with the initial dat. applying these estimates recursively we the validity of the difference is proven.im....,,,,,,,,,,,,..........ab,..,ab,,..ab,,ab,.',\n"," ' the the boundary discusses the boundarydimensional haddorffme on the to the the boundary boundary local time of the.The section also the naotoaka kajino for the comments on the proof. lema.............ad...........................................',\n"," ' in in text discusses a proof of the theorem stating the themma. le the. show the theoremollary. proof of that that the text u u\" is unounded. and the proof involves based by using the arguments. in the proof of theorem theorem........,,,,,,,,,,adj,ivalentadj,ivalentivalentadj..ababivalentivalent...abababab..ababab..ab..abababababababababababababab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:21,  3.85s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 6, training loss: 2.970034122467041\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.69s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 7, training loss: 2.496678352355957\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 8, training loss: 2.552245616912842\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 9, training loss: 2.4120185375213623\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 10, training loss: 2.240849018096924\n","epoch 7, prediction loss: 3.3402185440063477\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in study study in this paper is more 70 gigabytes of real traces traces from am campus of amirkabir university of technology. which of more and tcp link.Theows are identified using n n sourcesource dpi tool n nd.. which the classes of applications from for more 50 gigabytes of data. including more.,000,.The percent of these flows were used for training and while the rest are test datThe dataset includes 90 total of applications classes and including more classes of more than than dataset also a imbalance feature with more 83 percent of the dataset consisting of 4 cl.dpI, the',\n"," ' the the datasetsd face are used to evaluate the face recognition algorithm proposed thegc vbosphorus and and the-3de. the proposedgc dataset is 5 with 5 sets expressions and and the bosphorus dataset includes samples of six prototypic expressions.The b was performanceing accuracy and accuracy were evaluated using and that accuracy for thegc subjects to the samples andThe robustors were inabor wavelets and the the scale, for each recognition..The results was a accuracy rates for the b al and the samples. with aness for the-neutral samples. probes.Theisons results was the algorithms is also. showing',\n"," ' the the surface discusses the relation of the in a presence of the diffusion flows. focusing the theore 2. for for the process of flow. well as......,,,,,,,antingagingad,,adivalentivalent,..........aware..........ab,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 11, training loss: 2.3337433338165283\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 12, training loss: 2.4210457801818848\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 13, training loss: 2.569831132888794\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 14, training loss: 2.480353355407715\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 15, training loss: 2.1029326915740967\n","epoch 7, prediction loss: 2.4470832347869873\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke discusses the impact of detection detection of represent the detection eff of the ke mission forto grid is created into 100,000 regions in period and radius spac and for region is divided in in log space for period and radius spac all each are assigned m based on the order. for probability order is are the for detecting multipleoplanets within each detection within. probability described repeated for each 10 in the detection order grids. to probability efficiency maps for the effects of limbity and limb the new function for account mis mis transits within topreating between made to determine the probabilities for different detection order. probabilities are created using higher multipl',\n"," ' the the ke discusses the impact for incompleteness due ke planet occurrence rates due to transit multiplicity in. ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics affecting affect the radius and period distributions of each detection ord. text rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog. results model includes consistent with the studies but now includes an improved estimate of the multiplicity distribut. from average discusses',\n"," ' the the influence discusses a results test of the homogenized model of a perforated plate of the reissner-mindlin typ.The results is to compare responses responses of the homogenized model model with the of the associated 3d elastic structure withTheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.The deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat modelThe influence of the compliance on the loss in the waveguide is discussed.The influence']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:58,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 16, training loss: 2.806976556777954\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 17, training loss: 2.9642250537872314\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 18, training loss: 2.2499454021453857\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:09,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 19, training loss: 2.3246541023254395\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 20, training loss: 2.7270655632019043\n","epoch 7, prediction loss: 2.87434720993042\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this context of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play crucial building the-nano-medical applications. in paper presents the e-to-end communication link consisting electromagnetic electromagnetic and molecular communication. based closed-form expression for presented for the e error probability ( the e system system.based optimization method is formulated with minimize the bit error rate of the the optimal symbol duration for the time from. numerical proposed is solved by an iterative algorithm based on the bisection met.umerical results show that the proposed method ob ob',\n"," ' the the impact discusses thely interacting dark matter ( interactions their interactions with focusing are be motivated from various detection indirect detection experiments.The u physics extensions of standard standard model ( sm) and been proposed to address the matter candidates d) candidates or whose as uly interactingacting neutral (ons ( wimps)  detection experiments have shrunk the parameter space of the models where neutralimps to with the visible world viaThe constrained of sm particles sm model particles are encaps in the lagrangian approach. where the of the dimensional effective operators constructedThestrained on these higher are discussed from various data. estimate the the u models.The sensitivity',\n"," ' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous bay using focusing upon previous bay. extract information about the multiplicit. comple a best replication of the empirical popul multipl. studies have used a steep rise towards smaller radius planets at all periods and a sharp rise with increasing periods to by a gradual decline towe inclusion presented a larger maximization technique to a the distributions for a parameters. with the from previous provided previous bay. we study is that with the with previous studies. with with the case of small radius planets. to detection threshold. usingorously treating completeness mapping and a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 21, training loss: 2.5420596599578857\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 22, training loss: 2.3466646671295166\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 23, training loss: 2.32485294342041\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 24, training loss: 2.5574567317962646\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:30,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 25, training loss: 2.328422784805298\n","epoch 7, prediction loss: 2.717808961868286\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in isisms are on the category of for and networks by for andfulerryerson.Theisms preserve the context are the-fululkerson flows onTheflows on networks network is defined by a inequalities.Theflow is defined to minflowichai.perner showed original on that min ranks can satisfy hall s condition are to min naturalperne poset. and har introduced hall s matching cond by prove rot. s conjecture. leading the category matching condition. a normalized of the normalized flow property. category flo is with networksyclic vertex-weighted networks. and morphisms preserving these morphisms preserving',\n"," ' the the effects discusses the effects of mutual inclination on the k recovery forThe study recovery study was not account for mutual multiplicity planet. thus did not account mutual incl. however planets were injected with a impact parameters from study the effects parameters mutual inclination. detection eff.The artificial was at systems impact in impact parameters for recovered planet system with known planet and. mutual inclinations can cause certain planets to ge avoid transit compleometrically comple.......,........',\n"," ' reinforcement reinforcementactionforcement learning ( have agents to learn skills and strategies to complex tasks without detailed instructions or expensive training examples to algorithms can however of performing as humans do can called as a for the complex intelligence intelligence. to advances in deep reinforcement learning suggest that neural networks are natural suitedsuited for reinforcement tasks. to develop the useability of reinforcement learning into it need of explainable and networks-based reinforcement is crucial. here method method to to derive a secondary comprehensible agent from a neural network-based reinforcement learning agent. whose simple rule. decision-making.pirical evaluation of that for the a comprehens and comprehens agent using a method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 26, training loss: 2.571080446243286\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:38,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 27, training loss: 2.617249011993408\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 28, training loss: 2.6006176471710205\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:45,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 29, training loss: 2.472912549972534\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 30, training loss: 2.1625638008117676\n","epoch 7, prediction loss: 2.4151933193206787\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses the lie algebra of type an, whichoted sl sln+ is which to the graphs.. text discusses the all n-colored edge in the crystal graph. also discusses the the decomposition of the 4 is multiplicity-fre......,,,,,,,,,,,...,...,....,...,,,aware....,,,,',\n"," ' to to primary discusses the applications of thes agents to are able to evaluate a agents from r agents.q agents can evaluate used in specific- specific problems. from for such as state multiple rewards and of state rewards, can be used to evaluate agents-.izing the actual of transitions- can on the like coordinates and velocities can enhance agents accuracy of qs agents.s agents can also multiple matching and value networks. evaluate agents values of. proposed between p brain cortex and pfc) hippocampus and and anterior cingulate cortex ( explored for the. brain discusses that one of of q q cing',\n"," ' fraction fraction paper discusses numerical numerical of fractional power equations in time models with solving applications. as sub, biology or finance finance.in is on the fraction involving fractional power elliptic operators. numerical based the elements. quadlov subspace method.The numerical to solve fractional powerin-space reaction-diffusion equations are analyzed. in the integral and adaptively preconditioned lzos method. accuracy also discusses theimatingations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic operator.. is with a experiments. the results. the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 31, training loss: 2.3661317825317383\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 32, training loss: 2.392388105392456\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:00,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 33, training loss: 2.8818211555480957\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 34, training loss: 2.610908031463623\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 35, training loss: 2.503218173980713\n","epoch 7, prediction loss: 2.6593093872070312\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the accuracy discusses the results to thewise linear continuous p1 lagrange elements to approximate the elliptic oper.The accuracy of different approximations in time will investigated. the reference sol.The of the solution are the reference-level weighted difference scheme are estimated. fig.. accuracy is to investigate the accuracy of the threelevellevel difference scheme. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm.gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid',\n"," ' in in first discusses the thestation fractional power elliptic operator equations numerically. using equivalent local nonstationary initial value pseudo-parabolic problem.The such were the implicit backward and symmetrical euler method. while the paper introduces to the fourth-parameter family of three-level finite difference schemes forThe fourth-order approximation scheme is developed by optimal optimal weight paramizationThe resultsical analysis and are supplemented by extensive computational experiments......,,,.....',\n"," ' the theac s2obs- are used models that are the a textac equations with a externalic function.. create a setton with with a information. structures are called in the context of the equations. are be used to various applications models. the of theolds.x........igenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 36, training loss: 1.9824461936950684\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 37, training loss: 2.5322136878967285\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 38, training loss: 2.239314079284668\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 39, training loss: 2.85671329498291\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:25,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 40, training loss: 2.9956436157226562\n","epoch 7, prediction loss: 2.9340715408325195\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a simplified of theorem a, showing that variation of the theorem of in theorem a. the being between the proofs proofs, they. proof is provided. reader.The proof is a a common ingredient of both proofs. and the cases. and providing a partition. satisfy the desired result.The section to a proof of a specific 2-sparse family fqj such the proof is focuses the model on - onymund operator.. the cal version. text is with showing the similarmma to showing the proof. theorem a............',\n"," ' this this e discusses a e userto-end e-health system with for includes molecular and electromagnetic wireless communications.The-body and are considered via a generic-assisted diffusion-based molecular communication system. while aomachransmissionters in receivers molecules.off relay node is be improve the link andThe proposed model includes a-body and off-body communications. which a time of molecules schemes. different symbol intervals. each communication type.Theomachines/ as relay nodes. which nearly free and molecular. proposed is includes a2out-off-body communications communications. aways. on communication. the system-health system.',\n"," ' the the j discusses the j of generalizations of spontaneousar- andensor theories where sts)based the j frame where where where the scalar field replaced with other fields and couplings can depend on derivative. specifically study came from the that spontaneous tensoriz where where are most naturally defined in the canonical frame where however are be applied to any generalization of on a conformal scaling of the metric in the matter action by first focuses vector the scalar field a vector field the-tensor theories obtained vector to the-based spontaneous scalarization arezing the j of interesting time derivative terms in no renders orderorder equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 41, training loss: 2.8860971927642822\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:33,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 42, training loss: 2.4054183959960938\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 43, training loss: 1.942084550857544\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 44, training loss: 2.3248939514160156\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 45, training loss: 2.8161370754241943\n","epoch 7, prediction loss: 2.398592233657837\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the tree discusses the tree-matal amplitude and d3-brane couplings in the on the thelevellevel s-matrix elements of one ramond-ramond and three open strings. imposing symmetry symmetry the tree-level s-matrix elements of one kb-ramond and three open string.. also discusses a effective invariant form of the d3-brane effective action containing derivative gauge fields with derivative corrections. from one-loop level four-point amplitud. text with derivative corrections at found from expansion the nonlinear sl invariant structures. the more gauge fields.x..',\n"," ' in inrones are getting being in various fields fields. the such google, facebook, amaz amaz. their own drone technology.dron are used in various journalism so obtain videos of areas toto-access areas.dcopter are which quad of quad that four rotorors are are one used in and the spinors working clockwise and two other two spin counter-clockwise. balance that.dron are be autonomously based on a-entered program without and without with a resolutionresolution video. image processing. computer vision techniques. in, such of when a signals or satellite-captured satellite maps are not. in research',\n"," ' the the text discusses the properties for on the priori estimates for the a. based text provides convergence convergence of the unfolded function. the2.i to the convergenceation of the limit vibro-acoustic problem. a formal approach. the sequences constructed with the convergence res.based............ad.........,,..,,,...,,....,,aware....,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:48,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 46, training loss: 2.243518114089966\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 47, training loss: 2.470370054244995\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:55,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 48, training loss: 2.645697832107544\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 49, training loss: 2.3319578170776367\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:02,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 50, training loss: 2.122988700866699\n","epoch 7, prediction loss: 2.828357696533203\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed.The results was tested with a sampled datasets augmented datasets. and compared results show that our proposed approach outperforms thenn. terms of accuracy, recall, and f.........dd..dd....ababab............',\n"," ' the the acoustic discusses the method analysis for the the acoustic acoustic pressure and the displacements and and rotation in a limit lay.The result is based for understanding understanding- and equations of vib vibroacoustic problem imposedThe convergenceymptotic analysis is based using the unfolding method. which developed for the seminal paper by elaborated elaborated further thin structures inThex........gg,  ,.,,..,,,,..,,,,,,,,,,,',\n"," ' the the q discusses a new for the invisible qcd axion model without domain wall. with the heavy heavy heavy are present.The is is developed in the contextxiv:19012..... the 2018,2018.............gergngn........,fbfbfbfb..,...fbfb,aware.,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 51, training loss: 2.131300210952759\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 52, training loss: 1.9623472690582275\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 53, training loss: 2.2834677696228027\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:17,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 54, training loss: 2.3150100708007812\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 55, training loss: 2.641619920730591\n","epoch 7, prediction loss: 3.1364617347717285\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the comb discusses the comb of a7 crystals weight elements from decom the7 highest weight elements. a decom computation..The proofposition into e7 crystals is multiplicity freefree is discussed to the comb that to the one of proposition conjecture inThe proofinatorial r-matrix must used to its ability to map classical components to classical components. leading the weights are k k are k. computed. a function.The is is as a proof towards proving a conjecture regarding proving a construction of a7crysta value. the certain way.....            ',\n"," ' with with traffic is a for the ever amount that in withifying the patterns and applicationsifying applications is two tasks in with traffic tracingifications ( nt)) have classify anomalies in classify applications for however they methods have shown. port on ports in lack issues. their. ingorithms have these classification classification have promise in they methods for however thebalanced datasets is networks-scale networks datasets a challenging for deep. f.. inmentation is have machine learning have such as artificial artificial data for are address these imbalance issues, novel approachmentation method is k dataensity andimation ( kde)and lestestTerm memory ( lst',\n"," ' in in text discusses the classification of irregular with by theodge theory. specifically by the with irregular3 type. product modental part.. are the related the group of these surfaces and their conditions answers to the questions. certain conditions. text also the the classification of these surfaces is not not. that the state state of the art. also on the-quotients surfaces and show mod group theoretical dat. and well as those moduli spac. results obtained can used to prove that t- mumford-tate conjectures for these surfaces. text also the support of inspiration. provide a overview of the current state']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 56, training loss: 2.972310781478882\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 57, training loss: 2.5598909854888916\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 58, training loss: 2.7158327102661133\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:36,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 59, training loss: 2.286759853363037\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 60, training loss: 2.8004963397979736\n","epoch 7, prediction loss: 2.521749973297119\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' image image use discusses with the algorithm developed by us authors is a best candidate for creating a bigger image from small images. and theofcv can results to fit two images with better accuracy.after algorithm also the theofcv can results would be imp for the mapping because to the..he algorithm concludes the the algorithm developed short of achieving goal of create the parking lot. and the in the stitching and the ar-drone 0.0.0 also that the different version of the ar with even different camera with a 1080p camera. this image., the issues with the ar were to the results stitching..The text',\n"," ' the the text discusses a detailed overview of theson sld. a on the only and in the text. also as a reference reference for the the concepts in thei geometryometry. the problems.x........igenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' hom hom text discusses the homogenization of thero-acoustic transmission on perforated plates.The is a the plate by an interface on can transmission conditions by homogenization of a problem describing vibroacoustic fluid-structure interactions in a transmission layer inThe homissner-mindlin theory of plates is adopted for periodic perforations designed arbitrary cylindrical holes withThe homogenized model of thero-oustic transmission is obtained using the-scale asymptotic analysis with respect to the layer thickness and which to the plate thickness and toforation pericityThe nonlocal, implicit transmission conditions involve a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 61, training loss: 2.334829330444336\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 62, training loss: 2.0902669429779053\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:50,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 63, training loss: 2.4648077487945557\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 64, training loss: 2.8929479122161865\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:57,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 65, training loss: 2.205341100692749\n","epoch 7, prediction loss: 2.3473622798919678\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the we on thet and algebra and the contextil algebra. 16 55.2........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,,ivalentivalentivalentawareawareivalentawareaware..awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalent,,ivalentivalentivalent',\n"," ' in in text discusses a bounds for cal operators and harmonic analys.Theization and sparseness are two ingredients in make sparse bounds especially tools quantitative norm inequ. in text on sparse bounds for too andars bounds for cal on- onymund operators are calizations domination principles are discussed. text show a proof proof on means the main hypot in the them the weighted weightedq proper proper  result simpl the need for work with the grand maximal truncated operator mt which it sparse more efficient. text also organized as five. the proof and the theorem theorem and the and and and and. t1-type result and and examples',\n"," ' in in e discusses with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communication is conducted.The closed-form expression for the e error probability of concatenation of molecular two channels was derived.The optimization problem was at minimize the e error probability was conc system was formulated to determine the symbol durations for both molecular of communication.The reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication......,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 66, training loss: 2.315398693084717\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:05,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 67, training loss: 2.3866028785705566\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 68, training loss: 3.6530842781066895\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 69, training loss: 2.6023895740509033\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 70, training loss: 2.3231146335601807\n","epoch 7, prediction loss: 2.8751003742218018\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the proposed space method the filter is based on the surface normal methodThe proposed feature proposedises thelets overlap and redundancy in the images. is the the discrete fourier transform of the resampled gabor wavelet g the wave and orientations.o the frequency component set. proposedization for the scale and are computed into a block matrix. the analysis.x....,,,,,,,,,,,..............,,,.',\n"," ' in in crystal result of in this section is the multiplicity freereeness of the decom. this labeling labeling convent. which well by section 2. proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the  using the and adding loops to everyices in and adding the composition graph g, we is shown that the crystal b is type e. a multipl rule. the multipl m of x x. proofposition is multipl proven by amma. leabeling the fundamental weight. and leading in a multiplicity',\n"," ' previous previous distribution discusses the resultsolation of previous populations parameters to longer periods andwe discusses the the results of not differ significantly from previous studies. discusses consistent with previous findings.. arises found between previousman-mackey et study to uses the a specific functional form for theolation to using aussian process regression. determine the functions.man-mackey et approach also a results pipeline in for does reports the highest signal to to- noiseise candidate around each star. results also discusses the detection order can bias the. leading leadingcounting small planets and long periods. text used in bur et al.uses used by the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 71, training loss: 2.2311971187591553\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 72, training loss: 2.6809675693511963\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:27,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 73, training loss: 2.328738212585449\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 74, training loss: 2.2859017848968506\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:34,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 75, training loss: 2.642148733139038\n","epoch 7, prediction loss: 2.4859166145324707\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text results the model is three datasets datasets shows that the method of sampling in able in handling thebalanced datasets.The results are to precision1 measure, precision and and recall measureThe accuracy is performance on compared with sampling in and the in precision and in to higher false predictions predictions and overall accuracy of the model is also than sampling in with a improvement in precision and recall, and confusion accuracy. model also that accuracyiz accuracy accuracy decrease in false negative. to the..........dddddddddddddddddddd,,',\n"," ' the the text discusses the results related to the theory dir subsetets and andichlet forms and andotone class argument, andity and and domain,, and eigenfunction, and, and finini theorem theorem.The words include the thatity, the dirichlet form, showing convergence of themma 1. proof. to le results. section also discusses the sectionification theorem. the principaln t. l. the textiteness of the*.................',\n"," ' in in surface discusses the concept of uniformly regular manifolds and and the importance properties. for the the diffusion flows. will willmore flow.The structuresolds are consideredodesically complete, of positive positive injectivity radius and are are allant derivatives of the curvature tensor arelyolds are boundary are uniformly regular. and well the surfacesolds considered in. text. textally uniformly a defined tens compactly supported tensor fields is the base base manifold is identifying it as zero outside their original dom is used. text also discusses the bcs and bcs. in a similar manner. am.....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 76, training loss: 3.0362515449523926\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:42,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 77, training loss: 2.4303133487701416\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:46,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 78, training loss: 2.76750111579895\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 79, training loss: 3.2926156520843506\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:53,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 80, training loss: 2.4423828125\n","epoch 7, prediction loss: 3.2872891426086426\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using using study discusses on the multipl effects multipl the parameters parameters provided theoseismic data fromwe study of new updated allows the radius measurements and, address thelier systems in the ga data we we values are tested against the ke dr25 cat. to of also from the curves and thus periods need on the data keks.. to positive are removed using the thes. allowing are planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in with a for on the and period cuts. when with multiple positive are artificially removed to accuracy order accuracy with detection detection multiplicity we in 7',\n"," ' the the t discusses the tford-tate and t conjectures for surfaces surfaces mentioned and on the cycles-- ofThe textford-tate group is v is denoted by g, g, is the using the to theic cycles and motiv.The text also a of to theelian motives and theodge m. and that existenceelian nature of the motiv. textford-tate group is proven for the certain fib. the alese variety. and a to the thodge conjecture. the class...........',\n"," ' 3 3acial expressions isness is 3d face recognition is a key issue topic in to the need of by the-rigid objects expressions.3isting approaches for such the iterative closest point algorithm and can become to variations minima and, approach to capturing a range of facial expressions for each subject and storing them in the subjects in face. but this are are capturing and storage.3 approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to address theness against variations expressions. in research have focused the to the multiple normals hist point']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:57,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 81, training loss: 2.539825677871704\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:00,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 82, training loss: 2.6410295963287354\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 83, training loss: 3.042307138442993\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 84, training loss: 2.237868547439575\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 85, training loss: 2.4297120571136475\n","epoch 7, prediction loss: 3.133815288543701\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the aim project we to come an image processing algorithm that the the university of bridgeport parking lot using using two images into with a stable device like a good camera. such the ar-drone. along main camera of the drone will images imagesapped images which which can then into the algorithm that. alongcv and boofcv are were used to developing processing. and thecv being java interface being used primary component ofboofcv is a-level image processing capabilities. bo low example processing algorithm.. whiching images the open goal research. stitching refers combining a 2d geometric transform which minimize two images into and a like',\n"," ' in in index discusses theasipinear inequalities with aitycommity. withizing the index j sub acritical. the certain inequality and satisfied. critical in equality holds in case certain case.x.....,,,.ivalentivalent,,,,ivalent,,,ivalent,,,,,,,,,,,,,,,,,ivalentivalentivalentivalentivalent,ivalentivalent,ivalentivalentivalentivalentivalent,,,...,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the keism we in this study utilizes applied to derive the occurrence rate parameters for planets orbiting gk dwar stars.  from the final ke data dr25 and including planet radius measurements from theks and ga and, and corrected detection eff for multiple-planet systems are used.  resulting includes on previous poisson process likelihood function used includes a modifiedesian framework to using anm. resulting are that values for the occurrence of including a in the best fitfit model occurring at p times of novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 86, training loss: 2.543208122253418\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 87, training loss: 2.5058679580688477\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 88, training loss: 2.510694980621338\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 89, training loss: 2.5781798362731934\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:29,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 90, training loss: 2.4258453845977783\n","epoch 7, prediction loss: 2.6356260776519775\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using using importance discusses a the in the measurement into a bayesian hierarchical model. occurrence for parameters. order context generation of occurrence fitt methodsThe importanceicity parameters derived here be in determining an eta earth measuremen the importance of neighboring planets could the long of an earth analog is multiple multiple sy may important. importance also that a injection experiments to determine the eff across understanding the effects. detection eff.ining data from missions will it as ke and t tess will will will essential to understanding occurrence measure. as for the detection effiencies across method described here to incorporate these selection effects into maintaining a uniform distribution distribut. method',\n"," ' the the text presents the vib of modelling and vibration reduction in design design of the in the industry civil engineering.The considers on the the wave propagation through elasticating perforated plates. where the related respect modelling of to the geometricometrical ofThe text presents a method to theogenization to derive non-local vibro-acoustic transmission conditions for the per designed with acoustic inviscid fluid.The method involves us modelling reduction modelling modelling of takes information details about need need of disc discretization at text involves a new approach for modelling theroporous structures which providesates the proposedogenization re using direct numerical simulations.',\n"," ' the the main algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the heant of the heian matrix is usedized.sur determin is images from using blending the last image for performance and level detail detail and rendering in a final merging.The algorithm image image is as input input for the algorithm. the analysis. the drone moves forward.The.......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 91, training loss: 2.4914727210998535\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:37,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 92, training loss: 2.613028049468994\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 93, training loss: 2.4176933765411377\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:44,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 94, training loss: 3.0194733142852783\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:48,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 95, training loss: 2.513915538787842\n","epoch 7, prediction loss: 2.428367853164673\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this text section the in the images images. to the. can be the..The text used in to address these by improve that transitions between images images.The, ity details details can occur occur the quality.Theosing the best appropriate algorithm for this problem is a. to the issues.Theio algorithm.........addadd..addaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenaddaddadd.adenaddaden..ab.abababababababababababababababababab',\n"," ' the the text. the improved version of the pointwise sparse domination principle established by the first author in allows allows us obtaining singular singular assumptions on for a singular integral operator to admit a sparse domin.......,...,,,,,,,,,.,......................,,.......aware,,,,,,,,',\n"," ' the thefaces diffusion and willmore flows are considered for uniformlyurfaces parameterized over a uniformly regular reference manifold. uniform tubular neighborhood withThe the are in a fourth-order quasilinear parabolic equation with non singular structures. the contextlinear terms satisfying............,,........,......able....,...,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 96, training loss: 2.2265617847442627\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 97, training loss: 2.785060405731201\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [05:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 98, training loss: 2.25488018989563\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:03,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 99, training loss: 2.9453611373901367\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:06,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 100, training loss: 2.484231472015381\n","epoch 7, prediction loss: 2.5983095169067383\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in goal aims to create the quad to camera to take images images from a parking parking lot and blend them to create a large image image. the entire parking. to approaches were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. to field was images images during certain points intervals during create the merging of this field test, we images lot was divided into a 4x4 matrix matrix better the drone. movement.. algorithm was using images at different and then them images together each column, and then merging them columns together after',\n"," ' feature featureised features descriptors are used to the nasal region using the features in spherical.Theised are theabor wavelets filters are a featuresors. and to a dimensionality and reduced redundancy and and improvedabilistic feature selection. reduce the to facial expressions. maintaining theinative features.The landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.The sphericalors are the use of the spherical on the nasal surface. when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........',\n"," ' well well well discusses the well-posedness properties for the wellard - theorem the on the workorems on the. to the regular surfaces andThe text involves from proofs as in the previous section.x.........,,,,,adad,.ivalentivalent..ivalent..awareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:11,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 101, training loss: 2.3424010276794434\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 102, training loss: 2.4085378646850586\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:18,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 103, training loss: 2.0358242988586426\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 104, training loss: 2.5629141330718994\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:24,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 105, training loss: 2.235588788986206\n","epoch 7, prediction loss: 2.667374610900879\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using usinginstein of are transit transit study have to properties of the populations fromusing key function is utilized for determining bayesian theorem theorem and extract parameters parameters. using method distribution is assumed as independent independent power lawlaw distributions in period and rad. using distribution that a single population population is made assuming assuming the distribution of this assumption is examined.order distribution focuses on multiple systems with examineszes the effects effects introduced the and multipl. distribution used to on previous studies to utilizing planets by detection order. results show insight on the factors detection order. show distribution parameters functions this introduced the distribution distribution fun. to this. statistics are discussed for to',\n"," ' double double text discusses theinc s lie bundles and a are the to the lie algebroids. text is been in applications with other fields systems., it text discusses the splitting of double vector bundles and-....,,,,,,,,,,,ivalentaware,,awareawareivalent,,,,',\n"," ' deep deep learning ( potential to high stakesstakes decision problemsmaking is still challenging for it influence may uncertain. extensive test. whileing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents, provide their performance-making.. however these studies have focused on feedability of feedforward deep learning agents we studies explored interpret issue of more learning. well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is a agents. in potential approach is to provide the in reinforcement learning agents.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:29,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 106, training loss: 2.4422361850738525\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:32,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 107, training loss: 2.7218127250671387\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 108, training loss: 1.9869465827941895\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:39,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 109, training loss: 2.6952083110809326\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 110, training loss: 2.2992031574249268\n","epoch 7, prediction loss: 2.587026357650757\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the current discusses the impact of the matter ( d)ther density using using the thermally averaged andaged annihilation annihilation cross- forThe current have the cross-averaged annihilation cross- for f operators candidates including compare the results to compute the cos density constraint direct are such as dermil-abs, hess are are sensitive to the types candidates.ihilation cross- are various types candidates are computed. various with le leptons and photons. results also discusses the on theider experiments to these operators for their on theh.. text discusses on the detection experiments such d particleselectron scattering delastic',\n"," ' the the textogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated solid structure. model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation. model of are the the referenceogenized and the models are constructed in responses of the homogenized model is performed in two steps. comparing responses of acousticlections obtained by direct numerical simulations. firstogenized model andifies the text by to the complexity of the finite element mesh complexity increasing number of holesforating holes. reference are implemented',\n"," ' sn sn text discusses that super is normalized normalized matching property. which that sn is indeed sperne. result achieved by the induction on. the normalized case is trivia.. the baseive step is the permutations from the copies. sn. the collapsing the n of the new network is constructed. satisfy the normalized matching cond. which to the conclusion that sn is indeed sperner. well satisfies normalized normalized flow property..................']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:47,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 111, training loss: 2.3267531394958496\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 112, training loss: 2.248379945755005\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:54,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 113, training loss: 2.8529906272888184\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:58,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 114, training loss: 2.603940010070801\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:01,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 115, training loss: 2.6088943481445312\n","epoch 7, prediction loss: 2.266627788543701\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' tele tele text discusses the importance of time duration ratio ( emedicine communications for e communication delivery. theomachin.The text symbol slot partitioning ( found by the the user to-end symbol error rate (The optimization algorithm is formulated for find the best performance in e between The optimization involves solving the symbol slot interval three of in types of communication links.The achieve the quasiconvex optimization problem, a quection optimization is formulated. on amc parameters and symbolr of the. The optimization is a in the ec transmission side. does of and robust. low complexity complexity........',\n"," ' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. The novel five-step algorithm is presented. with with aly of the nose tip location segmenting and aligning the face and and thenpping the nasal region.The very anding algorithm is seven keypoints on the nasal reg.The genetic algorithm-based feature selector is the patches and curves over different facial expressions. The algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing.....',\n"," ' double doubletic models have transit probability have double transit systems have presented establishedknown for on the inclination and, larger models models for larger multiplicity systems is more difficult. requires semi-analytic models. to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated for to address the distribution population of the non for transit transit probability is some specific semi-major axis value is created. this with other for the geometric of otheroplanet period. to address this related to the order, the against a non-uniform method method is used to the period distributions to such']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.89s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 116, training loss: 2.679201126098633\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:09,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 117, training loss: 2.729844808578491\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:13,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 118, training loss: 2.4607386589050293\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:16,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 119, training loss: 2.331554651260376\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:20,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 120, training loss: 2.515646457672119\n","epoch 7, prediction loss: 2.7619307041168213\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' christ christ christ discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars.The doing the light light curves with the standard detection pip, the recovery fraction can be assessed. producing a probability function based on transit mes.to-noise ratios. mes))  christ of detection order on recover is discussed. with the order defined by the variable m. the christ from split into injection with and after the days. and well 200 time the distributions begin significantly. is made on the with 2 or discovered......g...ggg..',\n"," ' ch chorem discusses theic surfaces3 surfaces of ch ch to chow motives of surfaces.1 also a proofposition of theow motives of surfacesic surfaces into aic and transcendental components. and by a comput. computations.The sectionogenical decomposition of theelian varieties with group action is also. with to a proof of the specific example.The section discusses with a discussion on the specific example in a product of singular algebraic k3 partner of the minimal between theers surfaces. ch resolutions. showing the importanceogenism between theental surfaces of............',\n"," ' stars stars lack discusses the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity stars systems.The using these function to we expected suggests that 0 best empirical multiplicity of be increased by a function of selection effect. study also discusses the implications of this function to the the for the multipl and period. the the is the impact of this model of multiplicity in our solar system for theability. highlighting that lack for a studies. support such claims...........ab.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:24,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 121, training loss: 2.789172410964966\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:28,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 122, training loss: 2.846261739730835\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:31,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 123, training loss: 2.521803617477417\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:35,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 124, training loss: 2.244877338409424\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:38,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 125, training loss: 1.8663946390151978\n","epoch 7, prediction loss: 3.00714373588562\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses the concept of a - andbgorithmbrir. with the single of. and is of a electron structure of a electron of the individual bundles.. sectionorphic of the structuregebroid are determined. with the importance. the the behavior structure of the latt bundle.x..........igenigenigenigenigen,,,,,,,',\n"," \" quasi quasi lunar discusses the inter principles of quasi-symbolic agents qs)agents and quasi the inter with the learning ( r)agents.qiments conducted conducted to evaluate the performance of qs agents in solving lunar lunar-lander problem compared to the agents.q r agents, qs agents do not work al. do their behaviors and value networks by the agents' behaviors during train.q matching and in the of the vectors observed and the value network stores the induced by observed transitions.qs agents utilize the states, utilize their to reach them. the matching network. the r agent. identifying training time of training of\",\n"," ' the the en model ( the context is the en. modeling into state vector and action a inputs and the the next state.The this text, the network layer of a nodes is used to the text network.The is shown using the squared error regression each episode of random learning.. a ensemble learning rate of 0.0..........adddddddddddddddddddddddddddddddddadenadenadenaddadenaden,aware..adenaden.adenawareadenadenadenadenawareawareawarebh']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:43,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 126, training loss: 2.3146862983703613\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:46,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 127, training loss: 2.350698947906494\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:50,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 128, training loss: 2.4309654235839844\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:53,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 129, training loss: 2.132035970687866\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:56,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 130, training loss: 2.828629493713379\n","epoch 7, prediction loss: 3.4030280113220215\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses theooninivityverseal in............,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the feature selection step involves the engineeringgorithm ( ga) is to select thoseets of curves vectors extracted curves and patches patches extracted are more against facial expression.The modified vector is used to select select those most robust curves from remove the features.The varying the value vector b the subs and patches can selected or omitted based depending reducing the rates. reducing the selection. the appro. fisher fisher analysis analysis..- algorithmgorithm is to in the non dimensionaldimensional binary high-convex optimization process. with a high nsga-ii. elitism over individuals individuals healthy individuals..- feature assignments for the are are explained in section',\n"," ' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order in however others have focused the to as convesian neural networks in convabilistic graphical models. semi-supervised learning in however in been been done in the neural neural networks to however,stm networks, to address data data. and neural flow data. in main discusses a approachmentation approach for generating time data in network traffic trace g tcp the contribution that in the results used. generating cases and numer data aug. used as recurrent aug, andimation and kd) and used to generating data data. network network-']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:01,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 131, training loss: 2.4672794342041016\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:04,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 132, training loss: 2.046102285385132\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 133, training loss: 2.960869312286377\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:11,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 134, training loss: 2.7974419593811035\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 135, training loss: 2.7326908111572266\n","epoch 7, prediction loss: 2.7432243824005127\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a examples of the admitting admit thewise sparse domin.The text discusses the the operators operators are known known. but the unified approach simplified approach to provided to on theoremore 1. its variant. results are from from previous results. consideringi l and sheldy ombrosi. and the improvements provided in section..4 text text is the the text admits of weak type. to theorem 1. and a specific refined result with by section slightly case. by.....,,,,',\n"," ' dynam dynam cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking. theories context.The is the possibility wall problem and theion models higon models and suggests a to as the inflation and the warides-shafq and and the witten effect. minimal model is proposed where the breaking of peq symmetry is arises at a newiral confining force. leading the domain wall problem. model of instantons interference effects explored to address the domain wall problem. introducing the peq symmetry. the.. model also discusses the issue of thebaryons and which heavy',\n"," ' eccentric eccentric eccentric discusses the eccentricity into the model system is enhance the detection efficiency eccentric is the eccentricity models for including the modified gamma distribution used to a beta distribution used including from that significant differences between theity between the and multi-planet systems. the same & mur eccentric., applying with the eccentricities reveals significant in bias is theity occurrence using leading multi-planet systems producing more low eccentricity detections than significance suggest these differences between the empirical ofation of detection eff is crucial for determiningity occurrence measurement. evidence for needed to determine if these populationsity populations exist between the and multi-planet systems.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 136, training loss: 3.023463249206543\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 137, training loss: 2.806389093399048\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:26,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 138, training loss: 2.324709415435791\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:30,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 139, training loss: 2.401749610900879\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:33,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 140, training loss: 2.076199769973755\n","epoch 7, prediction loss: 2.9029645919799805\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the this context of section agentss and is q) and interact with r learning ( r) agents and make models env) agents. learn future actions.qs three are constructed using thetorch, an open-source machine learning toolkit.qx,....,,,,,,,,,,,,.,,.,..,adj.,,,....,,,,,,,,,,,,',\n"," ' in in text discusses the -to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes.The of molecules molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is calculatedimated by sim s rul.The orderpembol interference is ignored. the the of left to future work. error error performance ( is also. the on- and and off-body communication channel. the the of the such the between motion of-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' in in text discusses a results on to the text dirichlet form on the bounded-chitz domain.The using theorem of the closed is a by. text result is the section is that proofhei matsuura theorem. which states that the regular closed of a continuous vers............,,.,,,,..gable,,..ableableableableableableableableableabeabeabeabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 141, training loss: 2.1087534427642822\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:41,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 142, training loss: 2.9700403213500977\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:45,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 143, training loss: 2.54850697517395\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:48,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 144, training loss: 2.474975347518921\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:52,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 145, training loss: 3.121739625930786\n","epoch 7, prediction loss: 3.3905649185180664\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' 25 25 studyaic - involves a method to to measuringson toolds to with involves used with a, a functions.The involves the the equations of a basis. create the. solving the results.x method.,....igenigenigenigen,,,,,,,,',\n"," ' super super sensitivity discusses the sensitivity of the constraints on the matter pair d)- at including on the sensitivity to sensitivity to the momentum of d pair atom and/- electronron scattering. to suppressed of quarks in. is the need of theizing dpto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh) and discusses the need of studying the- to the-2 operators.on text is highlightszes the state effects of d- atom scattering cross dama data. derives the the- production channels at the proposed linear coll ( ilc)  study also the',\n"," ' the the d discusses the symmetry of the electrodynamics theory under theity transformation. considering on the drangian transformations. the the theion and dilaton fields.it is the behaviorance of the equations under equations of motion and energy-momentum tensor under the-duality transformationThe transformationsetries involving transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the symmetry of of theitudes involving the-duality. isves into the implications of the involving equationsitudes under the-duality transformations. focusing the need of the of the-duality']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:56,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 146, training loss: 2.673727035522461\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:00,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 147, training loss: 2.5453686714172363\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:03,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 148, training loss: 2.741133213043213\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:07,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 149, training loss: 2.8250956535339355\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:10,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 150, training loss: 2.351536989212036\n","epoch 7, prediction loss: 2.468583822250366\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the recognition.The algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.Themarksing is on a minima detector operator isative algorithm. remove landmarks landmarks in the nasal region. such as the nasalnasale and sub corners.lieriers are removed using aative methods. remove the selectioning. algorithm is to reduce identify landmarks al such maintaining redundant parts. the face.............',\n"," ' error error error results to that performance of the proposed e toto-end error sy for diff diffusive environment like blood.The channel coding is considered forThe performance probability performance analyzed as on the parameters like including location and and at and and symbol velocity. analyzing the parameters, the performance error probability ( ber) is be improved. trade-off between the conversion and channel rate time also. where the trade value-to-end ber e2e)berert performance when the the energy molecular channel ( dmc) and errorstatic ( ec).. the velocity can the minimum2e berery performance increased increased the',\n"," ' in in text presents a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation.The layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization..The diraging procedure based to a of outer acoustic field with the-layer variables.Theumerical examples illustrate the validityogenization model and accuracy. with the numerical simulations. research on at address the of perforated plates in vibroacoustic trans problems text highlights supported by the grants grants funded']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:15,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 151, training loss: 2.622941732406616\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:18,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 152, training loss: 2.42570161819458\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:22,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 153, training loss: 2.3782870769500732\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:25,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 154, training loss: 2.6354737281799316\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:28,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 155, training loss: 2.435432195663452\n","epoch 7, prediction loss: 2.63688325881958\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text of that to the the augmentation process in a data from classes with less population in the dat is The aug involves aug and convstm layer on generate the pattern of directions and windows windows sizes in the flo function and followed the distribution functions ( pdfs ) of every features using and points points in each feature dom, on the pdfs, and generating points dat dat. the.The the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points.if convolutional recurrent neural network was trained trained on the augmented dat. with a batch architecture. rel normalization lay.',\n"," ' in in order difference-level difference difference scheme are constructed. this paper. they stability condition for the initial the scheme is woted by w,,is to be computed with a symm-level algorithm algorithm. the same accuracy as of main scheme. themmetrical scheme are the with the order accur. suff smooth solutions. conditions for formulated for the symm-level scheme. and that stability with respect to the dat. high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy. the schemes can be constructed to solving conditions w they restrictions are that using.',\n"," ' effective effective effective discusses the effective interactions of darkermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the effectiveally averaged indirect indirect matter pair d) pair annihilation cross-section and the spin-independent d -. le and/or bound electron. and that with the data......,,,,,,,,,,.,,,......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:33,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 156, training loss: 2.3388173580169678\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:36,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 157, training loss: 2.4428462982177734\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 158, training loss: 2.3196682929992676\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:43,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 159, training loss: 2.4248287677764893\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 160, training loss: 2.0905282497406006\n","epoch 7, prediction loss: 2.4664905071258545\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the t discusses the t- mumford-tate conjectures for surfaces s connected components of the gieseker moduli space that contain a product-quotient surf sur.,....,,,,,,,antivalent,,,,......................able.....',\n"," ' in in text discusses the minimal domin1 theoremty singular for which the minimal assumptionsity conditions on the singular t. which the singular holds. is that the proof on the minimal hold similar unknown. discusses are they theorem dini cond can be relaxed to section also the minimal assumptions on t k yielding yield thewise sparse domin. text are in results and le the sectionmma. le. the. to the weak. also with showing that the the bounded extension of the t is to2 to itself if then bounded condition on hold for......,,ad.',\n"," ' in in comb discusses theing the., from the decom of the. the.The using the certain approachinatorial approach approach we section theorem,, proven to provepose the into i0,2-crystals......,,,,,,,,,,,,,...adjadj,....adenadenadjaden..aden,aware.aden']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:51,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 161, training loss: 3.0549490451812744\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:55,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 162, training loss: 2.274021625518799\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:58,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 163, training loss: 2.2268853187561035\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:02,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 7, batch 164, training loss: 2.6084346771240234\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:05,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.515327860369827\n","epoch {}'s average verification loss: {} 2.75440264493227\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [1:21:52<20:23, 611.78s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 0, training loss: 2.6641528606414795\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:04,  4.42s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 1, training loss: 2.261597156524658\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 2, training loss: 2.235318660736084\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:11,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 3, training loss: 2.3847403526306152\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:14,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 4, training loss: 2.638911008834839\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:18,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 5, training loss: 2.4096786975860596\n","epoch 8, prediction loss: 2.9087188243865967\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the theac s2obs- are used models that are the a textac equations with a externalical function.. create a setton. with a information. structures are called in the context of the equations. are be used to various applications models. the, theolds.x........igenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' dynam dynam cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking. theories context.The is the possibility wall problem and theion models higon models and suggests a to as the inflation and the warides-shafq and and the witten effect. minimal model is proposed where the breaking of peq symmetry is arises at a newiral confining force. leading the domain wall problem. model of instantons interference effects explored to address the domain wall problem. introducing the peq symmetry. the.. model also discusses the issue of thebaryons and which heavy',\n"," ' the the accuracy discusses the results on thewise linear continuous p1 lagrange elements to approximate the elliptic oper.The accuracy of different approximations in time will investigated. the reference sol.The of the solution are the reference-level weighted difference scheme are estimated. fig.. accuracy is to investigate the accuracy of the threelevellevel difference scheme. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm.gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:22,  3.93s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 6, training loss: 2.332895278930664\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:26,  3.74s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 7, training loss: 1.9837270975112915\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:29,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 8, training loss: 2.731696605682373\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:33,  3.61s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 9, training loss: 2.270505428314209\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:36,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 10, training loss: 2.283033847808838\n","epoch 8, prediction loss: 2.47096848487854\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in inrones are getting being in various fields fields. the such google, facebook, amaz amaz. their own drone technology.dron are used in various journalism so obtain videos of areas toto-access areas.dcopter are which quad of quad that four rotorors are are one used in and the spinors working clockwise and two other two spin counter-clockwise. balance that.dron are be autonomously based on a-entered program without and without with a resolutionresolution video. image processing. computer vision techniques. in, such of when a signals or satellite-captured satellite maps are not. in research',\n"," ' in in comb discusses theing the., from the decom of the. the.The using the certain approachinatorial approach approach we section theorem,, proven to provepose the into i0,2-crystals......,,,,,,,,,,,,,..adjadj,....adenadenadjaden..aden,aware.',\n"," ' the the text discusses the the homogenized vibroacoustic transmission model derived the text discusses be used for numerical simulation of acoustic waves using the two-scale in. The text is is the to the one considered section text. where the zero neumann condition appl a same acoustic fluid and the solid.. textscopic responses are computed. compared in fi. illustrate the model.....,,,,,,,,,,,,,,,,,....,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:41,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 11, training loss: 2.218911647796631\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:44,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 12, training loss: 2.094273805618286\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:48,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 13, training loss: 2.4651193618774414\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:51,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 14, training loss: 2.329742193222046\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:55,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 15, training loss: 2.314953088760376\n","epoch 8, prediction loss: 2.1209256649017334\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' spontaneous spontaneousalar-tensor theories have commonly alternatives to general relativity and have had a large impact on cosmology.sc theories commonly variousar degrees of freedom in addition to the usual metric of general relativity. but to various phenomenology due to various coupling terms in their action. the relationship to choose the field variables while them the of the the j frame or where the gravitational is minimally to matter degrees or the e frame where where the metric is is in the e-hilbert form. the relationship focuses to generalize the analysis of these relationship between these two to theories that higher spin fields such vectors instead. study of on theories',\n"," ' quasi quasi agent-critic model is a to a reference model agent to order study.The structure of quasi quasi-symbolic agent is matching and value networks. which single layer and networks.entially connected.The matching network memorizes input vectors by imprinting normalized inputs to synaptic weights converThe value of matching nodes is identical to the number of value nodes. and the-to-one mapping between matching. the new node is added to the matching network, a new node is added to the value network. keep one one. the strength strength between these is determined by the reward induced by r selected agent with structure of matching',\n"," ' computer computer proposed presents a method called d map Maker using dmc), can computer vision algorithm to create create a by stitching together images information captured by a d. camera camera. The proposed utilizes the speeded up robustotic features method to detect the points for each image frame. identify the the points between frames. maximizing the determinant of a heian mat.The proposed points are identified to create together two by and in a st creation. some from the external environment....,, adad    dddddd']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:59,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 16, training loss: 2.298807144165039\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:03,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 17, training loss: 2.4665324687957764\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:06,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 18, training loss: 2.540130376815796\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:10,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 19, training loss: 2.5561985969543457\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:13,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 20, training loss: 2.17400860786438\n","epoch 8, prediction loss: 2.4260969161987305\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in this context of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play crucial building the-nano-medical applications. in paper presents the e-to-end communication link consisting electromagnetic electromagnetic and molecular communication. based closed-form expression for presented for the e error probability ( the e system system.based optimization method is formulated with minimize the bit error rate of the the optimal symbol duration for the time from. numerical proposed is solved by an iterative algorithm based on the bisection met.umerical results show that the proposed method ob ob',\n"," ' in in continuity discusses the continuity of the heat kernels of the reflection brownian motion ( a general lipsipschitz domain.The is that existence of theolev typetype inequality on a domains like to the presence of a cusp at inf.The text prove that the heat kernel of reflection reflectionian motion on a uniform domains are continu. and not heat domainsipschitz domains is not an uniform.The text also the estimates estimates to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain isThe is important in the transformation theory of theov processes. its the-spectral independence',\n"," ' a a study discusses auscule represent with the to the weight uq-crystals.The. weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. thex and.....,,,,,,,,,,.......,,,...,............,,......ivalent,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:18,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 21, training loss: 2.384828567504883\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:21,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 22, training loss: 2.147977352142334\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:24,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 23, training loss: 2.4134199619293213\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:28,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 24, training loss: 2.6407761573791504\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:31,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 25, training loss: 2.2912960052490234\n","epoch 8, prediction loss: 2.588805675506592\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the recognition.The algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region.Themarksing is on a minima detector operator isative algorithm. remove landmarks landmarks in the nasal region. such as the nasalnasale and sub corners.lieriers are removed using aative methods. remove the selectioning. algorithm is to reduce identify landmarks al such maintaining redundant parts. the face.............',\n"," ' in in decom discusses the the type e6 crystal decomposition into constructing the and adding loops at everyices. the the composition graph.The example decom r is a as an i0,7-highest weight ele. the sectionposition.......,,,,,,,,,,,.,...ivalentivalent.ivalentivalentivalentadj.ivalentivalentivalentadjivalentivalentivalentivalentivalentivalent..ivalentawareawareawareawareawareawareawareawareawareawareivalentivalentawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' feature featureised features descriptors are used to the nasal region using the features in spherical. Theised are theabor wavelets filters are a featuresors. and to a dimensionality and reduced redundancy and and improvedabilistic feature selection. reduce the to facial expressions. maintaining theinative features.The landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors.The sphericalors are the use of the spherical on the nasal surface. when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:36,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 26, training loss: 2.6360280513763428\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:39,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 27, training loss: 1.9763810634613037\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:43,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 28, training loss: 2.831475257873535\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:46,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 29, training loss: 2.3364310264587402\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:50,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 30, training loss: 2.4407379627227783\n","epoch 8, prediction loss: 2.8338358402252197\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses a detailed overview of theson sld. a on the only and in the text. also as a reference reference for understanding the concepts in thei geometryometry. the problems.x........igenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' double doubletic models have transit probability have double transit systems have presented establishedknown for on the inclination and, larger models models for larger multiplicity systems is more difficult. requires semi-analytic models. to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated for to address the distribution population of the non for transit transit probability is some specific semi-major axis value is created. this with other for the geometric of otheroplanet period. to address this related to the order, stability against a non-uniform method method is used to the period distributions to such',\n"," ' this this text section the in the images images. to the. can be the..The text used in to address these by improve that transitions between images images.The, ity details details can occur occur the quality.Theosing the best appropriate algorithm for this problem is a. to the issues.Theio algorithm.....,...addaddadd.addaddaddaddaddaddaddaddaddaddaddaddaddaddaddadenaddaddadd.abaddaden..ab.abababababababababababababababababab']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:54,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 31, training loss: 2.5396130084991455\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:58,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 32, training loss: 2.201483964920044\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:01,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 33, training loss: 2.592737913131714\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:05,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 34, training loss: 3.0660595893859863\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:08,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 35, training loss: 2.3747687339782715\n","epoch 8, prediction loss: 3.162421703338623\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke discusses the modeling soft the from the keomult soft soft extract the ke population parameters determine data. in study modeling presented each of planets according on the parameters and and each randomly to of detection basedbased probability parameters the population parameters are is a weak in the radius population around with due by a unique population planet and population population.-planet systems are also and comparison analysis. and that population dependence. forward model is from bayesian analysis shows compared and with that in the parameters due uncertainty.. best parametersiates between multiple- and systems and single-planet systems. showing the implications future studies of such period and radius',\n"," ' the the ke discusses the impact of detection detection of represent the detection eff of the ke mission for to grid is created into 100,000 regions in period and radius spac and for region is divided in in log space for period and radius spac all each are assigned m based on the order. for probability order is are the for detecting multipleoplanets within each detection within. probability described repeated for each of in the detection order grids. to probability efficiency maps for the effects of limbity and limb the new function for account mis mis transits.preating between made to determine the probabilities for different detection order. probabilities are created using higher multipl',\n"," ' in in works have been deep learning architectures or address network flows in however of have shown on the problem in order in however others have focused the to as convesian neural networks in convabilistic graphical models. semi-supervised learning in however in been been done in the neural neural networks to however,stm networks, to address data data. and neural flow data. in main discusses a approachmentation approach for generating time data in network traffic trace g tcp the contribution that in the results used. generating cases and numer data aug. used as recurrent aug, andimation and kd) and used to generating data data. network network-']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:13,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 36, training loss: 2.1718060970306396\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:16,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 37, training loss: 2.0807344913482666\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:20,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 38, training loss: 2.5659055709838867\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:23,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 39, training loss: 2.2998878955841064\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:27,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 40, training loss: 2.3795790672302246\n","epoch 8, prediction loss: 2.430161952972412\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses the lie algebra of type an, whichoted sl sln+ is which to the graphs.. text discusses the all n-colored edge in the crystal graph. also discusses the the decomposition of the 4 is multiplicity-fre......,,,,,,,,,,,,..,,,able.,,,aware.aware,,',\n"," ' abstract abstract concept on the concept of the of abstract u. the the on theq-crystals. a abstract on the e 7.kin diagram.The is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals. concept also the conceptor product convention for the tens for the abstract crystal. be a. a uq-crystal.. a u uq-mod...,,,,,,,,,,,,......',\n"," ' previous previous distribution discusses the resultsolation of previous populations parameters to longer periods and discusses the the results of not differ significantly from previous studies. discusses consistent with previous findings.. arises found between previousman-mackey et study to uses the a specific functional form for theolation to using aussian process regression. determine the functions.man-mackey et approach also a results pipeline in for does reports the highest signal to to- noiseise candidate around each star. results also discusses the detection order can bias the. leading leadingcounting small planets and long periods. text used in bur et al., used by the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:31,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 41, training loss: 1.8868318796157837\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:34,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 42, training loss: 2.9546520709991455\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:38,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 43, training loss: 3.016925573348999\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:41,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 44, training loss: 2.7214910984039307\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:45,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 45, training loss: 1.8880140781402588\n","epoch 8, prediction loss: 2.6582536697387695\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[\" reinforcement reinforcementinforcement learning ( inspired by brain brain's reward-based learning process allows artificial agents to learn a without detailed instructions or labeled training sets. given study is crucial for supervised general-like intelligence agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are not unclear.Theparent decision with transparentible internal-making processes are necessary for safe reinforcement learning agents into into high stakesstakesake problem. in conducted that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description. in of proposes a quasi-symbolic agent as a secondary agent and and can generalably to\",\n"," ' internet internet internet discusses the deep learning on network in analyze flow traffic patterns order imbalanced environment. The proposes a novel augmentation approach based longstm network for generating flow patterns and and kernel density estimation for replicating the features of The results is to improve the with which internet network with less users. The of datasets datasets demonstrates that performance of precision of precision, recall, and f1 measure. every classes classes.....,,,,,,,,,,,dddddddddddddddd',\n"," \" k krillov-reshetikhin modules k)cry are a-dimensional representations for affne lie algebras. by their drinfel'd polynomials. are mathematical. such as solutions of the q-system.k construction for to determine a uniform model for k modules. which are been achieved for br,1. kashiwara. construction of.aito and sagaki have constructed k construction brceptional affne br. lmibai-seshadri paths.. crystals are perfect for the physic and have connected to mathematical mathematical mathematics subject class 05e10,17b\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:49,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 46, training loss: 2.592987298965454\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:53,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 47, training loss: 2.3982086181640625\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:56,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 48, training loss: 2.6733803749084473\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [03:00,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 49, training loss: 2.12190318107605\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:03,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 50, training loss: 2.713698625564575\n","epoch 8, prediction loss: 2.7736480236053467\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the current discusses the impact of the matter ( d)ther density using using the thermally averaged andaged annihilation annihilation cross- forThe current have the cross-averaged annihilation cross- for f operators candidates including compare the methods to compute the lower density constraint direct such such as dermil-abs, hess are are sensitive to the types candidates.ihilation cross- are various types candidates are computed. various with le leptons and photons. results also discusses the on theider experiments to these operators for their on theh.. text discusses on the detection experiments such d particleselectron scattering delastic',\n"," ' the the textogenized model derived in this paper provides an approximation of theroacoustic interaction in a perforated solid structure. model responses of the modelogenized model are compared with the responses problemd heterogeneous solid structure representing direct mult model. on the finite element approximation. model of are the the referenceogenized and the models are illustrated in responses of the homogenized model is performed in two steps. comparing responses of acousticlections obtained by direct numerical simulations. firstogenized model andifies the text by to the complexity of the finite element mesh complexity increasing number of holesforating holes. reference presented implemented',\n"," ' in in text discusses a aff answer to the question of theodge is andoremical weight...12 is the weight of the. the is a eve for text also the. prove to t twists of the hodge struct. the that l is unimodula. text involves in a slightly weaker form of theorem theorem of is a proof involving involves similarrewise a primitive embedding and a hodge isometry on the transcendental lattice. text of v resultingodge is is2 new is the by the.k2.12, the weight of the ranks of h2 new and h is theoted by']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:08,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 51, training loss: 2.4999449253082275\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:11,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 52, training loss: 2.191176414489746\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:15,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 53, training loss: 2.2105801105499268\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:18,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 54, training loss: 2.4009509086608887\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:22,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 55, training loss: 2.4102818965911865\n","epoch 8, prediction loss: 3.1020877361297607\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' let let text discusses a conceptyl group of the certain ofoted w w.g by w..Thex....,,,,,,,,,,,,,,,,,,,,,,,ivalentivalentivalent,ivalent,,,,,,,,,ivalentivalentivalentivalentivalentivalent,,ivalent,,ivalentivalentivalentivalent,,,,,,,,,,,,ivalentivalent,,,,,,,,,,,,,,,,,,',\n"," \" the the isisms are on the category of for and networks by for andfulerryerson.Theisms preserve the context are the-fululkerson flows onTheflows on networks network is defined by a inequalities.Theflow is defined to minflowichai.perner showed original on that min ranks can satisfy hall s condition are to min naturalperne poset. and har introduced hall s matching cond by prove rot.'s conjecture. leading the category matching condition. a normalized of the normalized flow property. category flo is with networksyclic vertex-weighted networks. and morphisms preserving these morphisms.\",\n"," ' in in text discusses a conditions which coupling acoustic fluid pressure fields on an interface which a compliant perforated elastic plat with such by the periodic layer which periodic perforation.The layer is decoupled form the outer acoustic field by neumann fluxes and is by theymptotic analysis based averagingogenization..The diraging procedure based to a of outer acoustic field with the-layer variables.Theumerical examples illustrate the validityogenization model and accuracy. with the numerical simulations. research on at address the of perforated plates in vibroacoustic trans problems text highlights supported by the grants grants funded']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:26,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 56, training loss: 2.7998533248901367\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:30,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 57, training loss: 2.866610050201416\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:33,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 58, training loss: 2.0922939777374268\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:37,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 59, training loss: 1.9292645454406738\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:40,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 60, training loss: 2.6363062858581543\n","epoch 8, prediction loss: 2.986815929412842\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the comb discusses the comb of a7 crystals weight elements from decom the7 highest weight elements. a decom computation..The proofposition into e7 crystals is multiplicity freefree is discussed to the comb that to the one of proposition conjecture inThe proofinatorial r-matrix must used to its ability to map classical components to classical components. leading the weights are k elements are k. computed. a function.The is is as a proof towards proving a conjecture regarding proving a construction of a7crysta value. the certain way.....         ',\n"," ' in in text discusses the-to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes.The of molecules molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is calculatedimated by sim s rul.The orderpembol interference is ignored. the the of left to future work. error error performance ( is also. the on- and and off-body communication channel. and the of the such the between motion of-norm distribution off assumed to the best fitting distribution these-body communication',\n"," ' in in text discusses a examples of the admitting admit thewise sparse domin.The text discusses the the operators operators can known known. but the unified approach simplified approach to provided to on theoremore 1. its variant. results are from from previous results. consideringi l and sheldy ombrosi. and the improvements provided in section.. text text is the the text admits of weak type. to theorem 1. and a specific refined result with by section slightly case. by.....,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:45,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 61, training loss: 2.838918924331665\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:48,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 62, training loss: 2.2311770915985107\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:51,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 63, training loss: 2.392615556716919\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:55,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 64, training loss: 2.7284488677978516\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 65, training loss: 2.436028480529785\n","epoch 8, prediction loss: 2.462210178375244\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' effective effective effective discusses the effective interactions of darkermionic, scalar and vector vector dark matter with leptons and neutral electroweak gauge bosons induced the higher dimensional effective-2 tensor operator.  is the effectiveally averaged indirect indirect matter pair d) pair annihilation cross-section and the spin-independent d -. le and/or bound electron. and that with the data.....,,,,,,,,,,,,,,,......',\n"," ' the the boundary discusses the boundarydimensional haddorffme on the to the the boundary boundary local time of the.The section also the naotoaka kajino for the comments on the proof. lema.............ad................,............,,aware....',\n"," ' we we ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous studies using focusing upon previous bay. extract information about the multiplicit. comple a best replication of the empirical empirical multipl. studies have used a steep rise towards smaller radius planets at all periods and a steep rise with increasing periods to by a gradual decline towe inclusion presented a larger maximization technique to a the distributions for a parameters. with the from previous provided previous bay. study is that with the with previous studies. with with the presence of small radius planets. to detection threshold. usingorously treating completeness mapping and a']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:03,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 66, training loss: 2.8496956825256348\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:06,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 67, training loss: 1.9492195844650269\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:10,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 68, training loss: 2.7139010429382324\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:13,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 69, training loss: 2.036611557006836\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:17,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 70, training loss: 2.1664628982543945\n","epoch 8, prediction loss: 2.3326902389526367\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the potential discusses the potential of the patches and curves for expression expressiond face recognition. The novel five-step algorithm is presented. with with aly of the nose tip location segmenting and aligning the face and and thenpping the nasal region. The very anding algorithm is seven keypoints on the nasal reg.The genetic algorithm-based feature selector is the patches and curves over different facial expressions. The algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing.....',\n"," ' the the impact discusses thely interacting dark matter ( interactions their interactions with focusing are be motivated from various detection indirect detection experiments.The u physics extensions of standard standard model ( sm) and been proposed to address the matter candidates d) candidates or whose as uly interactingacting neutral (ons ( wimps)  detection experiments have shrunk the parameter space of the models where neutralimps to with the visible world viaThe constrained of sm particles sm model particles are encaps in the lagrangian approach. where the of the dimensional effective operators constructedThestrained on these higher are discussed from various data. estimate and the u models.The sensitivity',\n"," ' the thefaces diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space.The surface velocity of evolving surfaces is determined by purely geometric quant. while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. in these studies have on compact hypersurfaces, these paper considers uniformly regular hypersurfaces. which non-compac surfaces.. utilizing the study of uniformly larger class of manifolds and we study presented to the study research of geometric flows on non-compact manifolds. study relies based by the theory of continuous maximal']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:21,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 71, training loss: 2.5983211994171143\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:25,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 72, training loss: 2.191314220428467\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:28,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 73, training loss: 2.6578316688537598\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 74, training loss: 2.4248013496398926\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:35,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 75, training loss: 2.332214117050171\n","epoch 8, prediction loss: 2.9773428440093994\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text of that in the the augmentation process in a data from classes with less population in the dat is The aug involves aug and convstm layer on generate the pattern of directions and windows windows sizes in the flo function and followed the distribution functions ( pdfs ) of every features using and points points in each feature dom, on the pdfs, and generating points dat dat. the.The the number of points in the generated sequence is less than 20, the rest is app with arrays arrays points. convolutional recurrent neural network was trained trained on the augmented dat. with a batch architecture. rel normalization lay.',\n"," ' the the text. thexiv:190. a detailed description of the text details of in the text.ar discusses the main points of discusses. were be discussed in including a a detailed overview of the is expect from the future section.arx.......,,,,,,,,,,,,,,,,,,fbfb,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' this this e discusses a e userto-end e-health system with for includes molecular and electromagnetic wireless communications.The-body and are considered via a generic-assisted diffusion-based molecular communication system. while aomachransmissionters and receivers molecules.The specific node is be improve the link andThe proposed model includes a-body and off-body communications. which a symbol of molecules schemes. different symbol intervals. each communication type.Theomachines/ as relay nodes. and nearly free and molecular. proposed is includes a2out-off-body communications communications. aways. on communication. the system-health system.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:40,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 76, training loss: 2.082104206085205\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 77, training loss: 2.6533706188201904\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 78, training loss: 3.0568923950195312\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 79, training loss: 2.039649724960327\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:54,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 80, training loss: 2.588822364807129\n","epoch 8, prediction loss: 2.9413537979125977\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the keism we in this study utilizes applied to derive the occurrence rate parameters for planets orbiting gk dwar stars. The from the final ke data dr25 and including planet radius measurements from theks and ga and, and corrected detection eff for multiple-planet systems are used.  resulting includes on previous poisson process likelihood function used includes a modifiedesian framework to using anMC. resulting are that values for the occurrence of including a in the best fitfit model occurring at p times of novel feature of the ability to extract exoplanet multiplicit through through the f parameter. which the probability of a system having at least m',\n"," ' in in text discusses a text of uniformly well and and focusing the mean curvature and a. the applicationability to the hypersurfaces.The also the conceptence of the concept of uniformly strongly elliptic and uniformly normally elliptic hypers the contextar case. well -posedness result for the sphere class is derived. the methods. proofs textms. including the importance.chitz continuity of the semiflow.......,,,,,,.........,ababbh',\n"," ' the the acoustic discusses the method analysis for the the acoustic acoustic pressure and the displacements and and rotation in a limit lay.The result is based for understanding understanding- and equations of vib vibroacoustic problem imposedThe convergenceymptotic analysis is based using the unfolding method. which developed for the seminal paper by elaborated elaborated further thin structures inx......gg,,,,,,,,,,,.,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:58,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 81, training loss: 2.618428945541382\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:02,  3.73s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 82, training loss: 2.4777708053588867\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:05,  3.66s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 83, training loss: 1.8794358968734741\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 84, training loss: 2.6736645698547363\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:12,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 85, training loss: 2.814790964126587\n","epoch 8, prediction loss: 2.7294957637786865\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses a results test of the modelogenized model of a perforated plate of the reissner-mindlin typ.The impact is to compare responses responses of the homogenized model model with the of the associated 3d elastic structure withTheations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure.The deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat modelThe influence of the compliance on the loss in the waveguide is discussed.The influence',\n"," ' the the text discusses the text acoustic of thero-oustic response in inThe text is theposing the solvingogenizing the vib of thero-acoustic response in a hom ofThe text is on the the acoustic field in the layer with the surrounding en. the a coupling equation. conditions are the global problem are provided. and are the to the limit on the specific limit for....,,,,,,,,,,,...,,......,,,,,,',\n"," ' in in text discusses a simplified of theorem a, showing that variation of the proof of in theorem a. The being between the proofs proofs, they. proof is provided. reader. The proof is a a common ingredient of both proofs. and the cases. and providing a partition. satisfy the desired result.The section to a proof of a specific 2-sparse family fqj such The proof is focuses the model on - onymund operator.. the cal version. text is with showing the similarmma to showing the proof. theorem a............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 86, training loss: 2.3382296562194824\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 87, training loss: 2.474717378616333\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 88, training loss: 3.4298558235168457\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 89, training loss: 2.1388611793518066\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:30,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 90, training loss: 2.377429723739624\n","epoch 8, prediction loss: 2.6639280319213867\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the study: a study of ant antichain a a pos connected set. aet ) and no two elements are compar.The. and and...,,,,,,,,,,,,,,,,,ivalentivalent,,,,,,,,,,,,,,,,,,,,,,,,,,ivalentivalentivalentawareivalent,awareawareawareawareawareawareawareawareawareawareawareawareawareaware,awareawareawareaware,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in first discusses the thestation fractional power elliptic operator equations numerically. using equivalent local nonstationary initial value pseudo-parabolic problem.The such were the implicit backward and symmetrical euler method. while the paper introduces to the fourth-parameter family of three-level finite difference schemes forThe fourth-order approximation scheme is developed by optimal optimal weight paramization The resultsical analysis and are supplemented by extensive computational experiments.....,,,,..',\n"," ' the the text discusses the section of the in a presence of the diffusion flows. focusing the theore 2. for for the process of flow. well as......,,,,,,,antingaging,,,,ivalentivalent,adj.,,,..,......,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 91, training loss: 2.282823085784912\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 92, training loss: 2.449634075164795\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 93, training loss: 2.463991641998291\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 94, training loss: 1.9707603454589844\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:49,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 95, training loss: 2.8736231327056885\n","epoch 8, prediction loss: 2.5424981117248535\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the we on thet and algebra and the contextil algebra. 16 55.2........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,,ivalentivalentivalentawareawareivalentawareaware.awareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalent,,ivalentivalentivalent',\n"," ' in inorem discusses a proof of convergence theorem on the the monmma. is the convergence of the text. themma.. le to text condition. shown in section section by section also a concept ft : the to themma 3. le textotone convergence theorem., the introduces the ex for the with respect to the probability measure. the with section with proving le textms. lemmaps.............awareaware....',\n"," ' the the j discusses the j of generalizations of spontaneousar- andensor theories where sts), the j frame.. where the scalar field replaced with other fields and couplings can depend on derivative. The study came from the that spontaneous tensoriz where where are most naturally defined in the canonical frame where however are be applied to any generalization of on a conformal scaling of the metric in the matter action by first highlights vector the scalar field a vector field the-tensor theories obtained vector to the-based spontaneous scalarization arezing the equations of interesting time derivative terms in no renders orderorder equations']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 96, training loss: 2.316464424133301\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:57,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 97, training loss: 2.534348964691162\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [06:00,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 98, training loss: 1.7383604049682617\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:04,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 99, training loss: 2.1375882625579834\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:07,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 100, training loss: 2.81174635887146\n","epoch 8, prediction loss: 2.739109754562378\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' double double text discusses theisson s lie bundles and a are the to the lie algebroids. text is been in applications to other fields systems., it text discusses the splitting of double vector bundles and-....,,,,,,,,,,,aware,awareaware,,,,',\n"," ' we we study discusses the study of a ensemblene affinvariant ensemble sampl to explore 13 sets toThe bayesian framework is linear space uniform priors is used toThe toors are used for the 13 ofbr and pbr. on the distribution sample. casc prior is that f must must be larger than f. avoid trunc. prior is is for larger multiplicity systems to be more common than smaller multipl.....,,,,,,,,......',\n"," ' in in text discusses the classification of irregular with by theodge theory. specifically by the with irregular3 type. product modental part.The are the related the group of these surfaces and their conditions answers to the questions. certain conditions. text also the the text of these surfaces is not not. that the state state of the art. also on the-quotients surfaces and show mod group theoretical properties. and well as those moduli spac. text obtained can used to prove that t- mumford-tate conjectures for these surfaces. text also the support of inspiration. provide a overview of the current state']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:12,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 101, training loss: 2.2142257690429688\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 102, training loss: 2.140502691268921\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 103, training loss: 2.4815726280212402\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 104, training loss: 2.5277411937713623\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:26,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 105, training loss: 2.367781162261963\n","epoch 8, prediction loss: 2.645613431930542\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in surface discusses the concept of uniformly regular manifolds and and the importance properties. for the the diffusion flows. will willmore flow.The structuresolds are consideredodesically complete, of positive positive injectivity radius and are are allant derivatives of the curvature tensor arelyolds are boundary are uniformly regular. and well the surfacesolds considered in. text. textally uniformly a defined tens compactly supported tensor fields is the base base manifold is identifying it as zero outside their original dom is used. text also mentions the bcs and bcs. in a similar manner. am.....',\n"," ' the the feature selection step involves the engineeringgorithm ( ga) is to select thoseets of curves vectors extracted curves and patches patches extracted are more against facial expression.The modified vector is used to select select the most robust curves from remove the features. The varying the value vector element the curves and patches can selected or omitted based depending reducing the rates. reducing the selection. the appro. fisher fisher analysis analysis..- algorithmgorithm is to in this non dimensionaldimensional binary high-convex optimization process. with a high nsga-ii. elitism over individuals individuals healthy individuals..- feature assignments for the are are explained in section',\n"," ' j j j discusses the use theory of scalar-tensor theories f the j frame beyond focusing the importance of ill order time derivative terms in are ill-posednes in, equations is shown that equations of motion can always reduced to second second-order-in-time form as the original e frame formulation is well posedposed. inverse transformation from the j frame back the e frame is not be possible for all field values in the in but it fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f. text motivation is a better understand spontaneous scalarization and its general']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:30,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 106, training loss: 2.4837424755096436\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:33,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 107, training loss: 2.78197979927063\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:37,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 108, training loss: 2.216566324234009\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:40,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 109, training loss: 1.99940824508667\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:44,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 110, training loss: 2.0269856452941895\n","epoch 8, prediction loss: 2.8456802368164062\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using usinginstein of are transit transit study have to properties of the populations fromusing key function is utilized for determining bayesian theorem theorem and extract parameters parameters. The method distribution is assumed as independent independent power lawlaw distributions in period and rad. using distribution that a single population population is made assuming assuming the distribution of this assumption is examined.order distribution focuses on multiple systems with examineszes the effects effects introduced the and multipl. distribution used to on previous studies to utilizing planets by detection order. results show insight on the factors detection order. show distribution parameters functions this introduced the distribution distribution fun. to this. statistics are explored for to',\n"," ' the the en model ( the context is the en. modeling into state vector and action a inputs and the the next state.The this text, the network layer of a nodes is used to the text network.The is shown using the squared error regression each episode of random learning.. a ensemble learning rate of 0.0..........ad...,,,,.,dd,...adenaden....,,......,awareadenadenaware',\n"," ' super super study discusses the sensitivity of the constraints on the matter pair d)- at including on the sensitivity to sensitivity to the momentum of d pair atom and/- electronron scattering. to suppressed of quarks in. is the need of theizing lepto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh) and discusses the need of studying the- to the-2 operators.on text is highlightszes the state effects of d- atom scattering cross dama data. derives the the- production channels at the proposed linear coll ( ilc)  study also the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:49,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 111, training loss: 2.8166584968566895\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:52,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 112, training loss: 2.393317461013794\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:55,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 113, training loss: 2.393711566925049\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 114, training loss: 2.6714351177215576\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:02,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 115, training loss: 2.5942416191101074\n","epoch 8, prediction loss: 3.0823609828948975\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the datasetsd datasets are used to evaluate the face recognition algorithm proposed thegc,bosphorus 3 and the-3de. The proposedgc dataset is 5 with 5 sets expressions and and the bosphorus dataset includes samples of six prototypic expressions. The b was performanceing accuracy and accuracy were evaluated using and that accuracy for thegc samples to the samples and The robustors were inabor wavelets, the a scale, for each recognition..The results was a accuracy rates for the b al and the samples. with aness for the-neutral samples. probes. Theisons results was the face is also. showing',\n"," ' the the text discusses the results related to the theory dir subsetets and andichlet forms, andotone class argument, andity and and domain,, and eigenfun, and, and finini theorem theorem.The words include the thatity, the dirichlet form, showing convergence of themma 1. proof. to le proofs. section also discusses the textification theorem. the principaln t. l. the textiteness of the*....,........',\n"," ' using using importance discusses a the in the measurement into a bayesian hierarchical model. occurrence for parameters. order context generation of occurrence fitt. The importanceicity parameters derived here be in determining an eta earth measuremen the importance of neighboring planets could the long of an et analog is multiple multiple sy may important. importance also that a injection experiments to determine the eff across understanding the effects. detection eff.ining data from missions will it as ke and t tess will will will essential for understanding occurrence measure. as for the detection effiencies across method described here to incorporate these selection effects into maintaining a uniform distribution distribution. method']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 116, training loss: 2.1976335048675537\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 117, training loss: 2.4975221157073975\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 118, training loss: 2.6020405292510986\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:17,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 119, training loss: 2.4854495525360107\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:21,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 120, training loss: 2.7892167568206787\n","epoch 8, prediction loss: 2.3832380771636963\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' tele tele text discusses the importance of time duration ratio ( emedicine communications for e communication delivery. theomachin. The text symbol slot partitioning ( found by the the userto-end symbol error rate ( The optimization algorithm is formulated for find the best performance in e between The optimization involves solving the symbol slot interval three of in types of communication links. The achieve the quasiconvex optimization problem, a quection optimization is formulated. on amc parameters and symbolr of the. The optimization is a in the ec transmission side. does comput and robust. low complexity complexity........',\n"," ' in in text discusses the minimal domin1 theoremty singular for which the minimal assumptionsity conditions on the singular t. which the singular holds. is that the proof on the minimal hold similar unknown. discusses are they theorem dini cond can be relaxed to section also the minimal assumptions on t k yielding yield thewise sparse domin. text are in proofs and le the sectionmma. le. the. to the weak. also with showing that the the bounded extension of the t is to2 to itself if then bounded condition on hold for......,,ad, ',\n"," ' stars stars lack discusses the use of a modified poisson distribution function to modelolate to expected of existence for stars multiplicity stars systems.The using these function to we expected suggests that 0 best empirical multiplicity of be increased by a function of selection effect. study also discusses the implications of this function to the the for the multipl and period. the the is the impact of this model of multiplicity in our solar system for theability. highlighting that lack for a studies. support such claims...........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:25,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 121, training loss: 2.6261630058288574\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:29,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 122, training loss: 2.7097721099853516\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:32,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 123, training loss: 2.1325976848602295\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:36,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 124, training loss: 2.40706729888916\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 125, training loss: 2.7104997634887695\n","epoch 8, prediction loss: 3.114285945892334\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposesThe is the importance of the 3 for surface features for expression robust andust recogn. includinging previous approaches and providing high discrim of discriminant strength and The proposed is a landmarksing and feature extraction techniques and multi-resolution gabor wavelets to The isforms previous approachesd nose recognition algorithms by achieves superior performance compared with face that the whole facial dom. The, the proposed is a such as improved denoising and and improved pose pose correct algorithms features are achieved in section text. theing and feature extraction and and',\n"," ' error error error results to that performance of the proposed e toto-end error sy for diff diffusive environment like blood.The channel coding is considered for The performance probability performance analyzed as on the parameters like including location and and at and and symbol velocity. The analyzing the parameters, the performance error probability ( ber) is be improved. trade-off between the conversion and channel rate rate also. where the trade value-to-end ber e2e)berert performance when the the energy molecular channel ( dmc) and errorstatic ( ec).. the velocity can the minimum2e berery performance increased increased the',\n"," ' 25 25 textaic - involves a method to to measuringson toolds to with involves used in a, a functions.The involves the the equations of a basis. create the. solving the results.x method,,.,,,igenigenigen,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:44,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 126, training loss: 2.1408307552337646\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 127, training loss: 2.6123170852661133\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:51,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 128, training loss: 2.684262752532959\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 129, training loss: 2.0260064601898193\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:58,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 130, training loss: 2.420070171356201\n","epoch 8, prediction loss: 2.610283851623535\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a proof of the theorem stating the themma. le the. show the theoremollary. proof of that that the text u u\" is unounded. and the proof involves based by using the arguments. in the proof of theorem theorem.......,,,,,,,,,,,,,adj,,,,..ivalent,,,abableabivalent.,,ab,..,,ab,,abababab,,',\n"," ' splitting splitting splitting discusses the splitting theoremorems of homson pairs and j proposed by dazord, lichnerowicz and and marle inas. result is the proof to prove the splittingorems for which with the a alternative proof of the splitting theorem of homogeneous poisson structure.............,,,,,,,,,,..,,,.,,,..,,,,',\n"," ' christ christ christ discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars.The doing the light light curves with the standard detection pip, the recovery fraction can be assessed. producing a probability function based on transit mes.to-noise ratios. mes))  christ of detection order on recover is discussed. with the order defined by the variable m. the christ from split into injection with and after the days. and well 200 time the distributions begin significantly. is made on the with 2 or discovered......g...ggg..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 131, training loss: 2.839111089706421\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:05,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 132, training loss: 2.684119462966919\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:09,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 133, training loss: 2.1302413940429688\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 134, training loss: 2.401988983154297\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:16,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 135, training loss: 2.178889274597168\n","epoch 8, prediction loss: 2.222536563873291\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' ke ke ke mission has increased our understanding of the around sun-like stars.The final data release dr dr25, provides all on to the failure of two reaction wheel. providing the end end of the primary phase ofTheort are made to quantify the frequency of properties of planets systems and with the on the with earth-like proper.....,,,,,,,,,,,,,,,,,,,..............iviviviviviviviviviviviviv,.,,iv,.',\n"," ' the the this text, themology andarticles theoryientsal are considered. a method model. can a crucial role in the the understanding the systems. systemsversals are a framework tool for studying the such the thelectic and nony processeslectic structures are involved. studying the structuresversals,  can able to study insights insights into the structure of dynamics between the systems. and them useful valuable resource for understanding areas fields. modeling.x.......,,.,,,,',\n"," ' the the effects discusses the effects of mutual inclination on the k recovery forThe study recovery study was not account for mutual multiplicity planet. did did not account mutual incl. however planets were injected with a impact parameters from study the impact parameters mutual inclination. detection eff.The impact was at systems impact in impact parameters for recovered planet systems with known planet.. mutual inclinations can cause certain planets to ge avoid transit compleometrically........,,,......']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:20,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 136, training loss: 2.362903118133545\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 137, training loss: 2.5064008235931396\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 138, training loss: 2.4324638843536377\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 139, training loss: 2.658682346343994\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:34,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 140, training loss: 2.615722417831421\n","epoch 8, prediction loss: 2.4343934059143066\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the t discusses the t- mumford-tate conjectures for surfaces s connected components of the gieseker moduli space that contain a product-quotient surf..,,...,,,,,,,antivalent,,,,,,................able..',\n"," ' transition transition continuity discusses the continuity of transition densities of reflecting brownian motions on lipsipschitz domains. also provides the estimates for the transition. surface that the surface measure on the domain is in the local kato class. the reflecting brownian mot.................',\n"," ' the the text discusses theooninivityverseal in.........,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 141, training loss: 2.6183481216430664\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:42,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 142, training loss: 2.4795308113098145\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:46,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 143, training loss: 2.0583508014678955\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 144, training loss: 2.5065441131591797\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:53,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 145, training loss: 2.2605674266815186\n","epoch 8, prediction loss: 3.3050756454467773\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' bo bo boofcv library has image stitching algorithm is the some points features and findingly finding a 2d transform using findingating them key points between the and and then a robust fitting to to finding changes transformations. as rotation.The, when we to stitch more result image with a third image, the will. the result will tries the black background. the image process. to distortion is caused by the in theofcv. so to a images. stitching more than two images. to avoid this issue we algorithm algorithm was implemented using openc. find this distortion issue by theofcv. translation. to..x..',\n"," ' with with traffic is a for the ever amount volumes in withifying the patterns and applicationsifying applications is two tasks in with traffic tracingifications ( nt)) have classify anomalies in classify applications for however they methods have shown. port on ports in lack.. their. ingorithmms have these classification classification have promise in they methods for however thebalanced datasets is networks-scale networks datasets a challenging for deep. f.. inmentation is have machine learning have such as artificial artificial data for are address these imbalance issues, novel approachmentation method is k dataensity andimation ( kde) and lestestTerm memory ( lst',\n"," ' molecular molecular: The the text increase in the demand for health services is increasingacing the increase in health health services and professional.Themedicine is which implementation of tele technology to provide medical services is has a as a promising solution for address the challenges.in is the biological communication sensing technologies to gather biological signals and medical them information to the providers.The of application of themedicine is the delivery which which the focus on the therapy. control targeted information to the. minimizing the effects.The between a central role in the themedicine system. which the advancements has to the-based molecular communication ( inner body and communication.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:57,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 146, training loss: 2.215391159057617\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [09:01,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 147, training loss: 2.0866644382476807\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:04,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 148, training loss: 2.3446226119995117\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 149, training loss: 2.6491434574127197\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:11,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 150, training loss: 2.151193618774414\n","epoch 8, prediction loss: 2.653700351715088\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in order difference-level difference difference scheme are constructed. section section. The stability condition for the initial the scheme is woted by w,,is to be computed with a symm-level algorithm algorithm. the same accuracy as of main scheme. Themmetrical scheme are the with the order accur. suff smooth solutions. The conditions for formulated for the symm-level scheme. and that stability with respect to the dat. high of high high order three-level difference is to the second initial condition w denoted as w2 with the order accuracy. the schemes can be used to solving conditions w they restrictions are that using.',\n"," ' ch chorem discusses theic surfaces3 surfaces of ch ch to chow motives of surfaces.The also a proofposition of theow motives of surfacesic surfaces into aic and transcendental components. and by a comput. computations.The sectionogenical decomposition of theelian varieties with group action is also. with to a proof of the specific example.The section discusses with a discussion on the specific example in a product of singular algebraic k3 partner of the minimal between theers surfaces. ch resolutions. showing the importanceogenism between theental surfaces of............',\n"," ' in in text result of in this section is that multiplicity freereeness of the decom. this labeling labeling convent. which well by section 2. proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the 1 using the and adding loops to everyices and and adding the composition graph g, we is shown that the crystal b is type e. a multipl rule. the multipl m of x x. proofposition is multipl proven by amma. leabeling the fundamental weight. and leading in a multiplicity']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:16,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 151, training loss: 2.559375286102295\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:19,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 152, training loss: 2.639094114303589\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 153, training loss: 2.6288259029388428\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:26,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 154, training loss: 2.3118345737457275\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:29,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 155, training loss: 2.1598329544067383\n","epoch 8, prediction loss: 2.6596810817718506\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' using using study discusses the use of creating a stellar sample for use a detection efficiency map using the data. the1q17. The stellar includes a parameters from theur et al., ga stellar values from ga dr2. the values have been been updated from the dr2, the has25 stellar parameters values have updated updated. ensure thatteness mapping of the star must have a stellar of its radius and mass measurement values for either fields result in omission., the on placed on the cycle and f) > f.5) and time length ( light light curve ( final includes a-varying noise',\n"," ' the the text discusses the properties for on the priori estimates for the a. based text provides convergence convergence of the unfolded function. the2.i to the convergenceation of the limit vibro-acoustic problem. a formal approach. the sequences constructed with the convergence res.based......,,.,,,,,.ad.,,..,,,..,,,..,,,...,,,aware..,,,,,,,,,,,,,,,,,,,,,,',\n"," ' in in text discusses a bounds for cal operators and harmonic analys.Theization and sparseness are two ingredients in make sparse bounds especially tools weighted norm inequ.The text on sparse bounds for too andars bounds for cal on- onymund operators are calizations domination principles are reviewed. text show a proof proof on means the main hypot in the them the weighted weightedq proper proper  result simpl the need for work with the grand maximal truncated operator mt which it text more efficient. The text also organized as five. the proof and the theorem theorem and the and and and and proof t1-type result and and examples']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 156, training loss: 2.3351871967315674\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:37,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 157, training loss: 2.2637007236480713\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:41,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 158, training loss: 2.5058093070983887\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:44,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 159, training loss: 2.4700992107391357\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:48,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 160, training loss: 2.4045770168304443\n","epoch 8, prediction loss: 2.8794519901275635\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses a new for the invisible qcd axion model without domain wall. with the heavy heavy heavy are present.The is is developed in the contextxiv:19012..... the 2018,2018............,ger,,,...,,fbfb.,,,,,,aware,,',\n"," 'TheThe text algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the blobant of the heian matrix is usedized.sur determin is images from using blending the last image for performance and level detail detail and rendering in a final merging. The algorithm image image is as input input for the algorithm. the analysis. the drone moves forward........',\n"," ' in in index discusses theasipinear inequalities with aitycommity. withizing the index j sub acritical. is certain inequality and satisfied. critical in equality holds in case certain case.x....,,,,,ivalent,,,,,,,,,,,,,,,,,,,,,,,,,ivalentivalent,,ivalent,,ivalentivalentivalentivalent,,,,..,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 161, training loss: 2.3527212142944336\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:56,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 162, training loss: 2.2339627742767334\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 163, training loss: 2.418896198272705\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:03,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 8, batch 164, training loss: 2.173469066619873\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:06,  3.68s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.4217741157069352\n","epoch {}'s average verification loss: {} 2.7089897096157074\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [1:32:04<10:11, 611.75s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n","0it [00:00, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 0, training loss: 2.4700357913970947\n"]},{"output_type":"stream","name":"stderr","text":["\n","1it [00:03,  3.32s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 1, training loss: 2.639050245285034\n"]},{"output_type":"stream","name":"stderr","text":["\n","2it [00:06,  3.41s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 2, training loss: 2.4787981510162354\n"]},{"output_type":"stream","name":"stderr","text":["\n","3it [00:10,  3.44s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 3, training loss: 2.550274133682251\n"]},{"output_type":"stream","name":"stderr","text":["\n","4it [00:13,  3.46s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 4, training loss: 2.3991646766662598\n"]},{"output_type":"stream","name":"stderr","text":["\n","5it [00:17,  3.47s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 5, training loss: 2.7556395530700684\n","epoch 9, prediction loss: 3.1611461639404297\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' previous previous distribution discusses the resultsolation of previous populations parameters to longer periods and discusses the the results of not differ significantly from previous studies. discusses consistent with previous findings.. arises found between previousman-mackey et study to uses the a specific functional form for theolation to using aussian process regression. determine the functions.man-mackey et approach also a results pipeline in for does reports the highest signal to to- noiseise candidate around each star. results also discusses the detection order can bias the. leading leadingcounting small planets and long periods. text used in bur et al., used by the',\n"," ' the theac and2obs- are used models that are the a textac equations with a externalical function.. create a setton. with a information. structures are called in the context of the equations. are be used to various applications models. the, theolds.x........igenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' 3 3acial expressions isness is 3d face recognition is a challenging issue topic in to the need of by the-rigid objects expressions.3isting approaches for such the iterative closest point algorithm, can become to variations minima and, approach to capturing a range of facial expressions for each subject and storing them in the subjects in face. but this are are capturing and storage.The approaches have such as the 3 graphics algorithms to have registration and curve-based approaches and and-based methods and and curve difference boosting algorithms have been proposed to address theness against variations expressions. The research have focused the to the multiple normals hist point']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","6it [00:21,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 6, training loss: 2.2840240001678467\n"]},{"output_type":"stream","name":"stderr","text":["\n","7it [00:25,  3.69s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 7, training loss: 2.489304780960083\n"]},{"output_type":"stream","name":"stderr","text":["\n","8it [00:28,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 8, training loss: 2.6340324878692627\n"]},{"output_type":"stream","name":"stderr","text":["\n","9it [00:32,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 9, training loss: 2.6283185482025146\n"]},{"output_type":"stream","name":"stderr","text":["\n","10it [00:35,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 10, training loss: 2.3860867023468018\n","epoch 9, prediction loss: 2.636359214782715\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' feature featureised features descriptors are used to the nasal region using the features in spherical. The vectors are theabor wavelets filters are a featuresors. and to a dimensionality and reduced redundancy and and improvedabilistic feature selection. reduce the to facial expressions. maintaining theinative features. The landmarks are identified to define the keypoints in which sphericaling these central the nasal surface results spherical patchesors. The sphericalors are the use of the spherical on the nasal surface. when the selection selection., theogonal planes toing with the nasal surface provide a on the evaluation evaluation........',\n"," ' the the text discusses theooninivityverseal in.........,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,',\n"," ' the the text discusses the section of the in a presence of the diffusion flows. focusing the theore 2. for for the process of flow. well as......,,,,,,,,aging,,,,ivalentivalent,,.,,,..,......,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","11it [00:40,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 11, training loss: 2.6346435546875\n"]},{"output_type":"stream","name":"stderr","text":["\n","12it [00:43,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 12, training loss: 2.359785318374634\n"]},{"output_type":"stream","name":"stderr","text":["\n","13it [00:47,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 13, training loss: 1.9557890892028809\n"]},{"output_type":"stream","name":"stderr","text":["\n","14it [00:50,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 14, training loss: 2.0962331295013428\n"]},{"output_type":"stream","name":"stderr","text":["\n","15it [00:54,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 15, training loss: 2.4248011112213135\n","epoch 9, prediction loss: 2.411799907684326\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[\" k krillov-reshetikhin modules k)cry are a-dimensional representations for affne lie algebras. by their drinfel'd polynomials. are mathematical. such as solutions of the q-system.k construction for to determine a uniform model for k modules. which are been achieved for br,1. kashiwara. construction of.aito and sagaki have constructed k construction brceptional affne br. lmibai-seshadri paths.. crystals are perfect for the physic and have connected to mathematical mathematical mathematics subject class 05e10,17b\",\n"," ' transition transition continuity discusses the continuity of transition densities of reflecting brownian motions on lipsipschitz domains. also provides the estimates for the transition. surface that the surface measure on the domain is in the local kato class. the reflecting brownian mot.................',\n"," ' the the accuracy discusses the results on thewise linear continuous p1 lagrange elements to approximate the elliptic oper. The accuracy of different approximations in time is investigated. the reference sol. The of the solution are the reference-level weighted difference scheme are estimated. fig. The accuracy is to investigate the accuracy of the threelevellevel weighted scheme. show that the accuracy of the scheme is with the initial condition is w is computed using the algorithm.gence rates of the-level and threelevellevel schemes are on the discrete regularity of the solution of the can be reduced by using ge geometrically refined time grid']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","16it [00:58,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 16, training loss: 2.1782286167144775\n"]},{"output_type":"stream","name":"stderr","text":["\n","17it [01:02,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 17, training loss: 2.358072280883789\n"]},{"output_type":"stream","name":"stderr","text":["\n","18it [01:05,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 18, training loss: 2.365745782852173\n"]},{"output_type":"stream","name":"stderr","text":["\n","19it [01:08,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 19, training loss: 2.537137508392334\n"]},{"output_type":"stream","name":"stderr","text":["\n","20it [01:12,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 20, training loss: 2.8023440837860107\n","epoch 9, prediction loss: 2.5974762439727783\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' dynam dynam cosmic discusses the possibility between the physics and cosmology and the concept of topological defects during spontaneous breaking. theories context.The is the possibility wall problem and theion models higon models and suggests a to as the inflation and the warides-shafq and and the witten effect. minimal minimal is proposed where the spontaneous of peq symmetry is arises at a newiral confining force. leading the domain wall problem. model of instantons interference effects explored and address the domain wall problem. introducing the peq symmetry. the.. model also discusses the issue of hyperbaryons and which heavy',\n"," ' using using ke discusses the bayesian method to to estimate population parameters for the ke sampleoplanet sample with previous studies using focusing upon previous bay. extract information about the multiplicit. comple a best replication of the empirical empirical multipl. studies have used a steep rise towards smaller radius planets at all periods and a steep rise with increasing periods to by a gradual decline to. inclusion presented a larger maximization technique to a the distributions for a parameters. with the from previous provided previous bay. The study is that with the with previous studies. with with the presence of small radius planets. to detection threshold. usingorously treating completeness mapping and a',\n"," ' in in decom discusses the the type e6 crystal decomposition. considering the and adding loops at everyices. the the composition graph.The example decom r is a as an i0,7-highest weight ele. the sectionposition.......,,,,,,,,,,,,,,..ivalentivalentivalentivalentivalentadj.ivalentivalentadjivalentivalentivalentivalentivalentivalent..ivalentawareawareawareawareawareawareawareawareawareawareawareivalentawareawareawareawareawareawareawareawareawareawareawareaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","21it [01:17,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 21, training loss: 2.2620797157287598\n"]},{"output_type":"stream","name":"stderr","text":["\n","22it [01:20,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 22, training loss: 2.082414388656616\n"]},{"output_type":"stream","name":"stderr","text":["\n","23it [01:23,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 23, training loss: 2.424245834350586\n"]},{"output_type":"stream","name":"stderr","text":["\n","24it [01:27,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 24, training loss: 2.5136799812316895\n"]},{"output_type":"stream","name":"stderr","text":["\n","25it [01:30,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 25, training loss: 2.422614336013794\n","epoch 9, prediction loss: 2.5203824043273926\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' analysis analysis ke of the of the multiple planet systems suggests that two componentcomponent population for one one component composed high planet multiplicity and low inclination dispersion while while the other with low low intrinsic multiplicity or a inclination dispersion tol hasotomy has that existence of a low multiplicity population of planetary systems.l, the ke of be affected by the effteness effects/ loss. using analysis suggests that the for detection loss canens the need for an additional population to explain the. inclusion also suggests that dynam transiting systems are more dynamically excited than multiple systems and consistent this stellar suggestss with this notion that some populations share dynam dynam',\n"," \" reinforcement reinforcementinforcement learning ( inspired by brain brain's reward-based learning process allows artificial agents to learn a without detailed instructions or labeled training sets. given study is crucial for supervised general-like intelligence agents or general artificial intellig. in, the exact internal-making processes of reinforcement learning agents are not unclear.Theparent decision with transparentible internal-making processes are necessary for safe reinforcement learning agents into into high stakesstakesake problem. in conducted that the decision-making processes of reinforcement learning agents can be translated into humanreadablereadable description. in of proposes a quasi-symbolic agent as a secondary agent and and can generalably to\",\n"," ' in in transparent of transparents agents to transparent transparent r agent. which two operating units, matching and value network. with two are q agentss agents evaluate actions suggested suggested choose the most probable cho based utilizing for a to reach states. the env model. with suggest that q proposed q ensures the of to the simplicity inner and transparent. selecting selection. proposed of the nodes and nodes and q manual analysis modifications of q actions. property also the the the weights and synaptic states. which future improvement. improvement avoidance.............,..,,,,..']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","26it [01:35,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 26, training loss: 2.452610731124878\n"]},{"output_type":"stream","name":"stderr","text":["\n","27it [01:38,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 27, training loss: 2.116279363632202\n"]},{"output_type":"stream","name":"stderr","text":["\n","28it [01:42,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 28, training loss: 2.802558422088623\n"]},{"output_type":"stream","name":"stderr","text":["\n","29it [01:45,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 29, training loss: 2.519761085510254\n"]},{"output_type":"stream","name":"stderr","text":["\n","30it [01:49,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 30, training loss: 2.312804937362671\n","epoch 9, prediction loss: 3.086455821990967\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the impact discusses thely interacting dark matter ( interactions their interactions with focusing are be motivated from various detection indirect detection experiments.The u physics extensions of standard standard model ( sm) and been proposed to address the matter candidates d) candidates or whose as uly interactingacting neutral (ons ( wimps)  detection experiments have shrunk the parameter space of the models where neutralimps. with the visible world viaThe constrained of sm particles the model particles are encaps in the lagrangian approach. where twist of the dimensional effective operators constructed Thestrained on these higher are discussed from various data. estimate and the u models. The sensitivity',\n"," ' using usinginstein of are transit transit study have to properties of the populations.using key function is utilized for determining bayesian theorem theorem and extract parameters parameters. The method distribution is assumed as independent independent power lawlaw distributions in period and rad. The distribution that a single population population is made assuming assuming the distribution of this assumption is examined.order distribution focuses on multiple systems with examineszes the effects effects introduced radius and multipl. distribution used to on previous studies to utilizing planets by detection order. results show insight on the factors detection order. show distribution parameters functions this introduced the distribution distribution fun. to this. statistics are explored for to',\n"," ' the the ke discusses the modeling soft the from the keomult soft soft extract the data population parameters determine data. The study modeling presented each of planets according on the parameters and and each randomly to of detection based The probability parameters the population parameters are is a weak in the radius population around with due by a unique population planet and population population.-planet systems are also and comparison analysis. and that population dependence. forward model is from bayesian analysis shows compared and with that in the parameters due uncertainty.. best parametersiates between multiple- and systems and single-planet systems. showing the implications future studies of such period and radius']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","31it [01:53,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 31, training loss: 2.147129535675049\n"]},{"output_type":"stream","name":"stderr","text":["\n","32it [01:57,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 32, training loss: 2.307243824005127\n"]},{"output_type":"stream","name":"stderr","text":["\n","33it [02:00,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 33, training loss: 2.4632327556610107\n"]},{"output_type":"stream","name":"stderr","text":["\n","34it [02:04,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 34, training loss: 1.8973826169967651\n"]},{"output_type":"stream","name":"stderr","text":["\n","35it [02:07,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 35, training loss: 2.196584701538086\n","epoch 9, prediction loss: 3.049407720565796\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' to to primary discusses the applications of thes agents to are able to evaluate a agents from r agents.q agents can evaluate used in specific- specific problems. from for such as using multiple rewards and of state rewards, can enhance used to evaluate agents-.izing the actual of transitions- can on the like coordinates and velocities can enhance agents accuracy of qs agents.s agents can also multiple matching and value networks. evaluate agents values of. proposed between p brain cortex and pfc) hippocampus and and posterior cingulate cortex ( explored for the. proposed discusses that one of of q q cing',\n"," \" quasi quasi concept discusses the inter principles of quasi-symbolic agents qs)agents and quasi the inter with the learning ( r) agents.qiments conducted conducted to evaluate the performance of qs agents in solving lunar lunar-lander problem compared to the agents.q r agents, qs agents do not work al. do their behaviors and value networks by the agents' behaviors during train.q matching and in the of the vectors observed and the value network stores the induced by observed transitions.qs agents utilize the states, utilize their to reach them. the matching network. the r agent. identifying training amount of training,\",\n"," 'TheThe feature selection step involves the engineeringgorithm ( ga) is to select thoseets of curves vectors extracted curves and patches patches extracted are more against facial expression. The modified vector is used to select select the most robust curves from remove the features. The varying the value vector element the curves and patches can selected or omitted based depending reducing the rates. reducing the selection. the appro. fisher fisher analysis analysis.. The algorithmgorithm is to in this non dimensionaldimensional binary high-convex optimization process. with a high nsga-ii. elitism over individuals individuals healthy individuals..- feature assignments for the are are explained in section']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","36it [02:12,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 36, training loss: 2.7430968284606934\n"]},{"output_type":"stream","name":"stderr","text":["\n","37it [02:15,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 37, training loss: 2.4210031032562256\n"]},{"output_type":"stream","name":"stderr","text":["\n","38it [02:19,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 38, training loss: 2.224534273147583\n"]},{"output_type":"stream","name":"stderr","text":["\n","39it [02:22,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 39, training loss: 2.5293421745300293\n"]},{"output_type":"stream","name":"stderr","text":["\n","40it [02:26,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 40, training loss: 3.0577051639556885\n","epoch 9, prediction loss: 2.7021291255950928\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the ke discusses the impact for incompleteness due the planet occurrence rates due to transit multiplicity. The ke data typically planets in order of descending strength and but the detectability of transits experiences affected by the multiplicity.  modified for provided for determining the transit probability for multiple-planet systems by marginal the ke data.  distribution also the statistics affecting affect the radius and period distributions of each detection ord. text rate dataset includes radius from the cal ke surveyga the dr2,ga asteroseismolog. text model includes consistent with the studies but now includes an improved estimate of the multiplicity distribut. from average also',\n"," ' in in this paper, we augmentation method for lstm and k is is imbalanced network traffic classification is real traffic traces is proposed. The results was tested with a sampled datasets augmented datasets. and compared results show that the proposed approach outperforms thenn. terms of accuracy, recall, and f........dd,.dd,...ababab...,,....',\n"," ' in in index discusses theasipinear inequalities with aitycommity. withizing the index j sub acritical. is certain inequality and satisfied. critical in equality holds in case certain case.x....,,,,,ivalent,,,,,,,,,,,,,,,,,,,,,,,,,,ivalentivalent,,ivalent,,ivalentivalentivalentivalent,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","41it [02:30,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 41, training loss: 2.355659246444702\n"]},{"output_type":"stream","name":"stderr","text":["\n","42it [02:33,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 42, training loss: 2.5892393589019775\n"]},{"output_type":"stream","name":"stderr","text":["\n","43it [02:37,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 43, training loss: 2.251685857772827\n"]},{"output_type":"stream","name":"stderr","text":["\n","44it [02:40,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 44, training loss: 2.566481590270996\n"]},{"output_type":"stream","name":"stderr","text":["\n","45it [02:44,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 45, training loss: 1.9374005794525146\n","epoch 9, prediction loss: 3.295055389404297\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text. the improved version of the pointwise sparse domination principle established by the first author in The allows allows us obtaining singular singular assumptions on for a singular integral operator to admit a sparse domin......,,,,,,,,,,,,,,,,,,........,,.aware.,,,aware...,,,,,,,,,,,',\n"," ' the the t discusses the t- mumford-tate conjectures for surfaces s connected components of the gieseker moduli space that contain a product-quotient surf..,,...,,,,,,,antivalent,,,,,,...............able.',\n"," ' the the text discusses the behaviorogeneousization state of with the in surfaces on the section structure of theaus inThe equations are the types affecting as the properties, the sizes. determine insights descriptions for the the understanding the behavior. the..x and,,,,,,,,,,,ivalent,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","46it [02:48,  3.85s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 46, training loss: 2.244659662246704\n"]},{"output_type":"stream","name":"stderr","text":["\n","47it [02:52,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 47, training loss: 2.4068527221679688\n"]},{"output_type":"stream","name":"stderr","text":["\n","48it [02:55,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 48, training loss: 1.9840236902236938\n"]},{"output_type":"stream","name":"stderr","text":["\n","49it [02:59,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 49, training loss: 2.576726198196411\n"]},{"output_type":"stream","name":"stderr","text":["\n","50it [03:02,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 50, training loss: 2.506333112716675\n","epoch 9, prediction loss: 2.819835901260376\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a results on to the text dirichlet form on a bounded-chitz domain.The using theorem of the text is a by text result is the section is that proofhei matsuura theorem. which states that the regular closed of a continuous vers..........,,,,,,,,,,,,,,ableableableableableableableableableableableabeabeabeabawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareaware',\n"," ' using using study discusses on the multipl effects multipl the parameters parameters provided theoseismic data from, study of updated updated allows the radius measurements and, address thelier systems in the ga data we we values are tested against the ke dr25 cat. to of also from the curves and thus periods need on the data keks.. to positive are removed using the thes. with are planets with 500 days are considered. be contamination from when-icity effects are explored using a all the within in with a for on the and period cuts. when with higher positive are removed removed to accuracy order accuracy with detection detection multiplicity we in 7',\n"," 'TheThe en model ( the context is the en. modeling into state vector and action a inputs and the the next state.The this text, the network layer of a nodes is used to the text network.The is shown using the squared error regression each episode of random learning.. a ensemble learning rate of 0.0..........ad...,,,,.,,...adenaden...,,,aware.....,awareadenadenaware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","51it [03:07,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 51, training loss: 2.1001172065734863\n"]},{"output_type":"stream","name":"stderr","text":["\n","52it [03:10,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 52, training loss: 2.5589098930358887\n"]},{"output_type":"stream","name":"stderr","text":["\n","53it [03:14,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 53, training loss: 2.3551602363586426\n"]},{"output_type":"stream","name":"stderr","text":["\n","54it [03:17,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 54, training loss: 2.3655574321746826\n"]},{"output_type":"stream","name":"stderr","text":["\n","55it [03:21,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 55, training loss: 2.303895950317383\n","epoch 9, prediction loss: 3.00685715675354\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["['TheThe text algorithm is for thecv is is the image processing technique sur to to image point detection. which well in her bay.sur is is a local feature detector and descriptor that by theift. but with a in details.sur main is a blob detector based on the heian matrix to find points of int. the blobant of the heian matrix is usedized.sur determin is images from using blending the last image for performance and level detail detail and rendering in a final merging. The algorithm image image is as input input for the algorithm. the analysis. the drone moves forward. The.......',\n"," ' the the text discusses a new for the invisible qcd axion model without domain wall. with the heavy heavy heavy are present.The is is developed in the contextxiv:19012..... the 2018,2018............,ger,,,...,,fbfb,,,,,,,aware,,',\n"," ' in in text discusses a aff answer to the question of theodge is andoremical weight...12 is the weight of the. the is a eve for text also the. prove to t twists of the hodge struct. the that l is unimodula. text involves in a slightly weaker form of theorem theorem of is a proof involving involves similarrewise a primitive embedding and a hodge isometry on the transcendental lattice. text of v resultingodge is is2 new is the by the.k2.12, the weight of the ranks of h2 new and h is theoted by']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","56it [03:25,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 56, training loss: 2.1590826511383057\n"]},{"output_type":"stream","name":"stderr","text":["\n","57it [03:28,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 57, training loss: 2.2241051197052\n"]},{"output_type":"stream","name":"stderr","text":["\n","58it [03:32,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 58, training loss: 2.222480297088623\n"]},{"output_type":"stream","name":"stderr","text":["\n","59it [03:35,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 59, training loss: 2.3563082218170166\n"]},{"output_type":"stream","name":"stderr","text":["\n","60it [03:39,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 60, training loss: 2.6332132816314697\n","epoch 9, prediction loss: 2.2380170822143555\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' fraction fraction paper discusses numerical numerical of fractional power equations in time models. solving applications. as sub, biology or finance finance. The is on the fraction involving fractional power elliptic operators. numerical based the elements. quadlov subspace method. The approaches to solve fractional powerin-space reaction-diffusion equations are analyzed. in the integral and adaptively preconditioned lzos method. The accuracy also discusses theimatingations to fractionstation ellipt by their a new algorithm for on a to a pseudo-parabolic equation. solving fractional power elliptic operator.. is with a experiments. the results. the',\n"," 'TheThe goal aims to create the quad to camera to take images images from a parking parking lot and blend them to create a large image image. the entire parking. to approaches were used to first the boofcv library and image stitching algorithm and feature and and developing our new algorithm based on the opencv library and surf surf algorithm. The field was images images during certain points intervals during create the merging. The this field test, we image lot was divided into a 4x4 matrix matrix better the drone. movement.. algorithm was using images at different and then them images together each column, and then merging them columns together after The',\n"," ' the the text discusses the results related to the theory dir subsetets, andichlet forms, andotone class argument, andity, and domain,, and eigenfun, and, and finini theorem theorem.The words include the thatity, the dirichlet form, showing convergence of themma 1. proof. to le proofs. section also mentions the textification theorem. the principaln t. l. the textiteness of the*....,,......,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","61it [03:43,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 61, training loss: 2.4580767154693604\n"]},{"output_type":"stream","name":"stderr","text":["\n","62it [03:47,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 62, training loss: 2.3744218349456787\n"]},{"output_type":"stream","name":"stderr","text":["\n","63it [03:50,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 63, training loss: 2.4704458713531494\n"]},{"output_type":"stream","name":"stderr","text":["\n","64it [03:54,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 64, training loss: 2.508694648742676\n"]},{"output_type":"stream","name":"stderr","text":["\n","65it [03:57,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 65, training loss: 2.6458380222320557\n","epoch 9, prediction loss: 2.3091318607330322\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' this this e discusses a e userto-end e-health system with for includes molecular and electromagnetic wireless communications.The-body and are considered via a generic-assisted diffusion-based molecular communication system. while aomachransmissionters and receivers molecules.The specific node is be improve the link and The proposed model includes a-body, off-body communications. which a symbol of molecules schemes. different symbol intervals. each communication type. Theomachines/ as relay nodes. and nearly free and molecular. The proposed model includes a2out-off-body communications communications. aways. on communication. the system-health system.',\n"," ' har har text discusses the text of partial and graded posets. the order theory.The chain is a poset in every pair of elements is compar. and a graded poset is a poset equipped a rank fun.The the chainet is not explicitly weighted, the weight is implicitly the counting meas.The this, har. partial was the of order theory was published by one of the outstanding ten outstanding results in the editor-in-chief of the journal of are also a of a partial order, absolute order,......aware,,,.',\n"," ' sn sn text discusses that super is normalized normalized matching property. which that sn is indeed sperne. result achieved by the induction on. the normalized case is trivia.. the baseive step is the permutations from the copies. sn. The collapsing the n of the new network is constructed. satisfy the normalized matching cond. which to the conclusion that sn is indeed sperner. well satisfies normalized normalized flow property.............aware...']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","66it [04:02,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 66, training loss: 2.0915322303771973\n"]},{"output_type":"stream","name":"stderr","text":["\n","67it [04:05,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 67, training loss: 2.1472387313842773\n"]},{"output_type":"stream","name":"stderr","text":["\n","68it [04:09,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 68, training loss: 2.333247661590576\n"]},{"output_type":"stream","name":"stderr","text":["\n","69it [04:12,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 69, training loss: 2.228336811065674\n"]},{"output_type":"stream","name":"stderr","text":["\n","70it [04:16,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 70, training loss: 2.510141611099243\n","epoch 9, prediction loss: 2.2945303916931152\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses the classification of irregular with by theodge theory. specifically by the with irregular3 type. product modental part. The are the related the group of these surfaces and their conditions answers to the questions. certain conditions. The text also the the text of these surfaces is not not. that the state state of the art. also on the-quotients surfaces and show mod group theoretical properties. and well as those moduli spac. text obtained can used to prove that t- mumford-tate conjectures for these surfaces. text also the support of inspiration. provide further overview of the current state',\n"," ' double doubletic models have transit probability have double transit systems have presented establishedknown for on the inclination and, larger models models for larger multiplicity systems is more difficult. requires semi-analytic models. to simulating various semi-major axis to stellar radius ratios and looking 106 lines of sight to we probability of transit is calculated for address the distribution distribution of the non for transit transit probability is some specific semi-major axis value is created. this with other for the additional of otheroplanet period. to address this related to the order, the against a non-uniform method method is used to the period distributions. such',\n"," ' a a text discusses theuscule represent with the to the weight uq-crystals.The. weight uq-crystal b is min touscule if w w of w w distance w0 acts transitively the. thex and....,,,,,,,,,,,,.,,..,,,,,,,,,.....,,...,,,....,,ivalent,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","71it [04:20,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 71, training loss: 2.62408185005188\n"]},{"output_type":"stream","name":"stderr","text":["\n","72it [04:24,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 72, training loss: 2.4328088760375977\n"]},{"output_type":"stream","name":"stderr","text":["\n","73it [04:27,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 73, training loss: 2.390929698944092\n"]},{"output_type":"stream","name":"stderr","text":["\n","74it [04:31,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 74, training loss: 2.08152437210083\n"]},{"output_type":"stream","name":"stderr","text":["\n","75it [04:34,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 75, training loss: 1.7784050703048706\n","epoch 9, prediction loss: 2.591571569442749\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' tele tele text discusses the importance of time duration ratio ( emedicine communications for e communication delivery. theomachin. The text symbol slot partitioning ( crucial by the the user to-end symbol error rate ( The optimization algorithm is formulated for find the best performance in e between The optimization involves solving the symbol slot interval three of in types of communication links. The achieve the quasiconvex optimization problem, a quection optimization is formulated. on amc parameters and symbolr. the. The optimization is a in the ec transmission side. does of and robust. low complexity complexity. The.......',\n"," ' the the text discusses the thestation fractional power elliptic operator equations numerically. using equivalent local nonstationary initial value pseudo-parabolic problem. The such were the implicit backward and symmetrical euler method. while the paper introduces to the fourth-parameter family of three-level finite difference schemes for The fourth-order approximation scheme is developed by optimal optimal weight paramization The resultsical analysis and are supplemented by extensive computational experiments.....,,,,..',\n"," \" in in text discusses the-to-end communication error rate ( modeling the types links. such the molecular communication channel model and a diffusive environment. a and relay, and receiver nodes. The of molecules molecules is assumed by a maximum-a-posterior probability rule. the the transmitted distribution function is approximated by sim's rul. The orderpembol interference is ignored. the the of left to future work. The error error performance ( is also. the on- and and off-body communication channel. and the of the such the, motion of The-norm distribution off assumed to the best fitting distribution these-body communication\"]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","76it [04:39,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 76, training loss: 2.5897929668426514\n"]},{"output_type":"stream","name":"stderr","text":["\n","77it [04:42,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 77, training loss: 2.4716086387634277\n"]},{"output_type":"stream","name":"stderr","text":["\n","78it [04:45,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 78, training loss: 2.0600671768188477\n"]},{"output_type":"stream","name":"stderr","text":["\n","79it [04:49,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 79, training loss: 2.309959650039673\n"]},{"output_type":"stream","name":"stderr","text":["\n","80it [04:52,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 80, training loss: 1.891978144645691\n","epoch 9, prediction loss: 2.802016496658325\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' let let text discusses a conceptyl group of the certain ofoted w w.g by w..Thex....,,,,,,,,,,,,,,,,,,,,,,,ivalentivalentivalent,ivalent,,,,,,,,,ivalentivalentivalentivalentivalentivalent,,ivalent,,ivalentivalentivalent,,,,,,,,,,,,,ivalentivalent,,,,,,,,,,,,,,,,,,',\n"," ' the the text discusses the minimal domin1 theoremty singular for which the minimal assumptionsity conditions on the singular t. which the singular holds. is that the proof on the minimal hold similar unknown. discusses are they theorem dini cond can be relaxed to section also the minimal assumptions on t k yielding yield thewise sparse domin. text are in proofs and le the sectionmma. le. the. to the weak. also with showing that the the bounded extension of the t is to2 to itself if then bounded condition on hold for......,,,,',\n"," ' ch chorem discusses theic surfaces3 surfaces of ch ch to chow motives of surfaces. The also a proofposition of theow motives of surfacesic surfaces into aic and transcendental components. and by a comput. computations.The sectionogenical decomposition of theelian varieties with group action is also. with to a proof of the specific example.The section concludes with a discussion on the specific example in a product of singular algebraic k3 partner of the minimal between theers surfaces. ch resolutions. showing the importanceogenism between theental surfaces of............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","81it [04:57,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 81, training loss: 2.462651014328003\n"]},{"output_type":"stream","name":"stderr","text":["\n","82it [05:00,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 82, training loss: 2.662862777709961\n"]},{"output_type":"stream","name":"stderr","text":["\n","83it [05:04,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 83, training loss: 2.0894057750701904\n"]},{"output_type":"stream","name":"stderr","text":["\n","84it [05:07,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 84, training loss: 2.0484814643859863\n"]},{"output_type":"stream","name":"stderr","text":["\n","85it [05:11,  3.55s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 85, training loss: 1.905659794807434\n","epoch 9, prediction loss: 2.591002941131592\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' super super study discusses the sensitivity of the constraints on the matter pair d)- at including on the sensitivity to sensitivity to the momentum of d pair atom and/- electronron scattering. to suppressed of quarks in. is the need of detectingizing lepto- andic and electro boson b b-linic d particles at the proposed hadron coll ( lh) and discusses the need of studying the- to the-2 operators. The text is highlightszes the state effects of d- atom scattering cross dama data. derives the the- production channels at the proposed linear coll ( ilc)  study also the',\n"," ' j j j discusses the use theory of scalar-tensor theories f the j frame beyond focusing the importance of ill order time derivative terms in are ill-posednes. The, equations is shown that equations of motion can always reduced to second second-order-in-time form as the original e frame formulation is well posedposed. The inverse transformation from the j frame back the e frame is not be possible for all field values in the, but it fully invertible transformation is obtained by vector-tensor theories by a redefinition of the vector f. text motivation is a better understand spontaneous scalarization and its general',\n"," ' deep deep learning ( potential to high stakesstakes decision problemsmaking is still challenging for it influence may uncertain. extensive test. Theing deep learning agents to high high may lead in critical failures. in methods have been proposed to analyze the internal mechanisms of deep learning agents, provide their performance-making.. however such studies have focused on feedability of feedforward deep learning agents we studies explored interpret issue of more learning. well. in majority-hoc interpretability of deep learning agents can be used to predict and prevent potential. but it their is deep learning agents is a agents. in potential approach can to provide the in reinforcement learning agents.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","86it [05:15,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 86, training loss: 2.4397315979003906\n"]},{"output_type":"stream","name":"stderr","text":["\n","87it [05:19,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 87, training loss: 2.774035692214966\n"]},{"output_type":"stream","name":"stderr","text":["\n","88it [05:22,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 88, training loss: 2.601982355117798\n"]},{"output_type":"stream","name":"stderr","text":["\n","89it [05:26,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 89, training loss: 2.5388505458831787\n"]},{"output_type":"stream","name":"stderr","text":["\n","90it [05:29,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 90, training loss: 2.2669661045074463\n","epoch 9, prediction loss: 2.153817653656006\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the we on thet and algebra and the contextil algebra. 16 55.2........ivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalentivalent,,,,ivalentivalentivalentawareawareivalentawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareawareivalentivalentivalentivalentivalent,,ivalentivalentivalent',\n"," ' to to novel algorithm is introduced to this paper to address the invari invariariant face recognition. that the 3d shape of the nasal. The algorithm isages a robust anding algorithm, a feature space, discriminative feature descriptors and feature feature selector. The results is applied on three well face datasets, fr that results. both and verification scenarios. The, the algorithm achieves a ranks higher than previous nasal region-based algorithms. outper outperformed other 3d holistic and multi-modal approaches. algorithm can performance for to face in other alignment, low dimensionaldimensional face recognition and pattern pattern rejectio research on are the',\n"," ' high high high discusses the method of the order difference schemes for solving thestationary cauchy typetype ellipt. to theal power elliptic operator. The order approximations are used to approximate the time dependence of the solution. while the elliptic operator is approximated by the finite element sche. The. stability conditions are given for the-level discrete schemes with weight weight parameter.The order accuracy is proved for the symmetrical crankank-nicelsonson type scheme. The family of three-level symmetrical discrete schemes is constructed. investigated. and on the smooth solution. The condition on the first time level are computed by the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","91it [05:34,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 91, training loss: 1.7586907148361206\n"]},{"output_type":"stream","name":"stderr","text":["\n","92it [05:37,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 92, training loss: 1.9473106861114502\n"]},{"output_type":"stream","name":"stderr","text":["\n","93it [05:41,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 93, training loss: 2.163395404815674\n"]},{"output_type":"stream","name":"stderr","text":["\n","94it [05:44,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 94, training loss: 2.2779600620269775\n"]},{"output_type":"stream","name":"stderr","text":["\n","95it [05:47,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 95, training loss: 2.254495859146118\n","epoch 9, prediction loss: 2.219959259033203\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["['TheThe comb discusses the comb of a7 highest weight elements from decom the7 highest weight elements. a decom computation.. The textposition into e7 crystals is multiplicity freefree is discussed to the comb that to the proof of proposition conjecture in The proofinatorial r-matrix must used to its ability to map classical components to classical components. leading the weights are k elements are k. computed. a function. The is is as a proof towards proving a conjecture regarding proving a construction of a7crysta value. the certain manner.....        ',\n"," ' the the j discusses the j of generalizations of spontaneousar- andensor theories where sts), the j frame.. where the scalar field replaced with other fields and couplings can depend on derivative. The study came from the that spontaneous tensoriz, where are most naturally defined in the canonical frame where The are be applied to any generalization of on a conformal scaling of the metric in the matter action by first highlights vector the scalar field a vector field the-tensor theories, vector to the-based spontaneous scalarization arezing the equations of interesting time derivative terms in no renders orderorder equations',\n"," ' in in text results a model is three datasets datasets shows that the method of sampling in able in handling thebalanced datasets. The results like to precision1 measure, precision and and recall. The accuracy is performance on compared with sampling in and the in precision and in to higher false predictions predictions and The accuracy accuracy of the model is also than sampling in with a improvement in precision and recall, and confusion accuracy. model also that accuracyiz accuracy accuracy decrease in false negative. to the.........']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","96it [05:52,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 96, training loss: 2.5974864959716797\n"]},{"output_type":"stream","name":"stderr","text":["\n","97it [05:55,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 97, training loss: 2.53513765335083\n"]},{"output_type":"stream","name":"stderr","text":["\n","98it [05:59,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 98, training loss: 2.2537646293640137\n"]},{"output_type":"stream","name":"stderr","text":["\n","99it [06:02,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 99, training loss: 2.1265676021575928\n"]},{"output_type":"stream","name":"stderr","text":["\n","100it [06:06,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 100, training loss: 2.3812758922576904\n","epoch 9, prediction loss: 2.44553279876709\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in continuity discusses the continuity of the heat kernels of the reflection brownian motion ( a general lipsipschitz domain. The is that existence of theolev typetype inequality on a domains like to the presence of a cusp at inf. The text also that the heat kernel of reflection reflectionian motion on a uniform domains are continu. and not heat domainsipschitz domains is not. uniform. The text also the estimates estimates to the estimates to prove that of local the local measure on the boundary of a lipsipschitz domain is The is important in the transformation theory of theov processes. its the-spectral independence',\n"," ' we we study discusses the study of a ensemblene affinvariant ensemble sampl to explore 13 sets to The bayesian framework is linear space uniform priors is used toThe toors are used for the 13 ofbr and pbr. on the distribution sample. casc prior is that f must must be larger than f. avoid trunc. prior is is for larger multiplicity systems to be more common than smaller multipl.....,,,,,,,,......',\n"," ' christ christ detection discusses the the eff can be improved for as considering artificial planet signals into the christ pixels of the field stars.The doing the light light curves with the standard detection pip, the recovery fraction can be assessed. producing a probability function based on transit mes.to-noise ratios. mes))  christ of detection order on recover is discussed. with the order defined by the variable m. the christ from split into injection with and after the days. and well 200 time the distributions begin significantly. is made on the with 2 or discovered......g...gg,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","101it [06:10,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 101, training loss: 1.9756919145584106\n"]},{"output_type":"stream","name":"stderr","text":["\n","102it [06:14,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 102, training loss: 2.183237075805664\n"]},{"output_type":"stream","name":"stderr","text":["\n","103it [06:17,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 103, training loss: 2.469545602798462\n"]},{"output_type":"stream","name":"stderr","text":["\n","104it [06:21,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 104, training loss: 2.0179169178009033\n"]},{"output_type":"stream","name":"stderr","text":["\n","105it [06:24,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 105, training loss: 2.2157793045043945\n","epoch 9, prediction loss: 2.670020580291748\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["['TheThe aim project that to come an image processing algorithm that a the university of bridgeport parking lot using using two images. with a stable device like a good camera. such an ar-drone. The main camera of the drone will images imagesapped images which and can then into the algorithm that. Thecv and boofcv are were used to developing processing. and thecv being java interface being used primary component of Theofcv is a-level image processing capabilities. bo low example processing algorithm.. whiching images the open goal main. The stitching refers combining a 2d geometric transform which minimize two images into and a like',\n"," ' the the keism we in this study utilizes applied to derive the occurrence rate parameters for planets orbiting gk dwar stars. The from the final ke data dr25 and including planet radius measurements from theks and ga and, and corrected detection eff for multiple-planet systems are used. The resulting includes on previous poisson process likelihood function used includes a modifiedesian framework to using anMC. The resulting are that values for the occurrence of including a in the best fitfit model occurring at p times of novel feature of the ability to extract exoplanet multiplicit through through the f parameter. indicating the probability of a system having at least m',\n"," 'TheThe potential discusses the potential of the patches and curves for expression expressiond face recognition. The novel five-step algorithm is presented. with with aly of the nose tip location segmenting and aligning the face and and thenpping the nasal region. The very anding algorithm is seven keypoints on the nasal reg. The genetic algorithm-based feature selector is the patches and curves over different facial expressions. The algorithm provides the ranks ranks on the datasets. requiring alignment or denoising steps. is with with only one sample per subject per the gallery and and does not require a training step for theing. The....']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","106it [06:29,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 106, training loss: 2.186505079269409\n"]},{"output_type":"stream","name":"stderr","text":["\n","107it [06:32,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 107, training loss: 2.5530683994293213\n"]},{"output_type":"stream","name":"stderr","text":["\n","108it [06:36,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 108, training loss: 2.9039273262023926\n"]},{"output_type":"stream","name":"stderr","text":["\n","109it [06:39,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 109, training loss: 2.1941123008728027\n"]},{"output_type":"stream","name":"stderr","text":["\n","110it [06:43,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 110, training loss: 2.2513177394866943\n","epoch 9, prediction loss: 2.9653031826019287\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the text discusses the symmetry of the electrodynamics theory under theity transformation. considering on the drangian transformations. focusing focusing theion and dilaton fields.The is the behaviorance of the equations under equations of motion and energy-momentum tensor under the-duality transformation The transformationsetries involving transformations involving the theory are discussed discussed. including as the sl of the of type i super superstring theory and the symmetry of of theitudes involving the-duality. isves into the implications of the involving equationsitudes under the-duality transformations. focusing the need of the of the-duality',\n"," 'TheThe datasetsd datasets are used to evaluate the face recognition algorithm proposed thegc,bosphorus 3 and the-3de. The proposedgc dataset is 5 with 5 sets expressions and with the bosphorus dataset includes samples of six prototypic expressions. The b was performanceing accuracy and accuracy were evaluated using and that accuracy for thegc samples to the samples and The robustors were inabor wavelets, the a scale, for each recognition.. The results was a accuracy rates for the b al and the samples. with aness for the-neutral samples. probes. Theisons results was the face is also. showing',\n"," ' this this 3 presents a novel surface for provides on the the 3d nasal region for human identity authentication and verification purposes The is the importance of the 3 for surface features for expression robust andust recogn. includinging previous approaches and providing high discrim of discriminant strength and The proposed is a landmarksing and feature extraction techniques and multi-resolution gabor wavelets to The isforms previous approachesd nose recognition algorithms by achieves superior performance compared with face that the whole facial dom. The, the proposed is a such as improved denoising and and improved pose pose correct. The features are achieved in section text. theing and feature extraction and and']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","111it [06:47,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 111, training loss: 2.286370277404785\n"]},{"output_type":"stream","name":"stderr","text":["\n","112it [06:51,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 112, training loss: 2.032064437866211\n"]},{"output_type":"stream","name":"stderr","text":["\n","113it [06:54,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 113, training loss: 2.5793564319610596\n"]},{"output_type":"stream","name":"stderr","text":["\n","114it [06:57,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 114, training loss: 2.356048107147217\n"]},{"output_type":"stream","name":"stderr","text":["\n","115it [07:01,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 115, training loss: 2.2555739879608154\n","epoch 9, prediction loss: 2.636133909225464\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses a simplified of theorem a, showing that variation of the proof of in theorem a. The being between the proofs proofs, they. proof is provided. reader. The text is a a common ingredient of both proofs. and the cases. and providing a partition. satisfy the desired result. The section to a proof of a specific--sparse family ofqj such The text is focuses the model on - onymund operator.. the cal version. The text is with showing the similarmma to proving the proof. theorem a  The............',\n"," ' in in this context of medical care applications, high communication links between crucial for the end-toendend telemedicine sy. in delivery, molecular communication play crucial building the-nano-medical applications. in paper aims the e-to-end communication link consisting electromagnetic electromagnetic and molecular communication. based closed-form expression for presented for the e error probability ( the e system system. The optimization method is formulated with minimize the bit error rate of the the optimal symbol duration for the time from. numerical proposed is solved by an iterative algorithm based on the bisection met.umerical results show that the proposed method ob ob',\n"," ' ke ke ke mission has increased our understanding of the around sun-like stars.The final data release dr dr25, provides all on to the failure of two reaction wheel. providing the end end of the primary phase of Theort are made to quantify the frequency of properties of planets systems and with the on the with earth-like proper. The....,,,,,,,,,,,,,,,,,,,,..)..........,,iviviviviviviviviviviviv,,,,,,,.']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","116it [07:06,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 116, training loss: 3.047443389892578\n"]},{"output_type":"stream","name":"stderr","text":["\n","117it [07:09,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 117, training loss: 2.3671491146087646\n"]},{"output_type":"stream","name":"stderr","text":["\n","118it [07:12,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 118, training loss: 2.3816189765930176\n"]},{"output_type":"stream","name":"stderr","text":["\n","119it [07:16,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 119, training loss: 2.2100939750671387\n"]},{"output_type":"stream","name":"stderr","text":["\n","120it [07:19,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 120, training loss: 2.652463674545288\n","epoch 9, prediction loss: 2.9004101753234863\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text result of in this section is that multiplicity freereeness of the decom. this labeling labeling convent. which well by section 2. proof7 crystals b are be decomosed into a le subalgebra of type a6. a multiplicity freefree manner. and by a computation. a the 1 using the and adding loops to everyices and and adding the composition graph g, we is shown that the crystal b is type e. a multipl rule. the multipl m of x x. proofposition is multipl proven by amma. leabeling the fundamental weight. and leading in a multiplicity',\n"," ' the the text discusses the concept of a - andbgorithmbrir. with the specific of. and is of a text structure of a electron of the individual bundles.. sectionorphic of the structuregebroid are determined. with the importance. the the behavior structure of the system bundle.x.........igenigenigenigenigen,,,,,,,,',\n"," ' in in e discusses with the adaptive of the e -to-end communication link consisting electromagnetic and molecular communications is conducted. The closed-form expression for the e error probability of concatenation of molecular two channels was derived. The optimization problem was at minimize the e error probability was conc system was formulated to determine the symbol durations for both molecular of communication. The reveal that an adaptive system must necessary to achieve the minimum bit error rate and optimal performance for the e-to-end communication.....,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","121it [07:24,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 121, training loss: 2.9543399810791016\n"]},{"output_type":"stream","name":"stderr","text":["\n","122it [07:27,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 122, training loss: 2.0635879039764404\n"]},{"output_type":"stream","name":"stderr","text":["\n","123it [07:31,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 123, training loss: 2.2110655307769775\n"]},{"output_type":"stream","name":"stderr","text":["\n","124it [07:34,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 124, training loss: 2.2277486324310303\n"]},{"output_type":"stream","name":"stderr","text":["\n","125it [07:38,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 125, training loss: 2.328855514526367\n","epoch 9, prediction loss: 2.7153618335723877\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' eccentric eccentric eccentric discusses the eccentricity into the model system is enhance the detection efficiency The is the eccentricity models for including the modified gamma distribution used to a beta distribution used The from that significant differences between theity between the and multi-planet systems. the same & mur eccentric., applying with the eccentricities reveals significant in bias is theity occurrence using leading multi-planet systems producing more low eccentricity detections than significance suggest these differences between the empirical ofation of detection eff is crucial for eccentricity occurrence measurement. evidence for needed to determine if these populationsity populations exist between the and multi-planet systems.',\n"," ' in in text discusses the text algebra of type an, whichoted sl sln+ is the to the graphs.. text discusses the all n-colored edge in the crystal graph. also mentions the the decomposition of the 4 is multiplicity-fre.....,,,,,,,,,,,,,,..,,,,able,,,,aware,,,',\n"," ' boundary boundary this paper, we boundary discusses the boundary of boundary boundary value problem for the fractional power of the power power.The is the boundary to solvingimating boundary boundary by the finite of finite finite element method.x boundary boundary,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","126it [07:42,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 126, training loss: 2.057710647583008\n"]},{"output_type":"stream","name":"stderr","text":["\n","127it [07:46,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 127, training loss: 2.4954497814178467\n"]},{"output_type":"stream","name":"stderr","text":["\n","128it [07:49,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 128, training loss: 2.4784634113311768\n"]},{"output_type":"stream","name":"stderr","text":["\n","129it [07:53,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 129, training loss: 1.5827852487564087\n"]},{"output_type":"stream","name":"stderr","text":["\n","130it [07:56,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 130, training loss: 2.7014617919921875\n","epoch 9, prediction loss: 3.2670979499816895\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' with with traffic is a for the ever amount volumes in withifying the patterns and applicationsifying applications is two tasks in with traffic tracingifications ( nt)) have classify anomalies in classify applications for however they methods have shown. port on ports in lack.. their. ingorithmms have these classification classification have promise in they methods for however thebalanced datasets is networks-scale networks datasets challenging challenging for deep. f.. inmentation is have machine learning have such as artificial artificial data for are address these imbalance issues, novel approachmentation method is k dataensity andimation ( kde) and lestestTerm memory ( lst',\n"," ' in in text discusses a examples of the admitting admit thewise sparse domin. The text discusses the the operators bounds can known known. but the unified approach simplified approach to provided to on theoremore 1. its variant. The results are from from previous results. consideringi l and sheldy ombrosi. and the improvements provided in section.. text text is the the text admits of weak type. to theorem 1. and a specific refined result with by section slightly case. by.....,,,',\n"," ' the the current discusses the impact of the matter ( d)ther density using using the thermally averaged andaged annihilation- cross- for The current compare the cross-averaged annihilation cross- for f operators candidates including compare the methods to compute the lower density constraint The direct such such as dermil-abs, hess are are sensitive to the types candidates.ihilation cross- are various types candidates are computed. pair with le leptons and photons. The results also discusses the on theider experiments to these operators for the on theh.. text also on the detection experiments involving d particleselectron scattering delastic']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","131it [08:01,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 131, training loss: 2.644343137741089\n"]},{"output_type":"stream","name":"stderr","text":["\n","132it [08:04,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 132, training loss: 2.5430421829223633\n"]},{"output_type":"stream","name":"stderr","text":["\n","133it [08:08,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 133, training loss: 2.5514063835144043\n"]},{"output_type":"stream","name":"stderr","text":["\n","134it [08:11,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 134, training loss: 2.088275194168091\n"]},{"output_type":"stream","name":"stderr","text":["\n","135it [08:15,  3.58s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 135, training loss: 2.7143287658691406\n","epoch 9, prediction loss: 2.7791616916656494\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the study: a study of ant antichain a a pos connected set. aet ) and no two elements are compar.The. and and..,,,,,,,,,,,,,,,,,,,ivalent,,,,,,,,,,,,,,,,,,,,,,,,,,,ivalentawareawareivalent,awareawareawareawareawareawareawareawareawareawareawareawareawareaware,awareawareawareaware,,,,,,,,,,,,,,,,,,,,,',\n"," ' abstract abstract concept on the concept of the of abstract u. the, on theq-crystals. a abstract on the e 7.kin diagram. The is the concept between regular and seminormal abstract crystals and abstract general abstractq-crystals. concept also the conceptor product convention for the tens for defining abstract crystal. be a as a uq-crystal.. a u uq-mod..,,,,,,,,,,,,........',\n"," ' splitting splitting text discusses discusses on the splitting of double vector bundles in the context of splitting to discusses to the fields. including well in section text...42x text.......,,,,antant,,,ivalentivalentawareawareawareawareawareawareaware,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","136it [08:19,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 136, training loss: 2.7141237258911133\n"]},{"output_type":"stream","name":"stderr","text":["\n","137it [08:23,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 137, training loss: 2.1459381580352783\n"]},{"output_type":"stream","name":"stderr","text":["\n","138it [08:26,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 138, training loss: 2.3290514945983887\n"]},{"output_type":"stream","name":"stderr","text":["\n","139it [08:29,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 139, training loss: 2.5805516242980957\n"]},{"output_type":"stream","name":"stderr","text":["\n","140it [08:33,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 140, training loss: 1.7553966045379639\n","epoch 9, prediction loss: 2.921090841293335\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the boundary discusses the boundarydimensional haddorffme on the to the the boundary boundary local time of the.The section also the naotoaka kajino for the comments on the proof. lema.............ad.............,,......,,,aware..',\n"," ' bo bo boofcv library has image stitching algorithm, the some points features and findingly finding a 2d transform using findingating them key points between the, and then a robust fitting to to finding changes transformations. as rotation. The, when we to stitch more result image with a third image, the will. the result will tries the black background. the image process. to distortion is caused by the in theofcv. so to a images. stitching more than two images. to avoid this issue we algorithm algorithm was implemented, openc. find this distortion issue by theofcv. translation. to..x..',\n"," ' in in comb discusses theing the., from the decom of the. the. The using the certain approachinatorial approach, we section theorem,, proven to provepose the into i0,2-crystals.....,,,,,,,,,,,,,,,,,...adenadenadj.,,,aware']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","141it [08:38,  3.86s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 141, training loss: 1.8627605438232422\n"]},{"output_type":"stream","name":"stderr","text":["\n","142it [08:41,  3.70s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 142, training loss: 2.4351935386657715\n"]},{"output_type":"stream","name":"stderr","text":["\n","143it [08:44,  3.63s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 143, training loss: 2.2183353900909424\n"]},{"output_type":"stream","name":"stderr","text":["\n","144it [08:48,  3.59s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 144, training loss: 2.1888747215270996\n"]},{"output_type":"stream","name":"stderr","text":["\n","145it [08:51,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 145, training loss: 2.3953914642333984\n","epoch 9, prediction loss: 2.1498019695281982\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' the the effects discusses the effects of mutual inclination on the k recovery for The study recovery study was not account for mutual multiplicity planet. did did not account mutual incl. The planets were created with a impact parameters from study the impact parameters mutual inclination. detection eff. The impact was at systems impact in impact parameters for recovered planet system with known planet.. mutual inclinations can cause certain planets to ge avoid transit compleometrically.......,,,,,....',\n"," ' the the text discusses a results test of the modelogenized model of a perforated plate of the reissner-mindlin typ. The impact is to compare responses responses of the homogenized model model with the of the associated 3d elastic structure with Theations boundary conditions and loading functions are used to the homogenized model. where the aimd elastic represented by a plate model described as a 2d structure. The deflections are computed for the models. the dynamic of the 3d elastic and usingiscale simulations of the plat model The influence of the compliance on the loss in the waveguide is discussed. The influence',\n"," ' the the text discusses a detailed overview of theson sld. a on the only and in the text. also as a reference reference for understanding the concepts in thei geometryometry. the analysis.x,.......igenigenigenigenigenigenigenigenigenigenigenigenigenigenigen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","146it [08:56,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 146, training loss: 2.380974054336548\n"]},{"output_type":"stream","name":"stderr","text":["\n","147it [08:59,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 147, training loss: 2.5809226036071777\n"]},{"output_type":"stream","name":"stderr","text":["\n","148it [09:03,  3.64s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 148, training loss: 2.1016173362731934\n"]},{"output_type":"stream","name":"stderr","text":["\n","149it [09:06,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 149, training loss: 2.59973406791687\n"]},{"output_type":"stream","name":"stderr","text":["\n","150it [09:10,  3.56s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 150, training loss: 2.390251874923706\n","epoch 9, prediction loss: 2.959165334701538\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' 25 25 texter - involves a method to to measuringson toolds to with involves used in a, a functions. involves the the equations of a basis. create the. solving the results.x method,,,,,,igen,,,,,,,,,',\n"," ' the the ke discusses the impact of detection detection of represent the detection eff of the ke mission for The grid is created into 100,000 regions in period and radius spac and for region is divided in in log space for period and radius. all each are assigned m based on the order. The probability order is are the for detecting multipleoplanets within each detection within The probability described repeated for each of. the detection order grids. The probability efficiency maps for the effects of limbity and limb the new function for account mis mis transits. Thepreating between made to determine the probabilities for different detection orders. The probabilities are created using higher multipl',\n"," ' landmarks landmarks proposed discusses a novel- algorithm algorithm landmark landmarking algorithm for the recognition. The algorithm involves apping the face and using median filtering and medianampling and image and anding it dela and and thening the three to crop the nasal region. Themarksing is on a minima detector operator isative algorithm. remove landmarks landmarks in the nasal region. such as the nasalnasale and sub corners. Thelieriers are removed using aative methods. remove the selectioning. algorithm is to reduce identify landmarks al such maintaining redundant parts. the face............']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","151it [09:14,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 151, training loss: 2.3424668312072754\n"]},{"output_type":"stream","name":"stderr","text":["\n","152it [09:18,  3.71s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 152, training loss: 2.440662145614624\n"]},{"output_type":"stream","name":"stderr","text":["\n","153it [09:21,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 153, training loss: 2.8145358562469482\n"]},{"output_type":"stream","name":"stderr","text":["\n","154it [09:25,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 154, training loss: 2.2725579738616943\n"]},{"output_type":"stream","name":"stderr","text":["\n","155it [09:28,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 155, training loss: 1.9650083780288696\n","epoch 9, prediction loss: 2.3413336277008057\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["[' in in text discusses the but/ extensions of the theorem theorem of point on the specific precise version of pointwise sparse domination 7. The text of the theorem result compared the original theorem is that. and the is used how the theorem can used in a applicationsorems. text also mentions a use of the text to a multilinear cas. and the the results.essary changes in the proof are noted out. and the the original idea. the text theorem........',\n"," ' the thefaces diffusion and willmore flows are geometric evolution equations that describe the motion of hypersurfaces in eidean space. The surface velocity of evolving surfaces is determined by purely geometric quant. while the mean curvature being in the flows. while the willmore flow additionally depends upon gauss curvature. The these studies have on compact hypersurfaces, these paper considers uniformly regular hypersurfaces. which non-compac surfaces. The utilizing the study of uniformly larger class of manifolds, we study presented to the study research of geometric flows on non-compact manifolds. The study relies based by the theory of continuous maximal',\n"," ' in in study study in this paper is more 70 gigabytes of real traces traces from the campus of amirkabir university of technology. which of more and tcp links. Theows are identified using n n sourcesource dpi tool n nd.. which the classes of applications from for more 50 gigabytes of data. including more.,000,. The percent of these flows were used for training and while the rest are test dat The dataset includes 90 total of applications classes and including more classes of more common than The dataset also a imbalance feature with more 83 percent of the dataset consisting of 4 cl.dpI, the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","156it [09:33,  3.87s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 156, training loss: 2.0684163570404053\n"]},{"output_type":"stream","name":"stderr","text":["\n","157it [09:36,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 157, training loss: 2.616407871246338\n"]},{"output_type":"stream","name":"stderr","text":["\n","158it [09:40,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 158, training loss: 2.6192331314086914\n"]},{"output_type":"stream","name":"stderr","text":["\n","159it [09:43,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 159, training loss: 2.0394814014434814\n"]},{"output_type":"stream","name":"stderr","text":["\n","160it [09:47,  3.57s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 160, training loss: 2.752610683441162\n","epoch 9, prediction loss: 2.4720458984375\n","\n","prediction text:\n"]},{"output_type":"display_data","data":{"text/plain":["['TheThe text discusses the textence of doubleb-algebroid structures on d double lie algebroid and horizontal or vertical differentials on two of the threeil algebras and a well as a gerstenhaber bracket on the th. also discusses the menzie s definition of a double lie algebroid is equivalent to compatibilities between two such structures on any one the three weil algebras.....,,,,,.,',\n"," ' computer computer proposed presents a method called d map Maker using dmc), utilizes computer vision algorithm to create create a by stitching together video information captured by a d. camera camera. The proposed utilizes the speeded up robustotic features method to detect the points for each image frame. identify the the points between frames. maximizing the determinant of a heian mat. The proposed points are identified to create together two by and in a st creation. some from the external environment. The...,,,adad,    dddd',\n"," ' error error error results to that performance of the proposed e toto-end error sy for diff diffusive environment like blood. The channel coding is considered for The performance probability performance analyzed as on the parameters like including location, and at, and symbol velocity. The analyzing the parameters, the performance error probability ( ber) is be improved. The trade-off between the conversion and channel rate efficiency also. where the trade value-to-end ber e2e) berert performance when the the energy molecular channel ( dmc) and errorstatic ( ec).. the velocity can the minimum2e berery performance increased increased the']"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","161it [09:51,  3.88s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 161, training loss: 2.5214390754699707\n"]},{"output_type":"stream","name":"stderr","text":["\n","162it [09:54,  3.72s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 162, training loss: 2.4456260204315186\n"]},{"output_type":"stream","name":"stderr","text":["\n","163it [09:58,  3.65s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 163, training loss: 2.3607988357543945\n"]},{"output_type":"stream","name":"stderr","text":["\n","164it [10:01,  3.60s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["epoch 9, batch 164, training loss: 2.369572639465332\n"]},{"output_type":"stream","name":"stderr","text":["\n","165it [10:05,  3.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["epoch {}'s average training loss: {} 2.3610765507726956\n","epoch {}'s average verification loss: {} 2.678419128060341\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [1:42:14<00:00, 613.46s/it]"]},{"output_type":"stream","name":"stdout","text":["The checkpoint model is saved after finishing epoch {epochi}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["num_epochs =10\n","total_train_loss, total_val_loss, total_train_rouge, total_val_rouge = [], [], [], []\n","torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n","best_val_loss = float('inf')\n","#Declare variable for storing the checkpoint\n","checkpoint_filename = \"LED_model_checkpoint.pt\"\n","patience = 3\n","\n","for epochi in tqdm(range(num_epochs)):\n","    val_batch_data_iter = iter(val_data_loader)\n","    train_loss, train_rouge1, train_rouge2, train_rougeL = [], [], [], []\n","    val_loss, val_rouge1, val_rouge2, val_rougeL = [], [], [], []\n","    for idx, data in tqdm(enumerate(train_data_loader)):\n","        ids = data['input_ids'].to(DEVICE)\n","        am = data['attention_mask'].to(DEVICE)\n","        gam = data['global_attention_mask'].to(DEVICE)\n","        labels = data['labels'].to(DEVICE)\n","\n","        # freeze all the layers except the last layer lm_head\n","        model_action.model.train()\n","        for parameter in model_action.model.parameters():\n","            parameter.requires_grad = False\n","        for parameter in model_action.model.lm_head.parameters():\n","            parameter.requires_grad = True\n","        model_action.model.final_logits_bias.requires_grad = True\n","\n","        # output = model_action.model(input_ids = ids, attention_mask = am, labels = labels, global_attention_mask = gam, use_cache = False)\n","        output = model_action.model(input_ids = ids, attention_mask = am, global_attention_mask = gam, labels = labels, use_cache = False)\n","\n","        torch.device('cpu')\n","        loss = output.loss\n","        logits = output.logits\n","\n","        print(\"epoch {}, batch {}, training loss: {}\".format(epochi, idx, loss.item()))\n","        p_text = model_action.convert_logits_to_text(output.logits)[1:]\n","        e_text = model_action.convert_tokens_to_text(labels)\n","        model_action.log_generated_summary(epochi, e_text, p_text, f\"training batch:{idx}\")\n","\n","        rouge1, rouge2, rougeL = model_action.calculate_rouge_scores(p_text, e_text)\n","        train_rouge1.append(rouge1)\n","        train_rouge2.append(rouge2)\n","        train_rougeL.append(rougeL)\n","\n","        # Backward and optimize\n","        model_action.optimizer.zero_grad()\n","        train_loss.append(loss.item())\n","        loss.backward()\n","        model_action.optimizer.step()\n","\n","        # evaluate once every 20 mini-batches\n","        if idx > 0 and idx % 5 == 0:\n","            val_batch_data = next(iter(val_data_loader))\n","\n","            # model. eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode. torch. no_grad() impacts the autograd engine and deactivate it.\n","            model_action.model.eval()\n","            with torch.no_grad():\n","                val_data = next(val_batch_data_iter)\n","                val_ids = val_data['input_ids'].to(DEVICE)\n","                val_am = val_data['attention_mask'].to(DEVICE)\n","                val_gam = val_data['global_attention_mask'].to(DEVICE)\n","                val_labels = val_data['labels'].to(DEVICE)\n","                val_output = model_action.model(input_ids = val_ids, attention_mask = val_am, labels = val_labels, global_attention_mask = val_gam, use_cache = False)\n","\n","            torch.device('cpu')\n","            vloss = val_output.loss.item()\n","            val_loss.append(vloss)\n","\n","            print(\"epoch {}, prediction loss: {}\".format(epochi, vloss))\n","            # The first word is always a repeat, so delete it.\n","            pred_text = model_action.convert_logits_to_text(val_output.logits)[1:]\n","            exp_text = model_action.convert_tokens_to_text(val_labels)\n","            model_action.log_generated_summary(epochi, e_text, p_text, f\"verification batch:{idx}\")\n","            rouge1, rouge2, rougeL = model_action.calculate_rouge_scores(pred_text, exp_text)\n","            val_rouge1.append(rouge1)\n","            val_rouge2.append(rouge2)\n","            val_rougeL.append(rougeL)\n","            print(\"\\nprediction text:\")\n","            display(pred_text)\n","\n","    total_train_loss.append(train_loss)\n","    total_val_loss.append(val_loss)\n","    avg_train_loss = np.mean(train_loss)\n","    avg_val_loss = np.mean(val_loss)\n","    avg_train_rouge = [np.mean(train_rouge1), np.mean(train_rouge2), np.mean(train_rougeL)]\n","    total_train_rouge.append(avg_train_rouge)\n","    avg_val_rouge = [np.mean(val_rouge1), np.mean(val_rouge2), np.mean(val_rougeL)]\n","    total_val_rouge.append(avg_val_rouge)\n","    model_action.log_metrics(epochi, avg_train_loss, avg_val_loss, avg_train_rouge, avg_val_rouge)\n","    print(\"epoch {}'s average training loss: {}\", np.mean(train_loss))\n","    print(\"epoch {}'s average verification loss: {}\", np.mean(val_loss))\n","\n","    # The following uses Sudha's code to stop training and save checkpoint when the val loss improves\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        epochs_no_improve = 0\n","        model_action.save_model_checkpoint(checkpoint_filename)\n","        print(\"The checkpoint model is saved after finishing epoch {epochi}\")\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve == patience:\n","            print(f\"Early stopping triggered.\")\n","            break\n","\n","# save running result for evaluation\n","running_res_folder = project_path + \"/Running_result\"\n","if not os.path.exists(running_res_folder):\n","    os.mkdir(running_res_folder)\n","\n","tt_loss = pd.DataFrame(total_train_loss)\n","tt_loss.to_csv(running_res_folder + \"/total_train_loss.csv\")\n","tv_loss = pd.DataFrame(total_val_loss)\n","tv_loss.to_csv(running_res_folder + \"/total_val_loss.csv\")\n","\n","tt_train_rouge = pd.DataFrame(total_train_rouge)\n","tt_train_rouge.to_csv(running_res_folder + \"/total_train_rouge.csv\")\n","tt_val_rouge = pd.DataFrame(total_val_rouge)\n","tt_val_rouge.to_csv(running_res_folder + \"/total_val_rouge.csv\")\n"]},{"cell_type":"markdown","metadata":{"id":"Rjrm3EwaCxXw"},"source":["# 4. Inference: Test PDF Summarization\n","Load a CSV file from `processed` folder. This CSV file is created after running `processing_pdf.jpynb`. The text of sections, subsections, subsubsections are put in different rows and marked with section number and section titles.\n","\n","Use your own CSV file name to replace the sample `1901.00936v3.csv`."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Qd6oIgod7KnZ","outputId":"e2126756-dbdb-49f6-c115-6986f94de5e6","executionInfo":{"status":"ok","timestamp":1714453975542,"user_tz":-480,"elapsed":21505,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Start generating summary...\n"]},{"output_type":"display_data","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n","0  an efficient linux kernel implementation of service function chaining for legacy vnfs based on ipv6 segment routing andrea mayer*, stefano salsano*, pier luigi ventre*, ahmed abdelsalam {double dagger} {section sign}, luca chiaraviglio*, clarence filsfils {section sign} *university of rome tor vergata, cnit, {double dagger}gran sasso science institute, {section sign}cisco systems extended version of the paper accepted to ieee netsoft 2019 - v04 - july 2019 abstract {em dash}we consider the ipv6 segment routing technology for service function chaining of virtual network functions . most of the vnfs are legacy vnfs and expect to process traditional ip packets. an sr proxy is needed to support them. we have extended the implementation of srv6 in the linux kernel, realizing an open source sr-proxy, referred to as srnk . the performance of the proposed solution has been evaluated, identifying a poor scalability with respect to the number of vnfs to be supported in a node. therefore we p...   \n","1  network operators are facing difficult challenges to keep up with the increasing demand for capacity, the need to support fast service creation and at the same time the goal of reducing the costs. network function virtualization and software defined networking represent an answer to these challenges and are changing the way ip networks are designed and operated. leveraging cloud computing principles, nfv moves the traditional data-plane network functions from expensive, closed and proprietary hardware to the so-called virtual network functions running over a distributed, cloud-like infrastructure referred to as nfvi . the sdn architecture splits the data and control planes and moves the intelligence to the sdn controller. sdn aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. the concept of services chaining is directly associated to nfv. actually, the idea of creating a processing path across services pre-da...   \n","2  the segment routing architecture is based on the source routing approach : it is possible to include a list of instructions in the packet headers. a comprehensive survey on segment routing can be found in this work considers the use of srv6 for sfc, leveraging its scalability properties.thanks to the source routing approach, srv6 is able to simplify network operations. generally speaking, the advantage of approaches based on source routing lies in the possibility to add state information in the packet headers, thus avoiding or minimizing the information that needs to be configured and maintained by the internal nodes. the possibility to interact only with the edge nodes to setup complex services is extremely appealing from the point of view of simplicity and efficiency. this greatly improves the scalability of services based on sr and allows simpler and faster service setup and re-configuration. in the scaling capability of segment routing has been demonstrated considering an use c...   \n","3  1) network programming model: the srv6 network programming model extends the ipv6 segment routing concept from the simple steering of packets across nodes to a general network programming approach. quoting from each segment represents a function to be called at a specific location in the network, a function can span from a simple action like forwarding or a complex processing defined by the user. going into the details, each srv6 capable node maintains the so-called my local sid table , each entry of this table maps a segment into a local function. as a consequence, when a packet enters in an srv6 enabled node with an active segment matching an entry of the table, the associated function is applied to the packet. leveraging the fact the segments are represented as regular ipv6 addresses, the node can advertise them using any routing protocol. combining these network instructions it is possible to literally program the network and realize very complex network behaviors. the associat...   \n","4  in this section we present the design of our first kernel implementation of the dynamic proxy , referred to as srnkv1. most of the following design choices apply also to the static proxy , which can be seen as a by-product of the the dynamic proxy implementation. in order to simplify the discussion we just mention the dynamic proxy in the paragraphs and in the images. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a pernetwork namespace hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns ...   \n","\n","  section_num:                                section  \\\n","0     Abstract                               Abstract   \n","1            I                        I. INTRODUCTION   \n","2           II  II. SFC BASED ON IPV6 SEGMENT ROUTING   \n","3            A          III. DESIGN OF THE SRV6 PROXY   \n","4            B          III. DESIGN OF THE SRV6 PROXY   \n","\n","                                 subsection  \\\n","0                                       NaN   \n","1                                       NaN   \n","2                                       NaN   \n","3  A. General Concepts and State-of-the-art   \n","4                                 B. SRNKv1   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 generated  \n","0  an efficient linux kernel implementation of service function chaining for legacy vnfs based on ipv6 segment routing andrea mayer*, stefano salsano*, pier luigi ventre*, ahmed abdelsalam {double dagger} {section sign}, luca chiaraviglio*, clarence filsfils { section sign} *university of rome tor vergata, cnit, {section sign}gran sasso science institute, {section sign}cisco systems extended version of the paper accepted to ieee netsoft 2019 - v04 - july 2019 abstract {em dash}we consider the ipv6 segment routing technology for service function chaining of virtual network functions ( vnfs ). most of the vnfs are legacy vnfs and expect to process traditional ip packets. an sr proxy is needed to support them. we have extended the implementation of srv6 in the linux kernel, realizing an open source sr-proxy, referred to as srnk. the performance of the proposed solution has been evaluated, identifying a poor scalability with respect to the number of vnfs to be supported in a node. therefo...  \n","1  network function virtualization ( nfv ) aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. on the other hand, the current view of service function chaining ( sfc) applied to nfv is that it has to be highly dynamic and scalable. in this scenario, the forwarding of traffic along a service function chain needs to be supported by specific protocols and mechanisms that allow the architectural elements to exchange context information. the ietf sfc working group is considering the network service header as a specific solution for the realization of the sfc architecture. in this work we are advocating the use of ipv6 segment routing to implement service function chaining. segment routing is a form of source routing, which allows to add a sequence of segments in the packet headers to influence the packet forwarding and processing within the network. in the srv6 architecture, the segments are expressed as ipv6 addresse...  \n","2                                                                                                                                                                                                                                                                                                                                                                                                              this work considers the use of srv6 for sfc, leveraging its scalability properties. thanks to the source routing approach, srv6 is able to simplify network operations. the possibility to interact only with the edge nodes to setup complex services is extremely appealing from the point of view of simplicity and efficiency. a comprehensive survey on segment routing can be found in this work considers the use of srv6 for sfc, leveraging its scalability properties. in the scaling capability of segment routing has been demonstrated considering an use case of 600,000 nodes and 300 millions of endpoints.  \n","3  the linux srv6 network programming model extends the ipv6 segment routing concept from the simple steering of packets across nodes to a general network programming approach. combining these network instructions it is possible to literally program the network and realize very complex network behaviors. the purpose of this work is to extend the implementation of the srv6 network programming model currently available in the linux kernel to support the dynamic proxy. going into the details, each srv6 capable node maintains the so-called my local sid table, each entry of this table maps a segment into a local function. as a consequence, when a packet enters in an srv6 enabled node with an active segment matching an entry of the table, the associated function is applied to the packet. leveraging the fact the segments are represented as regular ipv6 addresses, the node can advertise them using any routing protocol. the purpose of this work is to extend the implementation of the srv6 netwo...  \n","4  in this section we present the design of our first kernel implementation of the dynamic proxy, referred to as srnkv1. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a per-netns hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns hashtable is used to read the headers stored previously by the inbound processing. most of the following design choices apply also to the static proxy, which can be seen as a by-product of the dynamic proxy implementation. indeed, the hashtable is well suitable to...  "],"text/html":["\n","  <div id=\"df-dffefc49-3957-404c-9c4d-129984ec3e7d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>section_num:</th>\n","      <th>section</th>\n","      <th>subsection</th>\n","      <th>generated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>an efficient linux kernel implementation of service function chaining for legacy vnfs based on ipv6 segment routing andrea mayer*, stefano salsano*, pier luigi ventre*, ahmed abdelsalam {double dagger} {section sign}, luca chiaraviglio*, clarence filsfils {section sign} *university of rome tor vergata, cnit, {double dagger}gran sasso science institute, {section sign}cisco systems extended version of the paper accepted to ieee netsoft 2019 - v04 - july 2019 abstract {em dash}we consider the ipv6 segment routing technology for service function chaining of virtual network functions . most of the vnfs are legacy vnfs and expect to process traditional ip packets. an sr proxy is needed to support them. we have extended the implementation of srv6 in the linux kernel, realizing an open source sr-proxy, referred to as srnk . the performance of the proposed solution has been evaluated, identifying a poor scalability with respect to the number of vnfs to be supported in a node. therefore we p...</td>\n","      <td>Abstract</td>\n","      <td>Abstract</td>\n","      <td>NaN</td>\n","      <td>an efficient linux kernel implementation of service function chaining for legacy vnfs based on ipv6 segment routing andrea mayer*, stefano salsano*, pier luigi ventre*, ahmed abdelsalam {double dagger} {section sign}, luca chiaraviglio*, clarence filsfils { section sign} *university of rome tor vergata, cnit, {section sign}gran sasso science institute, {section sign}cisco systems extended version of the paper accepted to ieee netsoft 2019 - v04 - july 2019 abstract {em dash}we consider the ipv6 segment routing technology for service function chaining of virtual network functions ( vnfs ). most of the vnfs are legacy vnfs and expect to process traditional ip packets. an sr proxy is needed to support them. we have extended the implementation of srv6 in the linux kernel, realizing an open source sr-proxy, referred to as srnk. the performance of the proposed solution has been evaluated, identifying a poor scalability with respect to the number of vnfs to be supported in a node. therefo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>network operators are facing difficult challenges to keep up with the increasing demand for capacity, the need to support fast service creation and at the same time the goal of reducing the costs. network function virtualization and software defined networking represent an answer to these challenges and are changing the way ip networks are designed and operated. leveraging cloud computing principles, nfv moves the traditional data-plane network functions from expensive, closed and proprietary hardware to the so-called virtual network functions running over a distributed, cloud-like infrastructure referred to as nfvi . the sdn architecture splits the data and control planes and moves the intelligence to the sdn controller. sdn aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. the concept of services chaining is directly associated to nfv. actually, the idea of creating a processing path across services pre-da...</td>\n","      <td>I</td>\n","      <td>I. INTRODUCTION</td>\n","      <td>NaN</td>\n","      <td>network function virtualization ( nfv ) aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. on the other hand, the current view of service function chaining ( sfc) applied to nfv is that it has to be highly dynamic and scalable. in this scenario, the forwarding of traffic along a service function chain needs to be supported by specific protocols and mechanisms that allow the architectural elements to exchange context information. the ietf sfc working group is considering the network service header as a specific solution for the realization of the sfc architecture. in this work we are advocating the use of ipv6 segment routing to implement service function chaining. segment routing is a form of source routing, which allows to add a sequence of segments in the packet headers to influence the packet forwarding and processing within the network. in the srv6 architecture, the segments are expressed as ipv6 addresse...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the segment routing architecture is based on the source routing approach : it is possible to include a list of instructions in the packet headers. a comprehensive survey on segment routing can be found in this work considers the use of srv6 for sfc, leveraging its scalability properties.thanks to the source routing approach, srv6 is able to simplify network operations. generally speaking, the advantage of approaches based on source routing lies in the possibility to add state information in the packet headers, thus avoiding or minimizing the information that needs to be configured and maintained by the internal nodes. the possibility to interact only with the edge nodes to setup complex services is extremely appealing from the point of view of simplicity and efficiency. this greatly improves the scalability of services based on sr and allows simpler and faster service setup and re-configuration. in the scaling capability of segment routing has been demonstrated considering an use c...</td>\n","      <td>II</td>\n","      <td>II. SFC BASED ON IPV6 SEGMENT ROUTING</td>\n","      <td>NaN</td>\n","      <td>this work considers the use of srv6 for sfc, leveraging its scalability properties. thanks to the source routing approach, srv6 is able to simplify network operations. the possibility to interact only with the edge nodes to setup complex services is extremely appealing from the point of view of simplicity and efficiency. a comprehensive survey on segment routing can be found in this work considers the use of srv6 for sfc, leveraging its scalability properties. in the scaling capability of segment routing has been demonstrated considering an use case of 600,000 nodes and 300 millions of endpoints.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1) network programming model: the srv6 network programming model extends the ipv6 segment routing concept from the simple steering of packets across nodes to a general network programming approach. quoting from each segment represents a function to be called at a specific location in the network, a function can span from a simple action like forwarding or a complex processing defined by the user. going into the details, each srv6 capable node maintains the so-called my local sid table , each entry of this table maps a segment into a local function. as a consequence, when a packet enters in an srv6 enabled node with an active segment matching an entry of the table, the associated function is applied to the packet. leveraging the fact the segments are represented as regular ipv6 addresses, the node can advertise them using any routing protocol. combining these network instructions it is possible to literally program the network and realize very complex network behaviors. the associat...</td>\n","      <td>A</td>\n","      <td>III. DESIGN OF THE SRV6 PROXY</td>\n","      <td>A. General Concepts and State-of-the-art</td>\n","      <td>the linux srv6 network programming model extends the ipv6 segment routing concept from the simple steering of packets across nodes to a general network programming approach. combining these network instructions it is possible to literally program the network and realize very complex network behaviors. the purpose of this work is to extend the implementation of the srv6 network programming model currently available in the linux kernel to support the dynamic proxy. going into the details, each srv6 capable node maintains the so-called my local sid table, each entry of this table maps a segment into a local function. as a consequence, when a packet enters in an srv6 enabled node with an active segment matching an entry of the table, the associated function is applied to the packet. leveraging the fact the segments are represented as regular ipv6 addresses, the node can advertise them using any routing protocol. the purpose of this work is to extend the implementation of the srv6 netwo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>in this section we present the design of our first kernel implementation of the dynamic proxy , referred to as srnkv1. most of the following design choices apply also to the static proxy , which can be seen as a by-product of the the dynamic proxy implementation. in order to simplify the discussion we just mention the dynamic proxy in the paragraphs and in the images. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a pernetwork namespace hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns ...</td>\n","      <td>B</td>\n","      <td>III. DESIGN OF THE SRV6 PROXY</td>\n","      <td>B. SRNKv1</td>\n","      <td>in this section we present the design of our first kernel implementation of the dynamic proxy, referred to as srnkv1. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a per-netns hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns hashtable is used to read the headers stored previously by the inbound processing. most of the following design choices apply also to the static proxy, which can be seen as a by-product of the dynamic proxy implementation. indeed, the hashtable is well suitable to...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dffefc49-3957-404c-9c4d-129984ec3e7d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dffefc49-3957-404c-9c4d-129984ec3e7d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dffefc49-3957-404c-9c4d-129984ec3e7d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-71d409f2-4d7c-405f-ad76-680cf9b3ff28\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71d409f2-4d7c-405f-ad76-680cf9b3ff28')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-71d409f2-4d7c-405f-ad76-680cf9b3ff28 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"generated_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"network operators are facing difficult challenges to keep up with the increasing demand for capacity, the need to support fast service creation and at the same time the goal of reducing the costs. network function virtualization and software defined networking represent an answer to these challenges and are changing the way ip networks are designed and operated. leveraging cloud computing principles, nfv moves the traditional data-plane network functions from expensive, closed and proprietary hardware to the so-called virtual network functions running over a distributed, cloud-like infrastructure referred to as nfvi . the sdn architecture splits the data and control planes and moves the intelligence to the sdn controller. sdn aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. the concept of services chaining is directly associated to nfv. actually, the idea of creating a processing path across services pre-dates the nfv concept as stated in and . in fact, service chaining has been traditionally realized in a static way by putting hardware functions as middle-points of the processing paths and in some cases by diverting the forwarding paths with manual configuration of vlans stitching or policy routing. however, these static approaches comes with several drawbacks which are detailed in . in particular, they are intrinsically difficult to scale and hard to reconfigure. on the other hand, the current view of sfc applied to nfv is that it has to be highly dynamic and scalable.the ietf sfc working group has investigated the scenarios and issues related to dynamic service chaining and proposed a reference architecture . the main logical elements of this architecture are i) classifiers; ii) service functions forwarders , iii) the service functions, iv) sfc proxies. the classifiers match the traffic against a set of policies in order to associate the proper service function chain. the sffs forward the traffic towards the service functions or towards other sffs and handle the traffic coming back from the service functions. the sfc framework proposed in does not pose any restriction on the function that can be chained: they can be both virtualized or physical functions . for the sake of simplicity, hereafter in the paper we will only refer to the virtualized case and will simply use the term vnf instead of service function. in this scenario, the forwarding of traffic along a service chain needs to be supported by specific protocols and mechanisms that allow the architectural elements to exchange context information. the vnfs can participate to these chaining mechanisms and in this case they are called sfc aware. on the other hand, the legacy vnfs that do not interact with the sfc protocols and mechanisms are called sfc unaware. the sfc proxy elements are needed for the latter type of vnfs. an sfc proxy hides the sfc mechanisms to the sfc unaware vnfs, that will receive and send plain ip traffic. the ietf sfc wg is considering the network service header as a specific solution for the realization of the sfc architecture. the nsh header defines the service-level data-plane encapsulation for realizing the vnfs chaining. the nsh header identifies a service chain which is associated to the packets. moreover, it defines the packet meta-data that arxiv:1901.00936v3 23 jul 2019 can be inserted into the header to exchange state between the nodes of the sfc architecture. in this work we are advocating the use of ipv6 segment routing to implement service function chaining , . segment routing , is a form of source routing, which allows to add a sequence of segments in the packet headers to influence the packet forwarding and processing within the network. segment routing has been designed and implemented for the mpls and ipv6 data planes, we only focus here on the ipv6 version, denoted as srv6. in the srv6 architecture, the segments are expressed as ipv6 addresses. the srv6 network programming model , leveraging the huge ipv6 addressing space, extends the srv6 architecture from a simple forwarding mechanism for steering packets to a more general network programming abstraction. a segment can represent an instruction or behavior and not only a network location. our proposed approach is fully aligned with the network programming model described in . the srv6 architecture is not limited to service function chaining, which represents only a possible use case. indeed, srv6 can support several applications in a network provider backbone like traffic engineering, network resilience , virtual private networks , multicast, content delivery networks . with respect to the mpls based data plane, srv6 it has the advantage that it can be better integrated in host networking stack. for this reason data center applications could also benefit from srv6. a relevant subset of the srv6 and network programming model specifications have been implemented and integrated in the mainline linux kernel . in this paper, we rely on this existing work and extend it to focus on the service function chaining of legacy vnfs, which are not able to process the srv6 headers. the support of legacy vnfs is important for internet service providers for different reasons: i) it guarantees a feasible migration strategy saving past investments; ii) it facilitates the interoperability and the multi-vendor scenarios, i.e deployments composed by vnfs of different vendors; iii) the development of srv6 aware vnfs requires a new implementation cycle which can be more expensive in the short period. as introduced above, a proxy element needs to be inserted in the processing chain as relay mechanism in order to support srv6 unaware vnfs . the latest linux kernel still lacks of the functionality to implement such srv6 proxy element. in a prior work , we have provided this functionality as an external module not integrated with the most recent srv6 developments in the linux kernel. considering the importance of the support of legacy sr-unaware applications in nfv deployments, the main contribution this paper is the design and implementation of an sr-proxy integrated in the linux kernel networking components. we refer to this work as srnk . we designed a first version of srnk and evaluated its performance, identifying a poor scalability with respect to the number of vnfs to be supported. the issue is actually related to the implementation of policy routing framework in linux. therefore we provided a second design, enhancing the fig. 1: srv6 nfv node with sr-proxy for sr-unaware vnf linux policy routing framework, whose performance does not depend on the number of supported vnfs in a node. the content of the paper is as follows. section ii introduces sfc based on srv6 considering both srv6 aware and unaware vnfs. the proposed design and implementation of srv6 proxy to support legacy vnfs in the linux kernel is described in section iii. our testing environment and methodologies for performance analysis are reported in section iv. sections v details the performance evaluation of the implemented solutions. finally, in section vii we draw some conclusions and discuss future work. this work has been performed in the context of the rose research project which focuses on the development of an open source srv6 ecosystem. the source code of all components of srnk including the patches to the user space utilities are freely available at .\",\n          \"in this section we present the design of our first kernel implementation of the dynamic proxy , referred to as srnkv1. most of the following design choices apply also to the static proxy , which can be seen as a by-product of the the dynamic proxy implementation. in order to simplify the discussion we just mention the dynamic proxy in the paragraphs and in the images. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a pernetwork namespace hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns hashtable is used to read the headers stored previously by the inbound processing. figures 4 show an high-level view of the processing inside a srv6 enabled node and how ipv6 routing network subsystem interacts with the srv6 dynamic proxy implementation. 1) inbound processing: the inbound processing is depicted in figure 4a. as soon as an ipv6 packet arrives at interface eth0 of the nfv node, it enters into the linux networking stack. after passing the pre-routing stage, the kernel tries to look up the route with the longest prefix that matches the active segment of the packet. due to policy-routing settings, the linux kernel looks first at my local sid table and if no matching route has been found, it considers the other tables and possibly moves on the next stages of the processing . figure 4a shows this process in details, the packet destination address matches with prefix sid1 and the correspondent route is used. therefore, the linux kernel executes the processing function associated with the route: the inbound end.ad operation. the inbound end.ad operates in three different stages: i) it pops the outer ipv6 and srv6 headers from the incoming packet; ii) it updates the sid pointer of the srv6 header to select the next one; iii) it stores such retrieved headers into a per-netns hashtable data structure; iv) it sends out the decapsulated ipv6 plain packet to its designated legacy vnf. removed headers at step are indexed in the per-netns hashtable by using the identifier of the packet outgoing interface , the one used to communicate with the legacy vnf . due to the necessity of sharing ipv6 and srv6 headers between inbound and fromvnf processing, the choice of storing them within a external shared data structure turned out to be the right solution. this design simplifies the access pattern to the stored data, as well as it increases performance. indeed, the hashtable is well suitable to support fast data retrieving with a very low computational cost and, ideally it is independent with regard to the number inbound processing fromvnf processing fig. 4: srnkv1 design of stored entries. from a configuration point of view, the inbound processing just relies on the plain ipv6 routing through my local sid table: the new route is added with the ip -6 route add command of the iproute2 suite, by also specifying the behavior to be activated in the parameters of the command. appendix a provides further details on the configuration of the inbound processing. 2) auto-learning process: the auto-learning process consists in learning the information related of the vnfs chain from the inbound packets, without the need of a static configuration. the learned information is saved in a per-netns hashtable. we have introduced an age parameter to control the rate at which the per-netns hashtable can be updated. this parameter can be set during the setup of the lwt routing entry in my local sid table. when different from 0, the age parameter represents the minimum interval between two write operations in the per-netns hashtable for the same vnf. setting the age to 1 second corresponds to a maximum reconfiguration delay of 1 second for a nfv node when the vnf chain is changed by an ingress node and this is the default we used in our experiments. if age equals 0, the per-netns hashtable is updated for every inbound packets, providing the fastest possible reconfiguration time for a vnf chain. in the performance evaluation section, we have analyzed the performance cost for the continuous updating of the per-netns hashtable with respect to the default minimum reconfiguration delay of 1 second. the age parameter registers the last time the headers have been updated and it is used also to determine, when a packet is received, if it is the time to replace stale data with new fresh one. the auto-learning operation is performed only during the inbound processing. the learned information is retrieved during the fromvnf processing using the incoming interface2 of the packet to rebuild the whole srv6 packet ready for being forwarded into the network. setting properly the age parameter has an important impact on the performance of the system and a proper trade-off is necessary according to the use case to be supported. in a shared-memory producer-consumer context, we can identify the inbound processing as the content producer, and the fromvnf one as the consumer. indeed, the former is in charge of keeping the per-netns hashtable up-to-date, while the latter accesses the structure for retrieving the headers. considering this model, the aging parameter can be seen as the upper-bound of data production/refresh rate. by setting it to the maximum limit, it is possible to prevent overloading of the srv6 nfv node caused by high-rate writing in the shared memory. this problem is particularly noticeable in all of those systems based on multi-core architectures: the linux networking stack allows to assign the received packets to all available computing units in order to process them in parallel and to support high data rates. however, this means that several end.ad processing operations may occur at once and, potentially, they may involve updating the same ipv6 and srv6 headers. very frequent and simultaneous shared memory updates by multiple cpus can lead to conflicts that can negatively affect the overall performance of the system. for all these reasons, small values of the age parameter make the system more responsive to chain changes, but on the other side they can push heavy and unnecessarily load to the srv6 nfv node due to high data refresh rate. 3) end.as design: the end.ad differs from the end.as just on the way the stored headers are managed. the end.as behavior is a simplification of the end.ad because it does 2the current implementation of the dynamic proxy assumes that the same interface is used to interact with vnf in the two directions not need to deal with the auto-learning process. indeed, it uses chain information which has been saved once during the behavior configuration. the list of segments does not change during the entire life of the end.as instance unless it is first deleted and then saved with new headers values. 4) fromvnf processing: the fromvnf lwt tunnel is meant to work in tandem with its inbound counterpart. fromvnf packets do not carry any sid as it happens for the inbound ones. as result, in order to select the correct lwt tunnel and processing each packet accordingly, we can rely only on the incoming interface between the vnf and the nfv node through which packets come back. hence, we add an entry in the ipv6 routing policy db for each vnf to be supported. every rpdb entry is also known as ipv6 rule, as the command used to configure it is ip -6 rule. the rule points to a different routing table for each vnf, in which there is only a default route, pointing to the lwt tunnel associated to the vnf. this means that for n vnfs, we will have n rules and n routing tables. figure 4b provides a representation of the described fromvnf processing. let us analyze with more details the motivation for this design. the fromvnf lwt tunnel can not be tied to any route with a specific prefix because the ipv6 packets sent by vnf can use any destination address and do not have any relationship with the sids. moreover, each end.ad fromvnf tunnel expects to receive traffic by its own layer-2 interface , with no regards about the ipv6 destination address of the packets. this means that, in order to apply the fromvnf processing function to an incoming packet, the srv6 nfv node has to retrieve the route that points to the right lwt tunnel using only the identifier of the interface where such as packet has been received. as a consequence of this, the fromvnf end.ad design has to deal with: i) the problem of designating an ipv6 prefix to be used for creating a route pointing to a custom processing function , and ii) the issue of steering incoming traffic received on a specific interface through such as route. the first issue can be easily solved by using as route prefix the any address which is often indicated by ::. generally, the default route is selected by the routing algorithm when the ipv6 destination address can not be managed by any other. however, this usage gives rise to a new problem. indeed, creating a lwt on a default route has the side effect that no more than one vnf can be handled by the srv6 node using a single table. moreover, control traffic that transits through the srv6 node and for which there are no given explicit routes may be wrongly handled by the lwt installed on the default route. thankfully, this problem can be easily solved by installing every default route into a different ipv6 routing table and creating, for each of these, a rule in the ipv6 routing policy db. such rule is meant to instruct the ipv6 network system to perform route look-up on a specific table based on a specified match. the usage of an ipv6 policy route solves also the issue ii) as at this point we can use the fromvnf interface as match and a goto-table n as action predicate. in this way we can relate an interface to a specific default route that has attached to a lwt. figure 4b shows an high-level overview of proposed solution with the fromvnf lwt tunnel integrated in the ipv6 routing network subsystem. whenever a plain ipv6 packets, sent by vnf, arrives at srv6 nfv node, it is handled by the linux networking stack. after passing the pre-routing stage, the kernel tries to determine the right processing of the packet. it invokes the route look-up operation, but this time the routing algorithm finds first an entry in the rpdb of the node and does not consider ipv6 destination address at first. indeed, thanks to custom ipv6 rules the routing algorithm is capable to retrieve the ipv6 table tied to the incoming interface of the packet. at this point, the routing algorithm makes use of this table to find out the route that matches with the received packet. in this specific case, the routing algorithm selects and returns the only route available, the default one, that is attached to a specific end.ad tunnel. once the plain ipv6 packet has been received by the fromvnf processing function, it leverages the identifier of the incoming interface of the packet to search for the popped ipv6 and srv6 headers within the per-netns hashtable. if a result is found, the processing function forges a new packet and sets the headers of such as packet with those that have just been retrieved. the plain ipv6 packet is encapsulated into the newly created one and then the whole packet is delivered towards its destination. this concludes the job of the fromvnf lwt tunnel processing operation.\",\n          \"the segment routing architecture is based on the source routing approach : it is possible to include a list of instructions in the packet headers. a comprehensive survey on segment routing can be found in this work considers the use of srv6 for sfc, leveraging its scalability properties.thanks to the source routing approach, srv6 is able to simplify network operations. generally speaking, the advantage of approaches based on source routing lies in the possibility to add state information in the packet headers, thus avoiding or minimizing the information that needs to be configured and maintained by the internal nodes. the possibility to interact only with the edge nodes to setup complex services is extremely appealing from the point of view of simplicity and efficiency. this greatly improves the scalability of services based on sr and allows simpler and faster service setup and re-configuration. in the scaling capability of segment routing has been demonstrated considering an use case of 600,000 nodes and 300 millions of endpoints. by exploiting the srv6 approach the vnfs can be mapped in ipv6 addresses in the segments list and we can represent the vnf chain using this list carried in the segment routing header . the sr information can be pushed into the packets using two different approaches, denoted as insert and encap modes, respectively.according to the srv6 network programming document , when a node uses the insert mode the srh is pushed as next header in the original ipv6 packet, immediately after the ipv6 header and before the transport header. the original ipv6 header is changed, in particular the next header is modified according to the value of srh, the ipv6 destination address is replaced with the ipv6 address of the first sid in the segment list, while the original ipv6 destination address is carried in the srh header as the last segment of the list. in this work we only consider the encap mode: the original ipv6 packet is transported as the inner packet of an ipv6in-ipv6 encapsulated packet and travels unmodified in the network. the outer ipv6 packet carries the srh header with the segments list.1 an sr-aware vnf can process the srh of the incoming packets and can use it to influence the processing/forwarding of the packets. such vnfs interact with the node operating system or with sr modules in order to read and/or set the information contained in the srh. on the other side, the srunaware vnfs are not capable to process the srv6 sfc encapsulation. in this scenario an sr proxy is necessary to remove the srv6 header and deliver a clean ip packet to the vnf. figure 1 provides the reference architecture for a srv6 nfv node that includes an sr-unaware vnf . we refer to packets incoming to the srv6 nfv node that should be forwarded to the vnf by the srproxy as inbound packets. the sr-proxy needs to intercept the packets coming out from the vnf and re-apply the srv6 sfc encapsulation. we refer to these packets as fromvnf packets. in , a set of sr-proxy behaviors have been defined, among them we mention: i) static proxy ; ii) dynamic proxy ; iii) masquerading proxy . the first two cases support ipv6 sr packets in encap mode. the encapsulated packets can be ipv6, ipv4 or l2 packets. the sr proxy intercepts sr packets before being handed to the sr-unaware vnf, hence it can remove the sr encapsulation from packets. for packets coming back from sr-unaware vnf, the sr proxy can restore the srv6 encapsulation updating the srh properly. the difference between the static and the dynamic proxies is that the sr information that needs to be pushed back in the packets is statically configured in the first case and it is learned from the incoming packets in the dynamic case.instead, the masquerading proxy supports sr packets travelling in insert mode. it masquerades the sr packets before they are sent to the legacy vnf by replacing the ipv6 destination address with the original ipv6 destination . it is assumed that a vnf compatible with this operating mode is processing ipv6 packets and does not alter the srh, it just ignores it. in this way, when packets are received back, the sr proxy can restore the correct information in the ipv6 header in a stateless way, just using the information contained in the srh. 1as any tunneling method, srv6 introduces overhead the packets. the insert mode introduces an overhead of 8 + n *16 where n is the number of segments, while in the encap mode the overhead is 40 + 8 + n *16. let us discuss the operational model and the state information that need to be configured and maintained in the srv6 nfv nodes. figure 2 illustrates a srv6 based nfv domain, in which the vnfs are hosted in different nfv nodes. the packets to be associated to vnf chains are classified in ingress nodes, where the sr encapsulation is added. a network operator willing to use srv6 sfc chaining for srunaware vnfs, will first need to associate vnfs to segment ids in the hosting srv6 nfv nodes. we recall that a sid is represented by an ipv6 address. each srv6 nfv node has a pool of ipv6 addresses that are available to be used as sids for its vnfs. these prefixes are distributed using regular routing protocols, so that the reachability of all vnfs is assured. the association of the ipv6 address sid to a vnf is a configuration operation to be performed in the srv6 nfv node and it binds the sid to the virtual interface that connects the sr-proxy to the vnf. this operation is performed when a legacy vnf is created in a nfv node. the corresponding state information is used in the inbound direction, when packets directed to the vnf are processed by the sr-proxy. the second step is to configure a vnf chain across the vnfs that are running over the srv6 nfv nodes. the vnf chain will be applied to a packet by inserting a sid list in the ipv6 sr header in the ingress node. therefore, the classification of packets and the association with the sid list has to be configured in the ingress node. each nfv node which runs a legacy vnf needs the proper information to process the packets in the fromvnf direction. this is done differently for the respective types of proxy. in the static proxy case , the state information needed to process the packets coming from the vnf is done by statically configuring the sr-proxy with the sid list to be re-inserted in the packet. both the dynamic proxy and the masquerading one have the good property that they do not need to be configured when a new chain is added. the dynamic proxy learns the sid list from the packets in the inbound direction . the masquerading proxy does not even need to save the state information as the sid list is carried along with the packet through the legacy vnf . table i compares the different sr proxy behaviors. in this table i: comparison of sr proxy behaviours end.ad end.as end.am generate traffic yes yes no modify packets yes yes no stateless no no yes state-config auto manual n/a traffic supported ipv4/ipv6/l2 ipv4/ipv6/l2 ipv6 work, we focus on the design and in-kernel implementation of the sr dynamic proxy as it represents the most versatile solution and it offers a simple operational model. fig. 2: sfc scenario\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section_num:\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I\",\n          \"B\",\n          \"II\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"I. INTRODUCTION\",\n          \"III. DESIGN OF THE SRV6 PROXY\",\n          \"Abstract\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subsection\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"B. SRNKv1\",\n          \"A. General Concepts and State-of-the-art\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"network function virtualization ( nfv ) aims at simplifying the introduction of new services and fostering flexibility thanks to the centralized network state view. on the other hand, the current view of service function chaining ( sfc) applied to nfv is that it has to be highly dynamic and scalable. in this scenario, the forwarding of traffic along a service function chain needs to be supported by specific protocols and mechanisms that allow the architectural elements to exchange context information. the ietf sfc working group is considering the network service header as a specific solution for the realization of the sfc architecture. in this work we are advocating the use of ipv6 segment routing to implement service function chaining. segment routing is a form of source routing, which allows to add a sequence of segments in the packet headers to influence the packet forwarding and processing within the network. in the srv6 architecture, the segments are expressed as ipv6 addresses. the srv6 network programming model, leveraging the huge ipv6 addressing space, extends the srv6 architecture from a simple forwarding mechanism for steering packets to a more general network programming abstraction. the main logical elements of this architecture are i) classifiers; ii) service functions forwarders, iii) service functions, iv) sfc proxies. the classifiers match the traffic against a set of policies in order to associate the proper service function chain. the vnfs can participate to these chaining mechanisms and in this case they are called sfc aware. on the other hand, the legacy vnfs that do not interact with the sfc mechanisms and mechanisms are called sfc unaware. the sfc proxy elements are needed for the latter type of vnfs.\",\n          \"in this section we present the design of our first kernel implementation of the dynamic proxy, referred to as srnkv1. srnkv1 design relies on two distinct lwts which manage respectively the inbound and fromvnf traffic. for each lwt, state information is maintained in order to correctly perform the proxy operations. in particular, the inbound processing needs an entry on the my local sid table and uses a per-netns hashtable to store the headers that have to be restored during the fromvnf processing. as regards the traffic coming from the legacy vnf, a policy routing entry for each vnf is necessary to classify the packets, a routing table with a default route pointing to the lwt is used for the vnf and finally the per-netns hashtable is used to read the headers stored previously by the inbound processing. most of the following design choices apply also to the static proxy, which can be seen as a by-product of the dynamic proxy implementation. indeed, the hashtable is well suitable to support fast data retrieving with a very low computational cost and, ideally it is independent with regard to the number inbound processing fromvnf processing. appendix a provides further details\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["pdf_df = pd.read_csv(project_processed_data_path + \"/1901.00936v3.csv\")\n","\n","print(\"Start generating summary...\")\n","generated_df = model_action.generate_summary_for_user_pdf(pdf_df)\n","display(generated_df.head())\n","generated_df.to_csv(project_processed_data_path + \"/1901.00936v3_generated.csv\")\n"]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"wWiLN0LZirfn","executionInfo":{"status":"ok","timestamp":1714453975543,"user_tz":-480,"elapsed":11,"user":{"displayName":"Claudia Yao","userId":"16718924703474684624"}}},"execution_count":7,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3fa5e4e27c5e471ea49a5b8bba497600":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e97ae00353b44d5cb2dc6f9ef93c780d","IPY_MODEL_8ff265954bd1409690220199ffe921ca","IPY_MODEL_fad0f41386434da7a3d3dcc71d9321d6"],"layout":"IPY_MODEL_a3c193e904c841588668330205a92004"}},"e97ae00353b44d5cb2dc6f9ef93c780d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43dae62e7a324ea1af112da2910c4454","placeholder":"​","style":"IPY_MODEL_10c0ff64a14a49c7911848449853796a","value":"tokenizer_config.json: 100%"}},"8ff265954bd1409690220199ffe921ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_762e08c1376040fbad8c9aa94eaa94e2","max":27,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a7fedebd23f4939a0192b00ea7caf5f","value":27}},"fad0f41386434da7a3d3dcc71d9321d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b3a30409cd94a6386d96f777834d2cd","placeholder":"​","style":"IPY_MODEL_2a129e970cf346d585323ada85c602ab","value":" 27.0/27.0 [00:00&lt;00:00, 2.44kB/s]"}},"a3c193e904c841588668330205a92004":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43dae62e7a324ea1af112da2910c4454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10c0ff64a14a49c7911848449853796a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"762e08c1376040fbad8c9aa94eaa94e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a7fedebd23f4939a0192b00ea7caf5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b3a30409cd94a6386d96f777834d2cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a129e970cf346d585323ada85c602ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"972b7b89c75d4f7fa93339b217c6672c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99c6e25c75a94a36a90b983a6f103a6f","IPY_MODEL_5e1e30da780f4046a1df83fd9786898a","IPY_MODEL_0ccaa0fa1a4c4fe78ec8547b7e8c3c42"],"layout":"IPY_MODEL_2e3c73f6fa944e00b66aa99124c0f2a8"}},"99c6e25c75a94a36a90b983a6f103a6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93df08ee30274d90a36aed4b332dca7d","placeholder":"​","style":"IPY_MODEL_a73a522389394d2f9932293e15e64150","value":"vocab.json: 100%"}},"5e1e30da780f4046a1df83fd9786898a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb32b690d0e24fe586fdfc1b5b06b3ba","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf022384b4594a19b91d8bc716c31eab","value":898822}},"0ccaa0fa1a4c4fe78ec8547b7e8c3c42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bf53e8a16d048d0a46a47286008d3c7","placeholder":"​","style":"IPY_MODEL_4aabf63941f54c02b2477b2cc080933c","value":" 899k/899k [00:00&lt;00:00, 4.57MB/s]"}},"2e3c73f6fa944e00b66aa99124c0f2a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93df08ee30274d90a36aed4b332dca7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73a522389394d2f9932293e15e64150":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb32b690d0e24fe586fdfc1b5b06b3ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf022384b4594a19b91d8bc716c31eab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bf53e8a16d048d0a46a47286008d3c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aabf63941f54c02b2477b2cc080933c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da0f8ff6e7ea4c69a7874caa1beb9158":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a074d147a3c14d0280903f0e421b0ce3","IPY_MODEL_56209b6224c642a0b49c2032abec7f81","IPY_MODEL_5804012072e44502b69f69a0b307352a"],"layout":"IPY_MODEL_8211a0a1c191426ba48f3bf254879126"}},"a074d147a3c14d0280903f0e421b0ce3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0038fe4dbda4e2a87df49889ded43f1","placeholder":"​","style":"IPY_MODEL_641651b5c69a4459bfe7989c39db58f9","value":"merges.txt: 100%"}},"56209b6224c642a0b49c2032abec7f81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e222064b9b284dbfbbaeefd6ed239845","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8768666c82c147719c4a7653da7f8315","value":456318}},"5804012072e44502b69f69a0b307352a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_052afc11eb5045f28f9a839f14c9bfbc","placeholder":"​","style":"IPY_MODEL_18d71c66da5843a9b58fa4d09536b0b0","value":" 456k/456k [00:00&lt;00:00, 3.50MB/s]"}},"8211a0a1c191426ba48f3bf254879126":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0038fe4dbda4e2a87df49889ded43f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"641651b5c69a4459bfe7989c39db58f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e222064b9b284dbfbbaeefd6ed239845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8768666c82c147719c4a7653da7f8315":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"052afc11eb5045f28f9a839f14c9bfbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18d71c66da5843a9b58fa4d09536b0b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c675b8b4d06e4843ae57fd54c2bd3159":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_604dd127f6df40eea8f0d6ea533a9382","IPY_MODEL_e83867c6397a4f6ca362e22d2e4d9476","IPY_MODEL_cd0c690e635e4a15b9120ccfecaf2333"],"layout":"IPY_MODEL_8dd5fbd1a00441649c98e002356e8a92"}},"604dd127f6df40eea8f0d6ea533a9382":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eb23d9ddbed4f6686e83252e7bc02bb","placeholder":"​","style":"IPY_MODEL_d6bb1471c7d64e8e8406be853ed5ccec","value":"special_tokens_map.json: 100%"}},"e83867c6397a4f6ca362e22d2e4d9476":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b659bf3e976418b915eb35d11a4cfa3","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28c2489a280342479231287159274e84","value":772}},"cd0c690e635e4a15b9120ccfecaf2333":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b945ee3cd44d7e83eca46d90f080dc","placeholder":"​","style":"IPY_MODEL_6ce96d9e577d4a1eba85de412e8a804c","value":" 772/772 [00:00&lt;00:00, 70.9kB/s]"}},"8dd5fbd1a00441649c98e002356e8a92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eb23d9ddbed4f6686e83252e7bc02bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6bb1471c7d64e8e8406be853ed5ccec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b659bf3e976418b915eb35d11a4cfa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28c2489a280342479231287159274e84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6b945ee3cd44d7e83eca46d90f080dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce96d9e577d4a1eba85de412e8a804c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6aa5f11f8af49399a9e10174f0823be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6801026b5a414333b0a104234cc791ab","IPY_MODEL_93a9402327e342cabd96e4896744e3ea","IPY_MODEL_7badc401923640f99ed3d5f83813aafa"],"layout":"IPY_MODEL_fcca7437809c4a9cb5dfee768decf05d"}},"6801026b5a414333b0a104234cc791ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de1895013e2c42489b90636af331f3e6","placeholder":"​","style":"IPY_MODEL_8acdeabf82d64b71bebc56c9917088f6","value":"config.json: 100%"}},"93a9402327e342cabd96e4896744e3ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29b1110364540d6bdb080ff6c24004e","max":1291,"min":0,"orientation":"horizontal","style":"IPY_MODEL_881ca39313c94a1a84c85c7bb6f75731","value":1291}},"7badc401923640f99ed3d5f83813aafa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dacdf6436a01453bba4ce96c59e7b928","placeholder":"​","style":"IPY_MODEL_5da43f0c67734e6b9027256ab2f2e384","value":" 1.29k/1.29k [00:00&lt;00:00, 117kB/s]"}},"fcca7437809c4a9cb5dfee768decf05d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1895013e2c42489b90636af331f3e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8acdeabf82d64b71bebc56c9917088f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29b1110364540d6bdb080ff6c24004e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"881ca39313c94a1a84c85c7bb6f75731":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dacdf6436a01453bba4ce96c59e7b928":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da43f0c67734e6b9027256ab2f2e384":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86db3eb2cd0c4072af8808a18aa32070":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ea405461bfb4f4c926a4ceb209841dd","IPY_MODEL_d6b48a22023b4a40bd98f17ad2e59a20","IPY_MODEL_8d75a086a1f649fba8e2d25533b5efc6"],"layout":"IPY_MODEL_954e352842a548a188fb8ace537046e1"}},"3ea405461bfb4f4c926a4ceb209841dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad03682372847ea81939a6d46b667fd","placeholder":"​","style":"IPY_MODEL_75439258717c45fb938ae72ce890a228","value":"pytorch_model.bin: 100%"}},"d6b48a22023b4a40bd98f17ad2e59a20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2348bd4ef6b44008f17989a23a4fd4b","max":1839633783,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b2cb1165a86411bbd2cdbe8101cf0fb","value":1839633783}},"8d75a086a1f649fba8e2d25533b5efc6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_393cc3672e024b1085e1b2fd06ecdd79","placeholder":"​","style":"IPY_MODEL_343c0d3cc0024840bcede5e65812420b","value":" 1.84G/1.84G [00:38&lt;00:00, 49.4MB/s]"}},"954e352842a548a188fb8ace537046e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ad03682372847ea81939a6d46b667fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75439258717c45fb938ae72ce890a228":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2348bd4ef6b44008f17989a23a4fd4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2cb1165a86411bbd2cdbe8101cf0fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"393cc3672e024b1085e1b2fd06ecdd79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"343c0d3cc0024840bcede5e65812420b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a861d41f3d44786b2c6396a251e4e39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6adb11b0e0b14db1a0b167d3aa43d50b","IPY_MODEL_3ea2b12ce4d24c258f3fb8b2af9f55c1","IPY_MODEL_259f6c0004f247eabfbf6b4a1c92d408"],"layout":"IPY_MODEL_6df2d5f41d5d4f1a854323d5c4f560b6"}},"6adb11b0e0b14db1a0b167d3aa43d50b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf1e0b3c83d47bd953cb1476dd3eb3d","placeholder":"​","style":"IPY_MODEL_ad1663f408a9480dba0d7ea52319cf86","value":"generation_config.json: 100%"}},"3ea2b12ce4d24c258f3fb8b2af9f55c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_782e7b80b3074b1f949b66d4e79e2140","max":207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_615b99bd73624120ba6456316204fa1e","value":207}},"259f6c0004f247eabfbf6b4a1c92d408":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_637d732d085b42bfb7c9c8cf4c9c8144","placeholder":"​","style":"IPY_MODEL_c9fcddc37ded43eebfbdcad48400ef98","value":" 207/207 [00:00&lt;00:00, 18.7kB/s]"}},"6df2d5f41d5d4f1a854323d5c4f560b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cf1e0b3c83d47bd953cb1476dd3eb3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad1663f408a9480dba0d7ea52319cf86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"782e7b80b3074b1f949b66d4e79e2140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"615b99bd73624120ba6456316204fa1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"637d732d085b42bfb7c9c8cf4c9c8144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9fcddc37ded43eebfbdcad48400ef98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b577ef44afff4eb1954ccf0e2b59f2a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9f91067653749f8a96b93ab1b9515cb","IPY_MODEL_daaa419f80544e1da142b432d09f657a","IPY_MODEL_b34173b7eb8b4f6b9f16ff26a31716d2"],"layout":"IPY_MODEL_0aaa3f93f57440ab87d200e9b2179836"}},"d9f91067653749f8a96b93ab1b9515cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7313d54d931a411da82707d97fc53ab5","placeholder":"​","style":"IPY_MODEL_347e4c24766b453c8a71fa9043a12be6","value":"Downloading builder script: "}},"daaa419f80544e1da142b432d09f657a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c500b5b6d845aea5dd7592002bade2","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b413d776cfa4c008a0eb3a3dbab126e","value":2169}},"b34173b7eb8b4f6b9f16ff26a31716d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65050e92d76e44f794624fd61bfb2774","placeholder":"​","style":"IPY_MODEL_30a6d7f0f2e84b0da63c3441125c9fee","value":" 5.65k/? [00:00&lt;00:00, 350kB/s]"}},"0aaa3f93f57440ab87d200e9b2179836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7313d54d931a411da82707d97fc53ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"347e4c24766b453c8a71fa9043a12be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51c500b5b6d845aea5dd7592002bade2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b413d776cfa4c008a0eb3a3dbab126e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65050e92d76e44f794624fd61bfb2774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30a6d7f0f2e84b0da63c3441125c9fee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3ec44fb997a48908225b79f2d91dd19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c388426d4e094a7ea5f0ecf164b30373","IPY_MODEL_6ec8f012b3be419a9426866e0853db06","IPY_MODEL_af7497424ded49dda52192fd228b211f"],"layout":"IPY_MODEL_3f27cfb282db49cb889cddcc2af00dde"}},"c388426d4e094a7ea5f0ecf164b30373":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb661f5de24a4b94ac8e330c502d391e","placeholder":"​","style":"IPY_MODEL_ee610b54de85438baf36cc3d13753d89","value":"Map: 100%"}},"6ec8f012b3be419a9426866e0853db06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d38ba24f88d8413aadc54fd867665966","max":660,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08782b0ddcdc4eaa8bfa345abd2496d1","value":660}},"af7497424ded49dda52192fd228b211f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a6d70879e2346b9bbb5d96db2a2be7b","placeholder":"​","style":"IPY_MODEL_bf35a626b762404ba8254b28135d38fd","value":" 660/660 [00:03&lt;00:00, 211.43 examples/s]"}},"3f27cfb282db49cb889cddcc2af00dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb661f5de24a4b94ac8e330c502d391e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee610b54de85438baf36cc3d13753d89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d38ba24f88d8413aadc54fd867665966":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08782b0ddcdc4eaa8bfa345abd2496d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a6d70879e2346b9bbb5d96db2a2be7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf35a626b762404ba8254b28135d38fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f0d0831a8f4a69abcb7c1bf143fded":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_432297a5dbed491eb9dc63c160703409","IPY_MODEL_be2897b2218845b287d29eae7cd23650","IPY_MODEL_272205d6af4b46cca2e2db7096ff9b0c"],"layout":"IPY_MODEL_1b06954472e24bc499fb2c278350cd88"}},"432297a5dbed491eb9dc63c160703409":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64937d9d6ca449fd93b66e6e3de2f7cc","placeholder":"​","style":"IPY_MODEL_cf9684913e3a44dea5fa3d7d0002b2cd","value":"Map: 100%"}},"be2897b2218845b287d29eae7cd23650":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae72c930e4a42ef817dc49bf754eac7","max":139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbbef8bbc597481f9571aed448d1abbb","value":139}},"272205d6af4b46cca2e2db7096ff9b0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0824990860e244098c949f3cc031db3e","placeholder":"​","style":"IPY_MODEL_d815b985225c457e8380b76514d9977c","value":" 139/139 [00:00&lt;00:00, 194.91 examples/s]"}},"1b06954472e24bc499fb2c278350cd88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64937d9d6ca449fd93b66e6e3de2f7cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf9684913e3a44dea5fa3d7d0002b2cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ae72c930e4a42ef817dc49bf754eac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbbef8bbc597481f9571aed448d1abbb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0824990860e244098c949f3cc031db3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d815b985225c457e8380b76514d9977c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}