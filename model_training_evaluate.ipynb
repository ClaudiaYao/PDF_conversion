{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ensure that the imported .py file will get auto imported and updated whenever there is a change\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' \n",
        "\n",
        "# # global_attention_mask will be prepared in the same segments\n",
        "# global_attention_mask = torch.zeros_like(input_ids)\n",
        "# # set global_attention_mask on first token or only the top layer first token?\n",
        "# according to https://github.com/huggingface/transformers/issues/18190, As you are running summarization, it is LEDForConditionalGeneration. For this model, we should put 1 for the global_attention_mask on the first token <s> in the encoder input sequence.\n",
        "https://discuss.huggingface.co/t/flan-t5-t5-what-is-the-difference-between-automodelforseq2seqlm-and-t5forconditionalgeneration/29225/5\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "# !pip install datasets\n",
        "!pip install rouge_score\n",
        "# !pip install sentencepiece\n",
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbxlvBEhC-kO",
        "outputId": "faebd136-d3f6-4d9b-aa34-09c270578605"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Claud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, logging\n",
        "# from nltk.tokenize import word_tokenize #Used to extract words from documents\n",
        "# from nltk.stem import WordNetLemmatizer #Used to lemmatize words\n",
        "# from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import tqdm as notebook_tqdm\n",
        "# import textwrap\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "from transformers import LEDForConditionalGeneration, LEDTokenizer\n",
        "from datasets import load_dataset, load_metric\n",
        "import torch\n",
        "from rouge import Rouge\n",
        "from rouge_score import rouge_scorer\n",
        "import datasets\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "pd.options.display.max_colwidth = 1000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_V2cOEPzSe5U"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_input_length = 8192\n",
        "max_output_length = 512\n",
        "batch_size = 2\n",
        "\n",
        "project_path = os.getcwd()\n",
        "project_data_path = project_path + \"/data\"\n",
        "project_processed_data_path = project_path + \"/processed\"\n",
        "if not os.path.exists(project_data_path):\n",
        "    os.makedirs(project_data_path)\n",
        "if not os.path.exists(project_processed_data_path):\n",
        "    os.makedirs(project_processed_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding = \"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "      \n",
        "# FConvert JSON dictionary structure to a plain dataset with only two columns - Text, and Groundtruth\n",
        "def convert_dict_to_dataset(section, result):\n",
        "    content = section.get(\"Text\")\n",
        "    ground_truth = section.get(\"Groundtruth\")\n",
        "    result.append({\"Text\": content, \"Groundtruth\": ground_truth})\n",
        "    \n",
        "    if \"Subsections\" in section and len(section['Subsections']) > 0:\n",
        "        for subsection in section[\"Subsections\"]:\n",
        "            convert_dict_to_dataset(subsection, result)\n",
        "    return result \n",
        "\n",
        "def convert_json_to_csv_wrapper(json_file_full_name, converted_file_full_name):\n",
        "    if not os.path.exists(json_file_full_name):\n",
        "        print(\"the json file does not exist.\")\n",
        "        return\n",
        "\n",
        "    record_list = load_data(json_file_full_name)\n",
        "    result = []\n",
        "    for item in record_list:\n",
        "        convert_dict_to_dataset(item, result)\n",
        "\n",
        "    data = pd.DataFrame(result)\n",
        "    data.to_csv(converted_file_full_name, index=False)\n",
        "    print(\"converted to csv file - {}\".format(converted_file_full_name))\n",
        "    display(data.head())\n",
        "\n",
        "convert_json_to_csv_wrapper(project_path + \"/dataset/dataset_ground_truth.json\", project_path + \"/dataset/training.csv\")\n",
        "convert_json_to_csv_wrapper(project_path + \"/dataset/dataset_eval_ground_truth.json\", project_path + \"/dataset/eval.csv\")\n",
        "convert_json_to_csv_wrapper(project_path + \"/dataset/dataset_test_ground_truth.json\", project_path + \"/dataset/test.csv\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(project_path + \"/dataset/training.csv\")\n",
        "train_df.dropna(inplace=True)\n",
        "val_df = pd.read_csv(project_path + \"/dataset/eval.csv\")\n",
        "val_df.dropna(inplace=True)\n",
        "display(train_df.head())\n",
        "display(val_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text_len = train_df['Text'].str.len()\n",
        "plt.hist(text_len, bins = 20)\n",
        "plt.title(\"Text Length Distribution\")\n",
        "plt.xlabel(\"Text (char) Length\")\n",
        "plt.ylabel(\"Sample Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(train_dataset.shape, val_dataset.shape)\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.select(range(100))\n",
        "val_dataset = val_dataset.select(range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Define the sequence length for the model.\n",
        "# seq_length=1024\n",
        "max_input_length = 8192\n",
        "max_output_length = 512\n",
        "batch_size = 2\n",
        "\n",
        "\n",
        "#Define the Model\n",
        "class Model_operation:  \n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
        "\n",
        "    def __init__(self, model_name):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "        self.model = LEDForConditionalGeneration.from_pretrained(model_name).to(DEVICE)\n",
        "        self.config = LEDForConditionalGeneration.from_pretrained(model_name).config\n",
        "        print(\"config:\", self.config)\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()        \n",
        "\n",
        "    # tokenize the data\n",
        "    def process_data_to_model_inputs(self, batch):\n",
        "        inputs = self.tokenizer(\n",
        "            batch['Text'],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_input_length,\n",
        "        )\n",
        "        outputs = self.tokenizer(\n",
        "            batch['Groundtruth'],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_output_length,\n",
        "        )\n",
        "\n",
        "        batch[\"input_ids\"] = inputs.input_ids\n",
        "        batch[\"attention_mask\"] = inputs.attention_mask\n",
        "\n",
        "        print(\"input_ids shape:\", len(batch[\"input_ids\"]), len(batch[\"input_ids\"][0]))\n",
        "\n",
        "        # create 0 global_attention_mask lists\n",
        "        batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
        "            [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
        "        ]\n",
        "      # according to https://github.com/huggingface/transformers/issues/18190, As you are running summarization, it is LEDForConditionalGeneration. For this model, we should put 1 for the global_attention_mask on the first token <s> in the encoder input sequence.\n",
        "        batch[\"global_attention_mask\"][:, 0] = 1\n",
        "        batch[\"labels\"] = outputs.input_ids\n",
        "        # We have to make sure that the PAD token is ignored by setting it to -100\n",
        "        batch[\"labels\"] = [\n",
        "            [-100 if token == self.tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "        return batch\n",
        "\n",
        "    \n",
        "    # Function to train model\n",
        "    def train_and_validate_model(self, train_ds, validate_ds):\n",
        "      total_loss = 0.0  # Initialize total loss\n",
        "      self.model.train()\n",
        "\n",
        "\n",
        "\n",
        "        # get the input_ids, tokenized content text, label text\n",
        "        # self.tokenize_sections(data, results)\n",
        "        # added by me\n",
        "        # print(\"data from train_loading:\", data, len(results), results)\n",
        "        # for result in results:\n",
        "          ids = data[\"input_ids\"]\n",
        "          am = data[\"attention_mask\"]\n",
        "          gam = data['global_attention_mask']\n",
        "          labels = data[\"labels\"]\n",
        "          output = self.model(input_ids = ids, attention_mask = am, labels = labels, global_attention_mask = gam, use_cache = False)\n",
        "\n",
        "          # need to check how to express this\n",
        "          loss = output.loss\n",
        "          logits = outputs.logits\n",
        "          logits_flat = logits.view(-1, logits.size(-1))\n",
        "          labels_flat = labels.view(-1)\n",
        "\n",
        "        # Backward pass\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "      return total_loss\n",
        "    \n",
        "\n",
        "    # Function to calculate ROUGE scores for generated summary and ground truth\n",
        "    def calculate_rouge_scores(self, generated_summary, ground_truth_summary): \n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        scores = scorer.score(generated_summary, ground_truth_summary)\n",
        "        rouge1_f1 = scores['rouge1'].fmeasure\n",
        "        rouge2_f1 = scores['rouge2'].fmeasure\n",
        "        rougeL_f1 = scores['rougeL'].fmeasure\n",
        "        return rouge1_f1, rouge2_f1, rougeL_f1\n",
        "    \n",
        "    # Function to evaluate model using val set\n",
        "    def validate_model(self, val_loader):\n",
        "        val_loss=0.0\n",
        "        total_rouge1_f1 = 0.0\n",
        "        total_rouge2_f1 = 0.0\n",
        "        total_rougeL_f1 = 0.0\n",
        "        num_samples = 0\n",
        "      \n",
        "      # model. eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode. torch. no_grad() impacts the autograd engine and deactivate it.\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        for val_data in val_loader:\n",
        "          val_results = []\n",
        "          self.tokenize_sections(val_data, val_results)\n",
        "          for val_result in val_results:\n",
        "            input_ids = val_result[\"input_ids\"]\n",
        "            attention_mask = val_result[\"attention_mask\"]\n",
        "            labels = val_result[\"labels\"]\n",
        "            loss,logits = self.forward(input_ids, attention_mask, labels)\n",
        "            val_loss +=loss.item()      \n",
        "\n",
        "            # Decode the predicted summary\n",
        "            predicted_token_probs = torch.softmax(logits[0], dim=-1)\n",
        "            predicted_summary_ids = torch.argmax(predicted_token_probs, dim=-1).tolist()\n",
        "            predicted_summary = tokenizer.decode(predicted_summary_ids, skip_special_tokens=True)\n",
        "            ground_truth_summary = tokenizer.decode(labels[0], skip_special_tokens=True) \n",
        "\n",
        "            # Calculate ROUGE scores\n",
        "            rouge1_f1, rouge2_f1, rougeL_f1 = model_summarizer.calculate_rouge_scores(predicted_summary, ground_truth_summary)\n",
        "\n",
        "            # Accumulate ROUGE scores   \n",
        "            total_rouge1_f1 += rouge1_f1\n",
        "            total_rouge2_f1 += rouge2_f1\n",
        "            total_rougeL_f1 += rougeL_f1\n",
        "            num_samples += 1\n",
        "\n",
        "        return val_loss,total_rouge1_f1,total_rouge2_f1,total_rougeL_f1,num_samples\n",
        "    \n",
        "    #Function to test the model using test dataset\n",
        "    def test_model(self,section, model):\n",
        "        \n",
        "      section_summary_results = {}\n",
        "      content = section[\"Text\"]\n",
        "      section_name = section[\"Section\"]\n",
        "      ground_truth_summary = section.get(\"Groundtruth\")[0]\n",
        "      if content and ground_truth_summary:\n",
        "        # Tokenize the content\n",
        "\n",
        "        inputs = self.tokenizer(content, return_tensors=\"pt\", max_length=seq_length, truncation=True)\n",
        "        labels = self.tokenizer(ground_truth_summary, return_tensors=\"pt\", max_length=seq_length, truncation=True)[\"input_ids\"]\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].to(self.DEVICE)\n",
        "        attention_mask = inputs[\"attention_mask\"].to(self.DEVICE)\n",
        "        labels = labels.to(self.DEVICE)\n",
        "\n",
        "        # model. eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode. torch. no_grad() impacts the autograd engine and deactivate it.\n",
        "        model_summarizer.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outputs = self.model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=labels)\n",
        "\n",
        "          logits = outputs.logits\n",
        "          # Apply softmax to convert logits to probabilities\n",
        "          probs = torch.softmax(logits[0], dim=-1)          \n",
        "          generated_ids = torch.argmax(probs, dim=-1)\n",
        "\n",
        "          # Decode the generated summary using the tokenizer\n",
        "          summary_text = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "          ground_truth_summary = tokenizer.decode(labels[0], skip_special_tokens=True)\n",
        "\n",
        "            # Calculate ROUGE scores\n",
        "          rouge1_f1, rouge2_f1, rougeL_f1 = model_summarizer.calculate_rouge_scores(summary_text, ground_truth_summary)\n",
        "\n",
        "        section_summary_results[\"Section Name\"] = section_name\n",
        "        section_summary_results[\"Generated Summary\"] = summary_text\n",
        "        section_summary_results[\"ROUGE-1 F1\"] = rouge1_f1\n",
        "        section_summary_results[\"ROUGE-2 F1\"] = rouge2_f1\n",
        "        section_summary_results[\"ROUGE-L F1\"] = rougeL_f1\n",
        "        \n",
        "        print(\"Section Name: \", section_name)\n",
        "        wrapped_output = textwrap.fill(str(summary_text), width=80)\n",
        "        print(\"Generated Summary: \", wrapped_output)\n",
        "\n",
        "        if \"Subsections\" in section:\n",
        "          for subsection in section[\"Subsections\"]:\n",
        "            model_summarizer.test_model(subsection,model)\n",
        "\n",
        "      return section_summary_results\n",
        "\n",
        "    \n",
        "    \n",
        "    def log_metrics(self,epoch, train_loss, val_loss, rouge_scores):\n",
        "      log_file = \"logs/metrics_log.txt\"\n",
        "      with open(log_file, \"a\") as f:        \n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        log_str = f\"{timestamp}, Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, ROUGE: {rouge_scores}\\n\"\n",
        "        f.write(log_str)\n",
        "        \n",
        "\n",
        "\n",
        "#Model Inference\n",
        "#Generate Summary for the content using the loaded model\n",
        "    def generate_summary(self,content):\n",
        "        max_length=300\n",
        "        num_beams=4\n",
        "        inputs = self.tokenizer(content, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "        summary_ids = self.model.generate(inputs.input_ids.to(DEVICE), max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
        "        summary_text = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        return summary_text\n",
        "\n",
        "#Parse each sections and subsection to generate summaries from the model\n",
        "    def process_section(self,section,results,modelsummarizer): \n",
        "        # Process the content of the each section\n",
        "        section_summary_results = {}\n",
        "        content = section[\"Text\"]\n",
        "        section_name=section[\"Section\"]\n",
        "        summary_text = model_summarizer.generate_summary(modelsummarizer,content)\n",
        "        section_summary_results[\"Section Name\"] = section_name\n",
        "        section_summary_results[\"Generated Summary\"] = summary_text\n",
        "        results.append(section_summary_results)\n",
        "        print(\"Section Name: \", section_name)\n",
        "        wrapped_output = textwrap.fill(str(summary_text), width=80)\n",
        "        print(\"Generated Summary: \", wrapped_output)\n",
        "        # Process the subsections if they exist\n",
        "        if \"Subsections\" in section:\n",
        "            for subsection in section[\"Subsections\"]:\n",
        "                model_summarizer.process_section(subsection,results,modelsummarizer)\n",
        "            \n",
        "    # Summarize the section contents and subsection contents\n",
        "    def summarize_pdf(pdf_data, output_file,modelsummarizer):\n",
        "        all_results = []\n",
        "        for section in pdf_data:\n",
        "            model_summarizer.process_section(section,all_results,modelsummarizer)\n",
        "        \n",
        "        with open(output_file, \"w\") as json_file:\n",
        "            json.dump(all_results, json_file, indent=4)    \n",
        "        \n",
        "    \n",
        "# model_name = \"allenai/led-large-16384-arxiv\"\n",
        "# model_summarizer = SummarizationModel(model_name)\n",
        "# model = model_summarizer.model\n",
        "# tokenizer = model_summarizer.tokenizer    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import LEDForConditionalGeneration, LEDTokenizer\n",
        "import torch\n",
        "\n",
        "# pretrained_model_name = \"allenai/led-large-16384-arxiv\"\n",
        "\n",
        "model_action = Model_operation()\n",
        "train_dataset = train_dataset.map(\n",
        "    model_action.process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_dataset = val_dataset.map(\n",
        "    model_action.process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "# tokenizer = LEDTokenizer.from_pretrained(pretrained_model_name)\n",
        "# model = LEDForConditionalGeneration.from_pretrained(pretrained_model_name, return_dict_in_generate=True, gradient_checkpointing=True, use_cache=False)\n",
        "# model.state_dict()\n",
        "# config = LEDForConditionalGeneration.from_pretrained(pretrained_model_name).config\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=0.01)\n",
        "# criterion = torch.nn.CrossEntropyLoss()  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        ")\n",
        "val_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set generate hyperparameters\n",
        "model_action.config.num_beams = 2\n",
        "model_action.config.max_length = 512\n",
        "model_action.config.min_length = 100\n",
        "model_action.config.length_penalty = 2.0\n",
        "model_action.config.early_stopping = True\n",
        "model_action.config.no_repeat_ngram_size = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# json_dict = load_data(project_path + \"/dataset/dataset_ground_truth.json\")\n",
        "# train_data = pd.read_csv(project_processed_data_path + '/1901.00936v3.csv')\n",
        "train_data = pd.read_csv(project_path + \"/dataset/test.csv\")\n",
        "train_data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# refer to this post for the model training\n",
        "# https://huggingface.co/allenai/led-large-16384-arxiv\n",
        "# https://colab.research.google.com/drive/12INTTR6n64TzS4RrXZxMSXfrOd9Xzamo?usp=sharing\n",
        "# the above two examples are both about generating (inference)\n",
        "# This page is the entry point for this model !!! https://huggingface.co/docs/transformers/en/model_doc/led\n",
        "#the LEDTokenizer is just a alias of BertTokenizer: https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/bart#transformers.BartTokenizer\n",
        "# check this post \"a notebook showing how to fine tune LED\" from page https://huggingface.co/docs/transformers/en/model_doc/led\n",
        "# about dataset and dataloader and using dataset.map method https://www.scaler.com/topics/pytorch/map-style-vs-itetrable-datasets/\n",
        "\n",
        "# def training_one_section(text, ground_truth):\n",
        "#     if text and ground_truth:\n",
        "#         # since it is long text, it might be separated into multiple input_ids, that is, multiple sequences\n",
        "      #   input_ids = tokenizer(text, return_tensors=\"pt\", max_length=max_input_length).input_ids\n",
        "      #   # global_attention_mask will be prepared in the same segments\n",
        "      #   global_attention_mask = torch.zeros_like(input_ids)\n",
        "      #   # set global_attention_mask on first token\n",
        "      #   global_attention_mask[:, 0] = 1\n",
        "\n",
        "      #   label = tokenizer(ground_truth, return_tensors=\"pt\", max_length=seq_length, truncation=True)[\"input_ids\"]\n",
        "        \n",
        "      #   print(\"starting training:\", len(input_ids), global_attention_mask.shape)\n",
        "      #   outputs = model(input_ids=input_ids,\n",
        "      #                       attention_mask=global_attention_mask,\n",
        "      #                       labels=label)\n",
        "      #   logits = outputs.logits\n",
        "      #   logits_flat = logits.view(-1, logits.size(-1))\n",
        "      #   labels_flat = label.view(-1)\n",
        "      #   loss = criterion(logits_flat, labels_flat)\n",
        "          \n",
        "      # return loss,logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_data_to_model_inputs(text, ground_truth):\n",
        "    # tokenize the inputs and labels\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    )\n",
        "    outputs = tokenizer(\n",
        "        ground_truth,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_output_length,\n",
        "    )\n",
        "\n",
        "    input_ids = inputs.input_ids\n",
        "    print(\"input_ids shape:\", len(input_ids), len(input_ids[0]))\n",
        "    attention_mask = inputs.attention_mask\n",
        "\n",
        "    # create 0 global_attention_mask lists\n",
        "    global_attention_mask = len(input_ids) * [\n",
        "        [0 for _ in range(len(input_ids[0]))]\n",
        "    ]\n",
        "\n",
        "    # # global_attention_mask will be prepared in the same segments\n",
        "    # global_attention_mask = torch.zeros_like(input_ids)\n",
        "    # # set global_attention_mask on first token\n",
        "    # global_attention_mask[:, 0] = 1\n",
        "    \n",
        "\n",
        "    # since above lists are references, the following line changes the 0 index for all samples\n",
        "    global_attention_mask[0][0] = 1\n",
        "    labels = outputs.input_ids\n",
        "\n",
        "    # We have to make sure that the PAD token is ignored by setting it to -100\n",
        "    labels = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        for labels in labels\n",
        "    ]\n",
        "\n",
        "    return input_ids, global_attention_mask, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_sample(model, input_ids, global_attention_mask, labels):\n",
        "        outputs = model(input_ids=input_ids,\n",
        "                            attention_mask=global_attention_mask,\n",
        "                            labels=labels)\n",
        "        logits = outputs.logits\n",
        "        logits_flat = logits.view(-1, logits.size(-1))\n",
        "        labels_flat = labels.view(-1)\n",
        "        loss = criterion(logits_flat, labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load training data\n",
        "# train_data = load_data(train_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = tokenizer(LONG_ARTICLE, return_tensors=\"pt\").input_ids\n",
        "global_attention_mask = torch.zeros_like(input_ids)\n",
        "# set global_attention_mask on first token\n",
        "global_attention_mask[:, 0] = 1   \n",
        "\n",
        "sequences = model.generate(input_ids, global_attention_mask=global_attention_mask).sequences\n",
        "\n",
        "summary = tokenizer.batch_decode(sequences)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
