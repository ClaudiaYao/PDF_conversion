{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# ensure that the imported .py file will get auto imported and updated whenever there is a change\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in c:\\users\\wang zihan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.24.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.1 in c:\\users\\wang zihan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyMuPDF) (1.24.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'c:\\users\\wang zihan\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbxlvBEhC-kO",
        "outputId": "faebd136-d3f6-4d9b-aa34-09c270578605"
      },
      "outputs": [],
      "source": [
        "\n",
        "import fitz\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_V2cOEPzSe5U"
      },
      "outputs": [],
      "source": [
        "\n",
        "project_path = os.getcwd()\n",
        "project_data_path = project_path + \"/data\"\n",
        "project_processed_data_path = project_path + \"/processed\"\n",
        "if not os.path.exists(project_data_path):\n",
        "    os.makedirs(project_data_path)\n",
        "if not os.path.exists(project_processed_data_path):\n",
        "    os.makedirs(project_processed_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9of1D8dKPfj",
        "outputId": "7540a334-3420-47bb-e006-4d1dcd168097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\Wang\n",
            "[nltk_data]     Zihan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to C:\\Users\\Wang\n",
            "[nltk_data]     Zihan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Wang\n",
            "[nltk_data]     Zihan\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize #Used to extract words from documents\n",
        "from nltk.stem import WordNetLemmatizer #Used to lemmatize words\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 1000\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import processing_pdf\n",
        "pd.options.display.max_colwidth = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto generated table of content:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 'I Introduction', 1],\n",
              " [1, 'II Related work', 2],\n",
              " [1, 'III Our proposed method', 2],\n",
              " [2, 'III-A Density map estimation', 2],\n",
              " [2, 'III-B Method overview', 3],\n",
              " [2, 'III-C Backbone sub-network', 3],\n",
              " [2, 'III-D Mask prediction branch', 3],\n",
              " [2, 'III-E Mask-aware density density regressor', 4],\n",
              " [2, 'III-F Implementation details', 5],\n",
              " [1, 'IV Experiment', 5],\n",
              " [2, 'IV-A Evaluation metrics ', 5],\n",
              " [2, 'IV-B Datasets', 5],\n",
              " [2, 'IV-C Analysis of the proposed approaches', 6],\n",
              " [2, 'IV-D Ablation study', 6],\n",
              " [2, 'IV-E Comparison with the state-of-the-art', 8],\n",
              " [1, 'V Conclusion', 8],\n",
              " [1, 'References', 9]]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pdf_file =  \"An Empirical Survey on Long Document Summarization.pdf\"\n",
        "# pdf_file = \"1901.00009v1.pdf\"\n",
        "# pdf_file = \"1901.00936v3.pdf\"\n",
        "# pdf_file = \"an image is worth 16 by 16 words.pdf\"\n",
        "pdf_file = \"1901.00039v2.pdf\"\n",
        "doc, total_text, total_pages = processing_pdf.open_file(project_data_path + \"/\" + pdf_file)\n",
        "table_of_content = doc.get_toc()\n",
        "print(\"Auto generated table of content:\")\n",
        "display(table_of_content)\n",
        "\n",
        "# some papers have not table of content\n",
        "if len(table_of_content) == 0:\n",
        "    print(\"The paper has not table of content. Need to use regular expression to map table of content.\")\n",
        "    res = processing_pdf.auto_find_toc(doc)\n",
        "    print(\"Not satified the generated result or want to adjust? Build your own table of content by using this template:\")\n",
        "    display(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting looking for all the sections according to the provided section title info...\n",
            "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2.csv\n",
            "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2_meta.csv\n",
            "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2.json\n",
            "\n",
            "Title: Mask-aware networks for crowd counting\n",
            "\n",
            "Authors:Shengqin Jiang, Xiaobo Lu, Yinjie Lei, Lingqiao Liu\n",
            "\n",
            "Other info: \n",
            "\n",
            "Abstract:—Crowd counting problem aims to count the numberof objects within an image or a frame in the videos and is usuallysolved by estimating the density map generated from the objectlocation annotations. The values in the density map, by nature,take two possible states: zero indicating no object around, anon-zero value indicating the existence of objects and the valuedenoting the local object density. In contrast to traditional meth-ods which do not differentiate the density prediction of these twostates, we propose to use a dedicated network branch to predictthe object/non-object mask and then combine its prediction withthe input image to produce the density map. Our rationale isthat the mask prediction could be better modeled as a binarysegmentation problem and the difﬁculty of estimating the densitycould be reduced if the mask is known. A key to the proposedscheme is the strategy of incorporating the mask predictioninto the density map estimator. To this end, we study ﬁvepossible solutions, and via analysis and experimental validationwe identify the most effective one. Through extensive experimentson ﬁve public datasets, we demonstrate the superior performanceof the proposed approach over the baselines and show that ournetwork could achieve the state-of-the-art performance. Index Terms—Crowd counting; mask-aware network; densitymap; regression\n"
          ]
        }
      ],
      "source": [
        "#uncomment this list to customize table-of-content\n",
        "# table_of_content = [[1, 'I. INTRODUCTION', 1],\n",
        "#  [1, 'II. SFC BASED ON IPV6 SEGMENT ROUTING', 2],\n",
        "#  [1, 'III. DESIGN OF THE SRV6 PROXY', 4],\n",
        "#  [2, 'A. General Concepts and State-of-the-art', 4],\n",
        "#  [2, 'B. SRNKv1', 5],\n",
        "#  [2, 'C. SRNKv2', 7],\n",
        "#  [2, 'D. Implementation of other SR proxy types', 8],\n",
        "#  [1, 'IV. TESTING ENVIRONMENT', 8],\n",
        "#  [1, 'V. PERFORMANCE ANALYSIS', 9],\n",
        "#  [1, 'VII. CONCLUSIONS', 11]]\n",
        "\n",
        "# separate content into sections\n",
        "processing_pdf.clear_processed_folder(project_processed_data_path)\n",
        "title, authors, other_info, abstract = processing_pdf.find_meta_data(doc, table_of_content)\n",
        "df_meta = pd.DataFrame([title, abstract]).T\n",
        "df_meta.columns = [\"Title\", \"Abstract\"]\n",
        "ds, json_dict = processing_pdf.separate_content(total_text, table_of_content)\n",
        "processing_pdf.save_dataframe(ds, df_meta, json_dict, project_processed_data_path,  pdf_file.rsplit(\".\", 1)[0])\n",
        "# extract images\n",
        "processing_pdf.find_images(doc, table_of_content, total_pages, project_processed_data_path)\n",
        "\n",
        "# display(ds)\n",
        "print(f\"\\nTitle: {title}\")\n",
        "print(f\"\\nAuthors:{authors}\")\n",
        "print(f\"\\nOther info: {other_info}\")\n",
        "print(f\"\\nAbstract:{abstract}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'I',\n",
              " 'Section': 'I Introduction',\n",
              " 'Text': 'c rowd counting is a signicant topic for crowd un- derstanding and analysis , which has attracted much attention in multimedia and computer vision community due to large and practical demands for better management, safety and security , . it aims to count the number of objects within an image or a frame in the videos and is a very challenging problem because the objects-of-interest, e.g., people, can occur at a variety of scales, with heavy occlusions and cluttered visual appearances. also, due to the difculty in providing highly detailed annotations such as object bounding boxes or instance-level segmentation masks, existing datasets usually adopt a weak-level annotating scheme by labeling each object with a dot inside. these challenges make the traditional detection based approach less robust and most existing methods choose to solve this problem by estimating a density map generated from the dot-level annotation. once the density map is correctly estimated, the this work is done when the rst author visits the university of adelaide. s. jiang is with the school of automatic, southeast university, nanjing , china; the school of computer science, university of adelaide, adelaide, sa , australia; the key laboratory of measurement and control of complex systems of engineering, ministry of education, nanjing , china e-mail: . x. lu are with the school of automatic, southeast university, nanjing , china; key laboratory of measurement and control of complex systems of engineering, ministry of education, nanjing , china e- mail: . y. lei is with the college of electronics and information engineering, sichuan university, chengdu , china . l. liu is with the school of computer science, university of adelaide, adelaide, sa , australia . object count can be obtained by simply summing over the density values in the map. in the current density map annotation scheme, the values in the density map are all non-negative and only pixels close to an annotated dot can have nonzero values. in other words, a density value could exhibit two states: zero indicating no objects within its neighborhood; a non-zero value indicating the existence of objects with the value denoting the local object density. in fact, for the density maps of many images, a signicant portion of pixels will only take the zero value. the above observation suggests that the density map es- timation implicitly involves two steps: estimating whether a pixel belongs to the foreground or background (object/non- object) and estimating the density value of the foreground region. certainly, these two steps can be achieved by a single density map estimator which is trained with the traditional regression objectives, e.g., mean square error, as in the existing approaches. however, in this paper, we argue the benets of explicitly separating the mask prediction from the density estimation. more specically, we propose to use a dedicated branch of a network to rst predict the foreground/background mask, and then fuse the prediction with the input image to produce the nal density map estimation. the motivation of this strategy is that the rst step is essentially a binary segmentation problem and it can be better trained with seg- mentation loss such as cross-entropy loss. on the other hand, conditioned on the prediction of the mask, the estimation of the density map can be simpler than its unconditioned counterpart. consequently, the overall regression quality could be improved. the critical question of the above-proposed process is how to incorporate the mask prediction information into the density map estimator. in this paper, we study ve different variants for achieving this incorporation. specically, in the proposed ve solutions, we consider the following factors and their combinatorial effects: the representation of mask information. should we use the binary form of the mask prediction or the predicted mask posterior, i.e., the probability of a pixel being the foreground. the way to incorporate the mask information. by simply multiplying the estimated mask or fusing this part of information with a neural network. we analyze, both theoretically and experimentally, the pros and cons of the proposed methods and identify the last one as our best solution. more specically, in this solution, we feed the estimated object posterior into a few convolutional layers and together with the information from the input image to produce the nal density map. through extensive experiments on ve public datasets, we demonstrate the superior performance of the proposed approach over the competitive baseline and show that our method can achieve the state-of-the-art crowd counting performance. arxiv:v jun ieee transactions on circuits and systems for video technology in sum, the contributions of this paper are threefold: we propose a strategy to separately model the fore- ground/background mask with a dedicated neural network branch and training objective. we study ve different solutions of incorporating the mask prediction information into the overall density map estimation and identify the most effective one. the proposed method achieves the state-of-the-art crowd counting performance on various datasets.',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'II',\n",
              " 'Section': 'II Related work',\n",
              " 'Text': 'to date, many approaches have been proposed to study the issues existing in crowd counting , . here we present a brief review of the related work. for a more detailed survey of crowd counting, we refer the readers to , , . detection seems to be a straightforward solution for crowd counting. the most early methods use hand-crafted features such as haar wavelets , histogram oriented gradients to model the pedestrian, which are then fed to classiers to distinguish whether there is pedestrian or not. initially, , studied the monocular pedestrian detection by a diverse set of low-level feature-based systems. although monocular- based methods work well in a low density region, the perfor- mance is severely affected when they meet the crowded scenes with occlusion and scene clutter. to further consider this issue, more information of the pedestrian is taken into account. zhao et al. used multiple partially occluded human hypotheses in a bayesian framework to build a model-based approach to interpret the image observations. the authors in extracted the foreground and then aggregated the obtained silhouettes over a network to compute bounds about the crowd number and locations. nevertheless, the representation ability of the low-level features is limited, which cannot be applied in many real scenarios. recently, many approaches resort to application of the cnn-based detectors such as faster rcnn , yolo , ssd , which are trained end to end and have a good generalization compared with the traditional ones. these methods make a great progress in terms of detection performance and speed. however, for a heavily occluded and cluttered scenario, accurately detecting each object instance is still very difcult. as a alternative solution of the detection-based methods, the regression-based approaches are proposed to tackle the extremely dense crowds. initially, these approaches learn a mapping or relation between the features of local patches and the counts. actually, they avoid learning some independent detectors. for example, the authors proposed to cast the crowd counting problem as a density map estimation problem. the integral of the image density over any image region gives the count of objects within that region. it was shown that the density map regression framework offers a robust crowd counting solution for various challenging scenarios, and since then it becomes the mainstream framework for this problem. various extensions have been proposed to further improve the training and prediction of density maps. ma et al. studied an integer programming method for estimating the instantaneous count of pedestrians crossing a line of interest in a video sequence. idrees et al. argued that it is not reliable by only using one single feature or detection method for counting task when facing the high- level density crowds. and they also reported that the spatial relationship is an importance information to constrain the counts in neighboring local regions. chen et al. studied the challenges of inconsistent features along with sparse and imbalanced data, and proposed to learn a regression model by using cumulative attribute-based representation. with the breakthrough of deep learning in the past years, most recent works on crowd counting are based on convolu- tional neural networks. the authors in built an end-to-end cnn regression model to count the people in extremely crowd scenes. in the same year, proposed a deep cnn method, which is trained alternatively with two related learning objec- tives, crowd density estimation, and crowd count estimation. later, introduced a cnn architecture that is fed with a whole image and directly outputs the nal count. to address the large variations in people or head size, exploited a multi-column neural network by using receptive elds of different sizes in each column. the authors proposed a path switching architecture, called switching- cnn, to deal with the variation of object density within a scene. in order to gain better performance, proposed a contextual pyramid cnn by incorporating different levels of contextual information to achieve state-of-the-art performance. at the same time, more recent works , have gained promising results and advanced the development of crowd counting. in this paper, we propose a mask-aware network for crowd counting which incorporates the background/foreground mask information into the network for more accurate density re- gression. in terms of the network architecture design, our network is somehow similar to the recent work , which utilizes the top-down feedback to correct the initial prediction. however, our approach considers the background/foreground mask information and we will show later in the experiments that this consideration is crucial for achieving our good per- formance. in terms of using mask information, there has been some successful cases in the areas of object segmentation and person re-identication , . however, to our knowledge, our work is the rst one that systematically studies the effect of mask-aware networks for crowd counting.',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'III',\n",
              " 'Section': 'III Our proposed method',\n",
              " 'Text': 'a. density map estimation before elaborating the design of our network, we rst briey introduce the creation of the ground-truth density maps and the related training losses. this paper considers the case that a point-wise annotation is provided for training images. specically, a dot is annotated within each object-of-interest, i.e., people head. this pointwise annotation is further converted into a density map: d = x xia g(x xi ), ieee transactions on circuits and systems for video technology fig. an overview of our proposed method. it contains three modules: the backbone, the mask prediction branch and the mask-aware density regression branch. where x rdenotes the image coordinate and xi denotes the annotated head location. g( xxi ) denotes a gaussian kernel with xi as the mean vector and as the empirically chosen variance term. a typical choice of will make g( xxi ) = if x is not within the local neighborhood of xi. it is also easy to verify that the integral of d over x equals to the total number of objects. thus the counting problem can be cast as a density regression problem and the mean square loss is usually employed to train the regressor: lr = x x d) , where f is the regression network and denotes the model parameters. b. method overview the overview of the proposed method is shown in figure for the clarity of presentation, we divide the network into three parts: a backbone subnetwork b, a mask prediction branch g and the mask-aware density regressor r. the backbone generates the feature representation of the input image and is shared across all the mask-aware density regressors as discussed below. the mask prediction branch predicts the fore- ground/background mask. the mask-aware density regressor is the key contribution of this paper and ve different designs will be presented in this section. as mentioned in the introduction section, the value of d takes two possible states: with a zero value indicating no object around while with a nonzero value indicating the existence of object, and for a large portion of x its corresponding d is zero. this observation inspires us to design a dedicated branch of a neural network to predict the foreground/background mask and we train this branch as a binary segmentation network. then we can utilize the mask prediction information to guide the overall density estimation. formally this process is denoted as g, b), where i denotes the input image and the training objective can be written as: lm , m) + lr , b), d) , where lm is the loss function for evaluating the perfor- mance of mask prediction; lr is the loss function for evaluat- ing the overall density estimation; m, d are the groundtruth of the mask and the density map, respectively. the ground- truth mask is dened as m = sign). more specif- ically, the mask is used to distinguish the background and foreground, which means the threshold is that is, if the counting number of each pixel is greater than , the pixel is then classied to , otherwise, (i.e., background); is a trade-off parameter. c. backbone sub-network the architecture of the backbone sub-network is shown in figure . it consists of two parts. the rst part is a typical multi-layer cnn and the second part is similar to the blocks in the inception network . the layers of rst part are c-c-mp-c-c- mp-c where c denotes the convolution layer with x channels of input, y channels of output and z z convolution kernel and mp denotes max pooling. the second part has two identical units (the structure of each unit is shown in figure ) and its purpose is to encourage the network using information from different scales. this is in a spirit similar to the design of multi-column cnn (mcnn ). however, our backbone only adopts multiple scale paths at the second part and uses the separable convolution layers( and ) as shown in figure . one empirically suggests that the backbone is completely superior to mcnn in terms of the performance . the above proposed sub-network is a light-weight strategy which is completely trained from scratch. to further verify the following proposed solution is not specialized for the proposed sub-network, we also employ a pre-trained vgg model as our backbone to train our solution followed by the state-of- the-art model csrnet . d. mask prediction branch the mask prediction branch consists of multiple convolu- tional layers. specically, the architecture could be denoted as c-c. in our implementation, we can train the mask prediction branch with focal loss as the training objective lm. it is calculated by applying the sigmoid function to the output activation of the mask prediction branch. as reported in , focal loss is designed ieee transactions on circuits and systems for video technology fig. the architecture of the backbone subnetwork. m denotes pooling operation and c denotes concatenation of the features. to tackle the imbalance between foreground and background during training.in most crowd scenarios, there may exist the imbalance issues. but we nd it does not make much difference in our experiment when using the focal loss and traditional binary cross-entropy loss, which will be reported in section iv. here, we use focal loss as a general setting for cross-entropy loss. that is, lm is binary cross-entropy loss when = note that traditional single branch density map estimation networks still need to determine whether a pixel belongs to the foreground or background. they achieve this capability by using the mse loss while our mask pre- diction branch utilizes the cross-entropy loss (with the focal loss) which is generally considered as a better objective for segmentation tasks. e. mask-aware density density regressor the ways of incorporating the mask prediction information into the density regression are critical in our proposed method. in the following part, we consider ve possible solutions. solution by denition, the mask indicates which part of density should be nonzero/zero. thus a straightforward way to fuse mask information with the density map estimation is to elementwisely multiply the estimated density map by the estimated mask. our rst solution uses this scheme, as shown in figure . at the training stage, the training goal of the mask prediction branch to produce the ground-truth mask. thus we directly multiply the density map from the density estimation branch with the ground-truth mask at the training stage. note that this solution essentially requires the density estimation branch only focuses on the estimation of the density in the foreground region. while being conceptually straightforward, this solution, however, ignores the possible connection between the mask prediction branch and density estimation branch. noted that the gradient of the lr will not pass through the mask predic- tion branch at the training time. this suggests that these two branches are essentially trained independently with separated objectives. solution to facilitate the connection between the prediction branch and the density estimation branch, we modify solution fig. five different architectures for the mask-aware density regressor. , and use element-wise product to incorporate the predicted mask information, where uses the groundtruth mask, directly uses the predicted mask posterior and uses ste function to backpropagate the gradient; and fuse the information from predicted mask by several convolutional layers, where uses groundtruth mask but using predicted mask for test, and learns the mask-image features from the output of mask prediction in an end-to-end fashion. and propose the second solution as shown in figure . the difference is that instead of using the ground-truth mask we use the estimated posterior of the foreground (the soft version of the mask prediction) to multiply the output of the density estimation branch. in this case, the gradient loss lr can backpropagate to the mask prediction branch, making it jointly adapt with the density estimation branch to produce the nal estimation. solution in solution , the nal density prediction is the multiplication of the posterior and the output of the density estimation branch. since the value of the posterior is between and it is not a perfect mask and could make the estimation sensitive to the condence of mask prediction. to overcome this drawback, we propose to multiply the predicted binary mask instead. the generation of the mask involves a non- differentiable hard-thresholding operation. to backpropagate ieee transactions on circuits and systems for video technology the gradient, we adopt the straight-through estimator (ste for short) to approximate this operator as shown in figure . formally, in the forward calculation, the predicted mask used in the multiplication is obtained via mi = h), where h returns if the p is greater than , otherwise in backpropagation, we approximate the gradient as mi ) the schematic illustration of this solution is shown in figure . solution the above two designs are based on the el- ementwise product operation to merge the information of mask prediction, which can be quite restrictive and potentially sensitive to the mask prediction quality. here we propose an alternative solution as shown in figure . the idea is to use several convolutional layers to map the mask into a feature map which can be further concatenated with the image features to perform the density estimation. similar to solution , we can use the ground-truth mask at the training time and replace it with the predicted ones at the test stage. in this design, we use one channel of ground truth mask to generate a feature map with channels, and then we concatenate the channels from previous layers as the input for the last density map regressor. finally, the architecture of the density map regressor is c-c-c. solution similar to the solution , we could further improve solution by using the estimated posterior probability to replace the predicted mask. this allows joint training of all the components of the network. the structure of this solution is shown in figure . since this structure learns the incorporation operation through a set of convolutional layers rather than a simple elementwise product, we postulate that it can be less sensitive to the value of posterior estimation. f. implementation details our proposed method is trained from scratch based on the pytorch framework. firstly, we generate the ground truth following from previous method by using a gaussian kernel. we x the kernel size for all datasets to generate the density map although using geometry-adaptive kernel for different datasets might further improve prediction performance. for the proposed multi-scale backbone shown in figure , we randomly mirror the cropped training images and their associated gt on the y. whats more, the initialization of the network is drawn from normal distribution with standard deviation. in order to gain a quicker training speed, the adam optimizer is used to train the network before th epoch and then switch to mini-batch stochastic gradient descent . the learning rate is initially set to e- and then is decreased by a factor of every epochs. as for using pre-trained vgg as backbone, we use original images as training dataset without data augmentation unless otherwise stated. in our experiments, we use sgd optimizer train the network for the datasets with different size of images and the rest ones use adam optimizer. in addition, we use standard cross-entropy loss for all the experiments.',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'IV',\n",
              " 'Section': 'IV Experiment',\n",
              " 'Text': 'in this section, we conduct experiments on three challenging public datasets to demonstrate the effectiveness our proposed method including shanghaitech dataset , ucf cc dataset and worldexpo dataset . the purposes of our experiments are threefold: verify if the proposed mask-aware strategies lead to signicant improvement over the baselines. identify the most effective mask-aware den- sity estimation solution. compare our proposed approach against the state-of-the-art methods. in our experiments, we use shanghaitech dataset a to achieve the rst and the second objective. the identied best-performed solution will then be compared against the state-of-the-art on all three datasets. in what follows, we present the evaluation criterion and datasets in our experiments. then we present a detailed anal- ysis of the proposed solutions and identify the most effective one. finally, we compare our method with other state-of-the- art methods. a. evaluation metrics we use mean absolute error and mean square error as the evaluation metrics. the two metrics are dened as follows: mae = n n x i= |pri gti| and mse = v u u t n n x i= , where n is the number of the images in the test dataset, and pri denotes the predicted object count obtained from the network for the i-th image while gti denotes the ground truth count of the i-th image. more specically, pri equals to the sum of values in the estimated density map. b. datasets shanghaitech dataset. this is a large-scale crowd counting dataset, which contains images with , annotated heads. it is split into two parts: part a has images randomly collected from the internet including images for training and the rest for testing, and part b contains images taken from busy streets of metropolitan in shanghai, and with images for training and the remaining images for testing. we randomly crop patches from each training image with the resolution of ucf cc dataset. the ucf cc dataset has only images captured from various perspectives, which is a very challenging counting dataset introduced by . on average, it contains persons per image ranging from to we crop patches from each image to train both methods as this dateset is too small, and followed by , -fold cross- validation is used to evaluate our proposed method. worldexpo the worldexpo is the largest cross- scene crowd counting dataset introduced by , . it ieee transactions on circuits and systems for video technology table i the experimental comparison on the baselines and five proposed methods on shanghai part a. solution - corresponds to the architectures in figure method mae mse baseline baseline our proposed solution our proposed solution our proposed solution our proposed solution our proposed solution table ii the experimental comparison on baselines, our proposed method and csrnet on shanghai part a. method mae mse baseline our proposed solution csrnet our model csr consists of annotated video shot by surveillance cameras from shanghai worldexpo. there are frames uniformly sampled from the videos sequences, where frames are used for training and the rest for testing. the number of pedestrians ranges from to different from the above datasets, the region of interest is provided for the images in the dataset. during data preprocessing, we mask each frame and its corresponding density map with roi. c. analysis of the proposed approaches this paper proposes ve different designs for the mask- aware density regressor. its effectiveness will be examined in this subsection. we use solution - to denote the proposed architectures shown in figure besides these solutions, we also compare our method against three baselines (baseline - ) to verify the benet of introducing mask-aware network design. the baselines are: baseline is a simply backbone subnetwork plus the density estimation branch as in solution - the purpose of presenting this baseline is to examine if adding mask branch and mask-aware density regressor can indeed lead to improvement. baseline is a deeper version of baseline we notice that our solution and essentially use deeper networks for density regression. thus it is fair to compare against a baseline with the comparable depth. the experiment results of the above methods are summa- rized in table from the results, we could make the following observations. the proposed solution does not lead to the improved performance over baseline which is comparable to it in terms of the network depth. on the contrary, it worsens the density estimation performance. in comparison, solution leads to signicant performance improvement. comparing with baseline , it reduces the estimation error by in mae and mse. this observation suggests that it is inappropriate to treat the mask prediction and density prediction independently. it is crucial to train those two tasks jointly. somewhat surprising, the proposed solution has no signicant improvement. we postulate that it is due to the difculty in optimizing the non-differentiable operator despite the fact that we have already approximated it by the straight- through estimator. solution also leads to an improved performance over baselines, although the improvement over its comparable method, baseline , is marginal. note that solution does not utilize the joint training strategy and the mask-aware density regressor will receive different mask inputs (ground truth and predicted) at the training and testing stage respectively. however, this limit does not prevent the method from gaining performance improvement. this may suggest that using con- volutional layers to combine the mask prediction information is more robust than the elementwise product. our last solution further achieves signicant perfor- mance improvement over solution and baseline it reduces the mae from in baseline to . this again shows the benet of joint training and the power of using convolutional layers for information fusion. d. ablation study to have more insights into our proposed method, we con- duct ablation studies of the proposed method on the part one of shanghaitech a dataset. the main studies and ndings are presented below. to understand the effect of segmentation branch, we set a new baseline . this baseline uses identical network structure as our solution , but replaces the target of the mask prediction by density regression. in this way, the structure is similar to that in . this baseline is to verify whether the improvement of the proposed method merely comes from the architecture, or the mask prediction objective. from table ii, it is not hard to conclude that our best- performed solution still achieves signicant improvement over baseline recall that the difference between solution and baseline is that the former adopts the mask prediction as the training objective. the performance discrepancy of these two methods suggests that using mask information could indeed benet the density estimation. the improvement of our method does not solely come from the network structure. in figure , we also visualize the estimated density maps of our best-performed method and baseline approaches. from , it is interesting to nd that although the proposed approach gives more accurate count estimation, it does not provide a visibly better foreground/background separation than the baselines. this may suggest that the benet of introducing the mask objective is not as simple as providing a better foreground/background separation. we postulate that the better performance achieved by our approach is due to that its density value estimation becomes more accurate with the guidance of the mask prediction. we also conduct a comparison experiment between binary cross entropy loss and focal loss. the result shows that the network with binary cross entropy loss can achieve almost ieee transactions on circuits and systems for video technology fig. a comparison of the density map generated by our best-performed method and two baselines in shanghaitech part a. the same performance: mae: , mse: compared with that of the solution so focal loss in this paper is a general setting for the mask branch. to compare the considered model with different back- bones, we construct a new network with the same network structure in the solution on top of a recent state-of-the-art network . to distinguish our proposed baseline, we term this network as our method csr for short. as shown in table ii, we can see our method csr can achieve a promising improvement over the original csrnet. to some extent, it indicates that a good baseline with the exploited network structure can boost the performance. also note that the pre- trained model can be easily trained in a simple setting as shown in sec. iii compared to our proposed model trained from scratch. we argue that the main benets derives from the pre-trained vgg compared with csrnet, our proposed baseline is more computationally efcient. to show the interactions among the roi mask, input and density regression, we visualize the feature maps among those layers in figure we use the test images) in the part a of shanghaitech dataset.we nd that there exist mask errors after the sigmoid layer of the segmentation branch as shown in figure we randomly selected one feature map after feeding back the predicted mask posterior. interestingly, from figure , it can be seen that the errors in the mask prediction are suppressed in the sampled feature map. this suggests that the network has the capability of separating the error pattern at the mask prediction stage into different feature maps and potentially suppressing the error signal for density estimation. after the fusion of the two branches, each feature map in the regressor only focuses on a small part of the interest region shown in figure from the above discussion, we can see that even though there exist mask errors in the mask branch, they will not magnify in the next stage. finally, we get a rened density map as shown in figure here we argue that the mask error will not magnify in the next stage. as is known, there are different density levels in the crowd. so we conduct the comparative experiment with three levels on shanghaitech part a to show the improvement of our method. we split the density into three types of crowd: low crowd , middle crowd and high crowd. from figure , it is easily concluded that the proposed method achieves a promising result on the low and middle level of crowd. this is because the proposed segmentation branch has the ability to discriminate background and foreground. as for high-level crowd, it poses a challenging situation for most methods. the texture information of the crowd people are missing in those scenes so it is really hard to exact robust features for each head. as a result, we can not see clear ieee transactions on circuits and systems for video technology fig. the visualization of feature maps in the mask branch. is the input image; is the output in segmentation branch; is randomly selected feature map from the feedback convolution layers of the segmentation branch; is randomly selected feature map after concatenating the feedback of segmentation branch; is the nal predicted density map. fig. the average mae of different density levels tested on shanghaitech part a. promotion in this interval. as for the our method with pre- trained model, we can see that it has a similar improvement in low and middle crowds compared to the model with the proposed backbone while it also achieves a good result in high crowd. we conjecture that the pre-trained backbone has more prior knowledge to capture the texture information in high density level crowd than the model trained from scratch. e. comparison with the state-of-the-art we further compare our best-performed solution against the state-of-the-art results in various datasets. firstly, we make a comparison on the part a and part b of the shanghaitech dataset. we compare our method against cc-counting , fcn , mcnn, tdf-net , switching-net , (ba- net for short), netvlad , cp-cnn and csrnet . the results are summarized in table we can see that our method also achieves competitive results with the state-of-the-art methods and while keeping economic parameters. it is noted that the number of parameters of our proposed method is less than million while the number in the cp-cnn is million. so our method is more parameter economic and potentially more efcient. as for our method csr surpasses the two methods signicantly in this dataset. specically, the mae of part a is , which outperforms that of the csrnet by about . in terms of the mse, our proposed method shows signicant improvement over csrnet by %. in part b, we also see that our method csr achieves % in mae and % in mse improvement compared to csrnet on part b. these results show the benets of our proposed strategy in such a high variance scene. in addition, we report the results of our approach on ucf cc dataset in table our method obtains a improvement in mae over cp-cnn but is worse than csr- net. we argue that the main reason lies in that the pre- trained model enjoys more prior information compared with our model trained from scratch especially in such a small dataset. instead, our model csr armed with pre-trained vgg is superior to other models in mae. it should be noted that it shows and improvement over csrnet in terms of mae and mse, respectively. finally, we present the results of our method on the world- expo dataset as shown in table v. our method with light weight achieves a relatively good performance which is on par with the state-of-the-art methods like tdf-net, netvlad, and classical methods mcnn and cc- counting but it is inferior to csrnet and cp-cnn. besides, our model csr precedes csrnet and cp-cnn while obtaining the rst place in s, s and s scenes.',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'V',\n",
              " 'Section': 'V Conclusion',\n",
              " 'Text': 'in this paper, we address the crowd counting problem with deep neural networks. our main discovery is the benet ieee transactions on circuits and systems for video technology table iii the performance comparison on the shanghaitech dataset. part a part b method mae mse mae mse cc-counting fcn mcnn tdf-net switching-net ba-cnn netvlad cp-cnn csrnet our method our model csr table iv the performance comparison on the ucf cc dataset. method mae mse cc-counting fcn mcnn tdf-net switching-net ba-cnn netvlad cp-cnn csrnet our method our model csr table v the performance comparison on the worldexpo dataset. method s s s s s avg cc-counting mcnn tdf-net switching-net ba-cnn netvlad cp-cnn csrnet our method our model csr of using a dedicated network branch to predict the fore- ground/background mask and incorporating mask prediction into density map estimation. we systematically study ve different designs of the mask-aware density estimator and identify the best performed solution. through the experimental validation, we show that the proposed scheme is effective and achieves the state-of-the-art crowd counting performance on various datasets. acknowledgment the authors would like to thank the editor and the anony- mous reviewers for their valuable comments and constructive suggestions. this work is supported by the scientic re- search foundation of graduate school of southeast university , the postgraduate research & practice inno- vation program of jiangsu province , the national natural science foundation of china , key research and development program in jiangsu province and a project funded by the priority aca- demic program development of jiangsu higher education institutions.',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'References',\n",
              " 'Section': 'References',\n",
              " 'Text': '] wongun choi and silvio savarese, understanding collective activitiesof people from videos, ieee transactions on pattern analysis and machine intelligence, vol. , no. , pp. , jing shao, chen change loy, kai kang, and xiaogang wang, crowded scene understanding by deeply learned volumetric slices, ieee trans- actions on circuits and systems for video technology, vol. , no. , pp. , siyu huang, xi li, zhongfei zhang, fei wu, shenghua gao, rongrong ji, and junwei han, body structure aware deep crowd counting, ieee transactions on image processing, vol. , no. , pp. , yuke li, a deep spatiotemporal perspective for understanding crowd behavior, ieee transactions on multimedia, cong zhang, kai kang, hongsheng li, xiaogang wang, rong xie, and xiaokang yang, data-driven crowd understanding: a baseline for a large-scale crowd dataset, ieee transactions on multimedia, vol. , no. , pp. , vishwanath a sindagi and vishal m patel, a survey of recent advances in cnn-based single image crowd counting and density estimation, pattern recognition letters, vol. , pp. , shaoqing ren, kaiming he, ross girshick, and jian sun, faster r-cnn: towards real-time object detection with region proposal networks, in advances in neural information processing systems, , pp. wei liu, dragomir anguelov, dumitru erhan, christian szegedy, scott reed, cheng-yang fu, and alexander c berg, ssd: single shot multibox detector, in european conference on computer vision. springer, , pp. joseph redmon, santosh divvala, ross girshick, and ali farhadi, you only look once: unied, real-time object detection, in ieee conference on computer vision and pattern recognition, , pp. jianan li, xiaodan liang, jianshu li, yunchao wei, tingfa xu, jiashi feng, and shuicheng yan, multistage object detection with group recursive learning, ieee transactions on multimedia, vol. , no. , pp. , yingying zhang, desen zhou, siqin chen, shenghua gao, and yi ma, single-image crowd counting via multi-column convolutional neural network, in ieee conference on computer vision and pattern recog- nition, , pp. chuan wang, hua zhang, liang yang, si liu, and xiaochun cao, deep people counting in extremely dense crowds, in acm international conference on multimedia. acm, , pp. deepak babu sam, shiv surya, and r venkatesh babu, switching convolutional neural network for crowd counting, in ieee conference on computer vision and pattern recognition, , vol. , p. weina ge and robert t collins, marked point processes for crowd counting, in ieee conference on computer vision and pattern recognition. ieee, , pp. weina ge, robert t collins, and r barry ruback, vision-based analysis of small groups in pedestrian crowds, ieee transactions on pattern analysis and machine intelligence, vol. , no. , pp. , haroon idrees, khurram soomro, and mubarak shah, detecting humans in dense crowds using locally-consistent scale prior and global occlusion reasoning, ieee transactions on pattern analysis and machine intelligence, vol. , no. , pp. , daniel onoro-rubio and roberto j l opez-sastre, towards perspective- free object counting with deep learning, in european conference on computer vision. springer, , pp. chen change loy, ke chen, shaogang gong, and tao xiang, crowd counting and proling: methodology and evaluation, in modeling, simulation and visual analysis of crowds, pp. springer, gaurav tripathi, kuldeep singh, and dinesh kumar vishwakarma, convolutional neural networks for crowd behaviour analysis: a survey, the visual computer, pp. , paul viola and michael j jones, robust real-time face detection, international journal of computer vision, vol. , no. , pp. , ieee transactions on circuits and systems for video technology navneet dalal and bill triggs, histograms of oriented gradients for human detection, in ieee conference on computer vision and pattern recognition. ieee, , vol. , pp. markus enzweiler and dariu m gavrila, monocular pedestrian detec- tion: survey and experiments, ieee transactions on pattern analysis and machine intelligence, , no. , pp. , tao zhao, ram nevatia, and bo wu, segmentation and tracking of multiple humans in crowded environments, ieee transactions on pattern analysis and machine intelligence, vol. , no. , pp. , danny b yang, leonidas j guibas, et al., counting people in crowds with a real-time network of simple image sensors, in null. ieee, , p. shaoqing ren, kaiming he, ross girshick, and jian sun, faster r-cnn: towards real-time object detection with region proposal networks, ieee transactions on pattern analysis and machine intelligence, , no. , pp. , victor lempitsky and andrew zisserman, learning to count objects in images, in advances in neural information processing systems, , pp. antoni b chan and nuno vasconcelos, counting people with low- level features and bayesian regression, ieee transactions on image processing, vol. , no. , pp. , zheng ma and antoni b chan, crossing the line: crowd counting by integer programming with local features, in ieee conference on computer vision and pattern recognition, , pp. haroon idrees, imran saleemi, cody seibert, and mubarak shah, multi-source multi-scale counting in extremely dense crowd images, in ieee conference on computer vision and pattern recognition, , pp. ke chen, shaogang gong, tao xiang, and chen change loy, cumu- lative attribute space for age and crowd density estimation, in ieee conference on computer vision and pattern recognition, , pp. cong zhang, hongsheng li, xiaogang wang, and xiaokang yang, cross-scene crowd counting via deep convolutional neural networks, in ieee conference on computer vision and pattern recognition, , pp. vishwanath a sindagi and vishal m patel, generating high-quality crowd density maps using contextual pyramid cnns, in ieee interna- tional conference on computer vision. ieee, , pp. viresh ranjan, hieu le, and minh hoai, iterative crowd counting, arxiv preprint arxiv:, zan shen, yi xu, bingbing ni, minsi wang, jianguo hu, and xiaokang yang, crowd counting via adversarial cross-scale consistency pursuit, in ieee conference on computer vision and pattern recognition, , pp. zenglin shi, le zhang, yun liu, xiaofeng cao, yangdong ye, ming- ming cheng, and guoyan zheng, crowd counting with deep negative correlation learning, in ieee conference on computer vision and pattern recognition, , pp. yuhong li, xiaofan zhang, and deming chen, csrnet: dilated convo- lutional neural networks for understanding the highly congested scenes, in ieee conference on computer vision and pattern recognition, , pp. deepak babu sam and r venkatesh babu, top-down feedback for crowd counting convolutional neural network, arxiv preprint arxiv:, kaiming he, georgia gkioxari, piotr doll ar, and ross girshick, mask r-cnn, in ieee international conference on computer vision. ieee, , pp. pengyuan lyu, minghui liao, cong yao, wenhao wu, and xiang bai, mask textspotter: an end-to-end trainable neural network for spotting text with arbitrary shapes, arxiv preprint arxiv:, christian szegedy, vincent vanhoucke, sergey ioffe, jon shlens, and zbigniew wojna, rethinking the inception architecture for computer vision, in ieee conference on computer vision and pattern recogni- tion, , pp. tsung-yi lin, priyal goyal, ross girshick, kaiming he, and piotr doll ar, focal loss for dense object detection, ieee transactions on pattern analysis and machine intelligenc, yoshua bengio, nicholas l eonard, and aaron courville, estimating or propagating gradients through stochastic neurons for conditional computation, arxiv preprint arxiv:, mark marsden, kevin mcguinness, suzanne little, and noel e oconnor, fully convolutional crowd counting on highly congested scenes, arxiv preprint arxiv:, zenglin shi, le zhang, yibo sun, and yangdong ye, multiscale multitask deep netvlad for crowd counting, ieee transactions on industrial informatics, vol. , no. , pp. ,',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'Section_Num': 'No_title',\n",
              " 'Section': 'No_title',\n",
              " 'Text': 'ieee transactions on circuits and systems for video technology mask-aware networks for crowd counting shengqin jiang, xiaobo lu, yinjie lei, lingqiao liu abstractcrowd counting problem aims to count the number of objects within an image or a frame in the videos and is usually solved by estimating the density map generated from the object location annotations. the values in the density map, by nature, take two possible states: zero indicating no object around, a non-zero value indicating the existence of objects and the value denoting the local object density. in contrast to traditional meth- ods which do not differentiate the density prediction of these two states, we propose to use a dedicated network branch to predict the object/non-object mask and then combine its prediction with the input image to produce the density map. our rationale is that the mask prediction could be better modeled as a binary segmentation problem and the difculty of estimating the density could be reduced if the mask is known. a key to the proposed scheme is the strategy of incorporating the mask prediction into the density map estimator. to this end, we study ve possible solutions, and via analysis and experimental validation we identify the most effective one. through extensive experiments on ve public datasets, we demonstrate the superior performance of the proposed approach over the baselines and show that our network could achieve the state-of-the-art performance. index termscrowd counting; mask-aware network; density map; regression',\n",
              " 'Subsections': [],\n",
              " 'Groundtruth': ''}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# open json file\n",
        "with open(project_processed_data_path + \"/1901.00039v2.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for item in data:\n",
        "        display(item)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
