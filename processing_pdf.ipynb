{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# ensure that the imported .py file will get auto imported and updated whenever there is a change\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in c:\\users\\claud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.0 in c:\\users\\claud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from PyMuPDF) (1.24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbxlvBEhC-kO",
        "outputId": "faebd136-d3f6-4d9b-aa34-09c270578605"
      },
      "outputs": [],
      "source": [
        "\n",
        "import fitz\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_V2cOEPzSe5U"
      },
      "outputs": [],
      "source": [
        "\n",
        "project_path = os.getcwd()\n",
        "project_data_path = project_path + \"/data\"\n",
        "project_processed_data_path = project_path + \"/processed\"\n",
        "if not os.path.exists(project_data_path):\n",
        "    os.makedirs(project_data_path)\n",
        "if not os.path.exists(project_processed_data_path):\n",
        "    os.makedirs(project_processed_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9of1D8dKPfj",
        "outputId": "7540a334-3420-47bb-e006-4d1dcd168097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Claud\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Claud\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Claud\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize #Used to extract words from documents\n",
        "from nltk.stem import WordNetLemmatizer #Used to lemmatize words\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 1000\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import processing_pdf\n",
        "pd.options.display.max_colwidth = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto generated table of content:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The paper has not table of content. Need to use regular expression to map table of content.\n",
            "starting looking for all the sections...\n",
            "Not satified the generated result or want to adjust? Build your own table of content by using this template:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 'I. INTRODUCTION', 1],\n",
              " [1, 'IV. Sections', 2],\n",
              " [1, '5. The', 7],\n",
              " [1, 'IV. TESTING ENVIRONMENT', 8],\n",
              " [1, 'V. PERFORMANCE ANALYSIS', 9],\n",
              " [1, 'VII. CONCLUSIONS', 11]]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pdf_file =  \"An Empirical Survey on Long Document Summarization.pdf\"\n",
        "# pdf_file = \"1901.00009v1.pdf\"\n",
        "pdf_file = \"1901.00936v3.pdf\"\n",
        "doc, total_text, total_pages = processing_pdf.open_file(project_data_path + \"/\" + pdf_file)\n",
        "table_of_content = doc.get_toc()\n",
        "print(\"Auto generated table of content:\")\n",
        "display(table_of_content)\n",
        "\n",
        "# some papers have not table of content\n",
        "if len(table_of_content) == 0:\n",
        "    print(\"The paper has not table of content. Need to use regular expression to map table of content.\")\n",
        "    res = processing_pdf.auto_find_toc(doc)\n",
        "    print(\"Not satified the generated result or want to adjust? Build your own table of content by using this template:\")\n",
        "    display(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#uncomment this list to customize table-of-content\n",
        "table_of_content = [[1, 'I. INTRODUCTION', 1],\n",
        " [1, 'II. SFC BASED ON IPV6 SEGMENT ROUTING', 2],\n",
        " [1, 'III. DESIGN OF THE SRV6 PROXY', 4],\n",
        " [2, 'A. General Concepts and State-of-the-art', 4],\n",
        " [2, 'B. SRNKv1', 5],\n",
        " [2, 'C. SRNKv2', 7],\n",
        " [2, 'D. Implementation of other SR proxy types', 8],\n",
        " [1, 'IV. TESTING ENVIRONMENT', 8],\n",
        " [1, 'V. PERFORMANCE ANALYSIS', 9],\n",
        " [1, 'VII. CONCLUSIONS', 11]]\n",
        "\n",
        "# separate content into sections\n",
        "processing_pdf.clear_processed_folder(project_processed_data_path)\n",
        "ds, json_dict = processing_pdf.separate_content(total_text, table_of_content)\n",
        "processing_pdf.save_dataframe(ds, json_dict, project_processed_data_path,  pdf_file.rsplit(\".\", 1)[0])\n",
        "# extract images\n",
        "processing_pdf.find_images(doc, table_of_content, total_pages, project_processed_data_path)\n",
        "\n",
        "display(ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# open json file\n",
        "with open(project_processed_data_path + \"/1901.00936v3.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for item in data:\n",
        "        display(item)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
