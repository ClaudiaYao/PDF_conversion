{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer #Used to lemmatize words\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "import processing_pdf\n",
    "from model_summarizer.ModelSummarizer import SummarizationModel, load_data\n",
    "from gpt_summary import get_summaries\n",
    "from generate_ppt import *\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"1901.00039v2\"\n",
    "summary_models = [\"allenai/led-large-16384-arxiv\", \"gpt-3.5-turbo-0125\"]\n",
    "model_name = summary_models[0]\n",
    "use_gpt_ppt_parsing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Processing PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = f\"{filename}.pdf\"\n",
    "project_path = os.getcwd()\n",
    "project_data_path = project_path + \"/data\"\n",
    "project_processed_data_path = project_path + \"/processed\"\n",
    "if not os.path.exists(project_data_path):\n",
    "    os.makedirs(project_data_path)\n",
    "if not os.path.exists(project_processed_data_path):\n",
    "    os.makedirs(project_processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto generated table of content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'I Introduction', 1],\n",
       " [1, 'II Related work', 2],\n",
       " [1, 'III Our proposed method', 2],\n",
       " [2, 'III-A Density map estimation', 2],\n",
       " [2, 'III-B Method overview', 3],\n",
       " [2, 'III-C Backbone sub-network', 3],\n",
       " [2, 'III-D Mask prediction branch', 3],\n",
       " [2, 'III-E Mask-aware density density regressor', 4],\n",
       " [2, 'III-F Implementation details', 5],\n",
       " [1, 'IV Experiment', 5],\n",
       " [2, 'IV-A Evaluation metrics ', 5],\n",
       " [2, 'IV-B Datasets', 5],\n",
       " [2, 'IV-C Analysis of the proposed approaches', 6],\n",
       " [2, 'IV-D Ablation study', 6],\n",
       " [2, 'IV-E Comparison with the state-of-the-art', 8],\n",
       " [1, 'V Conclusion', 8],\n",
       " [1, 'References', 9]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, total_text, total_pages = processing_pdf.open_file(project_data_path + \"/\" + pdf_file)\n",
    "\n",
    "# Use processing_pdf.auto_find_toc(), which will clean up the original toc\n",
    "# table_of_content = doc.get_toc()\n",
    "table_of_content = processing_pdf.auto_find_toc(doc)\n",
    "display(table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting looking for all the sections according to the provided section title info...\n",
      "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2.csv\n",
      "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2_meta.csv\n",
      "save the dataframe to c:\\Academics\\MSBA Semester 2\\CS5242\\Project\\PDF_conversion/processed/1901.00039v2.json\n",
      "\n",
      "Title: arXiv:1901.00039v2  [cs.CV]  20 Jun 2019\n",
      "\n",
      "Authors:\n",
      "\n",
      "Other info: \n",
      "\n",
      "Abstract:\n"
     ]
    }
   ],
   "source": [
    "#uncomment this list to customize table-of-content\n",
    "# table_of_content = [[1, 'I. INTRODUCTION', 1],\n",
    "#  [1, 'II. SFC BASED ON IPV6 SEGMENT ROUTING', 2],\n",
    "#  [1, 'III. DESIGN OF THE SRV6 PROXY', 4],\n",
    "#  [2, 'A. General Concepts and State-of-the-art', 4],\n",
    "#  [2, 'B. SRNKv1', 5],\n",
    "#  [2, 'C. SRNKv2', 7],\n",
    "#  [2, 'D. Implementation of other SR proxy types', 8],\n",
    "#  [1, 'IV. TESTING ENVIRONMENT', 8],\n",
    "#  [1, 'V. PERFORMANCE ANALYSIS', 9],\n",
    "#  [1, 'VII. CONCLUSIONS', 11]]\n",
    "\n",
    "# separate content into sections\n",
    "processing_pdf.clear_processed_folder(project_processed_data_path)\n",
    "title, authors, other_info, abstract = processing_pdf.find_meta_data(doc, table_of_content)\n",
    "df_meta = pd.DataFrame([title, abstract]).T\n",
    "df_meta.columns = [\"Title\", \"Abstract\"]\n",
    "ds, json_dict = processing_pdf.separate_content(total_text, table_of_content)\n",
    "processing_pdf.save_dataframe(ds, df_meta, json_dict, project_processed_data_path,  pdf_file.rsplit(\".\", 1)[0])\n",
    "# extract images\n",
    "processing_pdf.find_images(doc, table_of_content, total_pages, project_processed_data_path)\n",
    "\n",
    "# display(ds)\n",
    "print(f\"\\nTitle: {title}\")\n",
    "print(f\"\\nAuthors:{authors}\")\n",
    "print(f\"\\nOther info: {other_info}\")\n",
    "print(f\"\\nAbstract:{abstract}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'Abstract',\n",
       " 'Section': 'Abstract',\n",
       " 'Text': 'ieee transactions on circuits and systems for video technology 1 mask-aware networks for crowd counting shengqin jiang, xiaobo lu, yinjie lei, lingqiao liu abstract {em dash}crowd counting problem aims to count the number of objects within an image or a frame in the videos and is usually solved by estimating the density map generated from the object location annotations. the values in the density map, by nature, take two possible states: zero indicating no object around, a non-zero value indicating the existence of objects and the value denoting the local object density. in contrast to traditional methods which do not differentiate the density prediction of these two states, we propose to use a dedicated network branch to predict the object/non-object mask and then combine its prediction with the input image to produce the density map. our rationale is that the mask prediction could be better modeled as a binary segmentation problem and the difficulty of estimating the density could be reduced if the mask is known. a key to the proposed scheme is the strategy of incorporating the mask prediction into the density map estimator. to this end, we study five possible solutions, and via analysis and experimental validation we identify the most effective one. through extensive experiments on five public datasets, we demonstrate the superior performance of the proposed approach over the baselines and show that our network could achieve the state-of-the-art performance. index terms {em dash}crowd counting; mask-aware network; density map; regression',\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'I',\n",
       " 'Section': 'I Introduction',\n",
       " 'Text': 'c rowd counting is a significant topic for crowd understanding and analysis -, which has attracted much attention in multimedia and computer vision community due to large and practical demands for better management, safety and security , . it aims to count the number of objects within an image or a frame in the videos and is a very challenging problem because the objects-of-interest, e.g, people, can occur at a variety of scales, with heavy occlusions and cluttered visual appearances. also, due to the difficulty in providing highly detailed annotations such as object bounding boxes or instance-level segmentation masks, existing datasets usually adopt a weak-level annotating scheme by labeling each object with a dot inside. these challenges make the traditional detection based approach less robust - and most existing methods - choose to solve this problem by estimating a density map generated from the dot-level annotation. once the density map is correctly estimated, the this work is done when the first author visits the university of adelaide. s. jiang is with the school of automatic, southeast university, nanjing 210096, china; the school of computer science, university of adelaide, adelaide, sa 5005, australia; the key laboratory of measurement and control of complex systems of engineering, ministry of education, nanjing 210096, china e-mail: . x. lu are with the school of automatic, southeast university, nanjing 210096, china; key laboratory of measurement and control of complex systems of engineering, ministry of education, nanjing 210096, china email: . y. lei is with the college of electronics and information engineering, sichuan university, chengdu 610064, china . l. liu is with the school of computer science, university of adelaide, adelaide, sa 5005, australia . object count can be obtained by simply summing over the density values in the map. in the current density map annotation scheme, the values in the density map are all non-negative and only pixels close to an annotated dot can have nonzero values. in other words, a density value could exhibit two states: zero indicating no objects within its neighborhood; a non-zero value indicating the existence of objects with the value denoting the local object density. in fact, for the density maps of many images, a significant portion of pixels will only take the zero value. the above observation suggests that the density map estimation implicitly involves two steps: estimating whether a pixel belongs to the foreground or background and estimating the density value of the foreground region. certainly, these two steps can be achieved by a single density map estimator which is trained with the traditional regression objectives, e.g, mean square error, as in the existing approaches. however, in this paper, we argue the benefits of explicitly separating the mask prediction from the density estimation. more specifically, we propose to use a dedicated branch of a network to first predict the foreground/background mask, and then fuse the prediction with the input image to produce the final density map estimation. the motivation of this strategy is that the first step is essentially a binary segmentation problem and it can be better trained with segmentation loss such as cross-entropy loss. on the other hand, conditioned on the prediction of the mask, the estimation of the density map can be simpler than its unconditioned counterpart. consequently, the overall regression quality could be improved. the critical question of the above-proposed process is how to incorporate the mask prediction information into the density map estimator. in this paper, we study five different variants for achieving this incorporation. specifically, in the proposed five solutions, we consider the following factors and their combinatorial effects: the representation of mask information. should we use the binary form of the mask prediction or the predicted mask posterior, i.e, the probability of a pixel being the foreground. the way to incorporate the mask information. by simply multiplying the estimated mask or fusing this part of information with a neural network. we analyze, both theoretically and experimentally, the pros and cons of the proposed methods and identify the last one as our best solution. more specifically, in this solution, we feed the estimated object posterior into a few convolutional layers and together with the information from the input image to produce the final density map. through extensive experiments on five public datasets, we demonstrate the superior performance of the proposed approach over the competitive baseline and show that our method can achieve the state-of-the-art crowd counting performance. arxiv:1901.00039v2 20 jun 2019 ieee transactions on circuits and systems for video technology 2 in sum, the contributions of this paper are threefold: {bullet} we propose a strategy to separately model the foreground/background mask with a dedicated neural network branch and training objective. {bullet} we study five different solutions of incorporating the mask prediction information into the overall density map estimation and identify the most effective one. {bullet} the proposed method achieves the state-of-the-art crowd counting performance on various datasets.',\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'II',\n",
       " 'Section': 'II Related work',\n",
       " 'Text': 'to date, many approaches have been proposed to study the issues existing in crowd counting , -. here we present a brief review of the related work. for a more detailed survey of crowd counting, we refer the readers to , , . detection seems to be a straightforward solution for crowd counting. the most early methods use hand-crafted features such as haar wavelets , histogram oriented gradients to model the pedestrian, which are then fed to classifiers to distinguish whether there is pedestrian or not. initially, , studied the monocular pedestrian detection by a diverse set of low-level feature-based systems. although monocularbased methods work well in a low density region, the performance is severely affected when they meet the crowded scenes with occlusion and scene clutter. to further consider this issue, more information of the pedestrian is taken into account. zhao et al. used multiple partially occluded human hypotheses in a bayesian framework to build a model-based approach to interpret the image observations. the authors in extracted the foreground and then aggregated the obtained silhouettes over a network to compute bounds about the crowd number and locations. nevertheless, the representation ability of the low-level features is limited, which cannot be applied in many real scenarios. recently, many approaches resort to application of the cnn-based detectors such as faster rcnn , yolo , ssd , which are trained end to end and have a good generalization compared with the traditional ones. these methods make a great progress in terms of detection performance and speed. however, for a heavily occluded and cluttered scenario, accurately detecting each object instance is still very difficult. as a alternative solution of the detection-based methods, the regression-based approaches are proposed to tackle the extremely dense crowds. initially, these approaches learn a mapping or relation between the features of local patches and the counts. actually, they avoid learning some independent detectors. for example, the authors proposed to cast the crowd counting problem as a density map estimation problem. the integral of the image density over any image region gives the count of objects within that region. it was shown that the density map regression framework offers a robust crowd counting solution for various challenging scenarios, and since then it becomes the mainstream framework for this problem. various extensions - have been proposed to further improve the training and prediction of density maps. ma et al. studied an integer programming method for estimating the instantaneous count of pedestrians crossing a line of interest in a video sequence. idrees et al. argued that it is not reliable by only using one single feature or detection method for counting task when facing the highlevel density crowds. and they also reported that the spatial relationship is an importance information to constrain the counts in neighboring local regions. chen et al. studied the challenges of inconsistent features along with sparse and imbalanced data, and proposed to learn a regression model by using cumulative attribute-based representation. with the breakthrough of deep learning in the past years, most recent works on crowd counting are based on convolutional neural networks. the authors in built an end-to-end cnn regression model to count the people in extremely crowd scenes. in the same year, proposed a deep cnn method, which is trained alternatively with two related learning objectives, crowd density estimation, and crowd count estimation. later, introduced a cnn architecture that is fed with a whole image and directly outputs the final count. to address the large variations in people or head size, exploited a multi-column neural network by using receptive fields of different sizes in each column. the authors proposed a path switching architecture, called switchingcnn, to deal with the variation of object density within a scene. in order to gain better performance, proposed a contextual pyramid cnn by incorporating different levels of contextual information to achieve state-of-the-art performance. at the same time, more recent works , - have gained promising results and advanced the development of crowd counting. in this paper, we propose a mask-aware network for crowd counting which incorporates the background/foreground mask information into the network for more accurate density regression. in terms of the network architecture design, our network is somehow similar to the recent work , which utilizes the top-down feedback to correct the initial prediction. however, our approach considers the background/foreground mask information and we will show later in the experiments that this consideration is crucial for achieving our good performance. in terms of using mask information, there has been some successful cases in the areas of object segmentation and person re-identification , . however, to our knowledge, our work is the first one that systematically studies the effect of mask-aware networks for crowd counting.',\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'III',\n",
       " 'Section': 'III Our proposed method',\n",
       " 'Text': \"a. density map estimation before elaborating the design of our network, we first briefly introduce the creation of the ground-truth density maps and the related training losses. this paper considers the case that a point-wise annotation is provided for training images. specifically, a dot is annotated within each object-of-interest, i.e, people head. this pointwise annotation is further converted into a density map: d = x xibelong to a g, ieee transactions on circuits and systems for video technology 3 fig. 1. an overview of our proposed method. it contains three modules: the backbone, the mask prediction branch and the mask-aware density regression branch. where x belong to r2denotes the image coordinate and xi denotes the annotated head location. g denotes a gaussian kernel with xi as the mean vector and {greek small letter sigma}2 as the empirically chosen variance term. a typical choice of {greek small letter sigma}2 will make g = 0 if x is not within the local neighborhood of xi. it is also easy to verify that the integral of d over x equals to the total number of objects. thus the counting problem can be cast as a density regression problem and the mean square loss is usually employed to train the regressor: lr = x x -d)2 , where f is the regression network and {greek small letter lamda} denotes the model parameters. b. method overview the overview of the proposed method is shown in figure 1. for the clarity of presentation, we divide the network into three parts: a backbone subnetwork b, a mask prediction branch g and the mask-aware density regressor r. the backbone generates the feature representation of the input image and is shared across all the mask-aware density regressors as discussed below. the mask prediction branch predicts the foreground/background mask. the mask-aware density regressor is the key contribution of this paper and five different designs will be presented in this section. as mentioned in the introduction section, the value of d takes two possible states: with a zero value indicating no object around while with a nonzero value indicating the existence of object, and for a large portion of x its corresponding d is zero. this observation inspires us to design a dedicated branch of a neural network to predict the foreground/background mask and we train this branch as a binary segmentation network. then we can utilize the mask prediction information to guide the overall density estimation. formally this process is denoted as g, b), where i denotes the input image and the training objective can be written as: lm , m) + {greek small letter alpha}lr , b), d) , where lm is the loss function for evaluating the performance of mask prediction; lr is the loss function for evaluating the overall density estimation; m, d are the groundtruth of the mask and the density map, respectively. the groundtruth mask is defined as m = sign). more specifically, the mask is used to distinguish the background and foreground, which means the threshold is 0. that is, if the counting number of each pixel is greater than 0, the pixel is then classified to 1 , otherwise, 0 ; {greek small letter alpha} is a trade-off parameter. c. backbone sub-network the architecture of the backbone sub-network is shown in figure 2 . it consists of two parts. the first part is a typical multi-layer cnn and the second part is similar to the blocks in the inception network . the layers of first part are c-c-mp-c-cmp-c where c denotes the convolution layer with x channels of input, y channels of output and z *z convolution kernel and mp denotes max pooling. the second part has two identical units ) and its purpose is to encourage the network using information from different scales. this is in a spirit similar to the design of multi-column cnn . however, our backbone only adopts multiple scale paths at the second part and uses the separable convolution layers as shown in figure 2 . one empirically suggests that the backbone is completely superior to mcnn in terms of the performance . the above proposed sub-network is a light-weight strategy which is completely trained from scratch. to further verify the following proposed solution is not specialized for the proposed sub-network, we also employ a pre-trained vgg16 model as our backbone to train our solution followed by the state-ofthe-art model csrnet . d. mask prediction branch the mask prediction branch consists of multiple convolutional layers. specifically, the architecture could be denoted as c-c. in our implementation, we can train the mask prediction branch with focal loss as the training objective lm. it is calculated by applying the sigmoid function to the output activation of the mask prediction branch. as reported in , focal loss is designed ieee transactions on circuits and systems for video technology 4 fig. 2. the architecture of the backbone subnetwork. 'm' denotes pooling operation and 'c' denotes concatenation of the features. to tackle the imbalance between foreground and background during training.in most crowd scenarios, there may exist the imbalance issues. but we find it does not make much difference in our experiment when using the focal loss and traditional binary cross-entropy loss, which will be reported in section iv. here, we use focal loss as a general setting for cross-entropy loss. that is, lm is binary cross-entropy loss when {greek small letter gamma} = 0. note that traditional single branch density map estimation networks still need to determine whether a pixel belongs to the foreground or background. they achieve this capability by using the mse loss while our mask prediction branch utilizes the cross-entropy loss which is generally considered as a better objective for segmentation tasks. e. mask-aware density density regressor the ways of incorporating the mask prediction information into the density regression are critical in our proposed method. in the following part, we consider five possible solutions. solution 1. by definition, the mask indicates which part of density should be nonzero/zero. thus a straightforward way to fuse mask information with the density map estimation is to elementwisely multiply the estimated density map by the estimated mask. our first solution uses this scheme, as shown in figure 3 . at the training stage, the training goal of the mask prediction branch to produce the ground-truth mask. thus we directly multiply the density map from the density estimation branch with the ground-truth mask at the training stage. note that this solution essentially requires the density estimation branch only focuses on the estimation of the density in the foreground region. while being conceptually straightforward, this solution, however, ignores the possible connection between the mask prediction branch and density estimation branch. noted that the gradient of the lr will not pass through the mask prediction branch at the training time. this suggests that these two branches are essentially trained independently with separated objectives. solution 2. to facilitate the connection between the prediction branch and the density estimation branch, we modify solution fig. 3. five different architectures for the mask-aware density regressor. , and use element-wise product to incorporate the predicted mask information, where uses the groundtruth mask, directly uses the predicted mask posterior and uses ste function to backpropagate the gradient; and fuse the information from predicted mask by several convolutional layers, where uses groundtruth mask but using predicted mask for test, and learns the mask-image features from the output of mask prediction in an end-to-end fashion. 1 and propose the second solution as shown in figure 3 . the difference is that instead of using the ground-truth mask we use the estimated posterior of the foreground to multiply the output of the density estimation branch. in this case, the gradient loss lr can backpropagate to the mask prediction branch, making it jointly adapt with the density estimation branch to produce the final estimation. solution 3. in solution 2, the final density prediction is the multiplication of the posterior and the output of the density estimation branch. since the value of the posterior is between 0 and 1. it is not a perfect mask and could make the estimation sensitive to the confidence of mask prediction. to overcome this drawback, we propose to multiply the predicted binary mask instead. the generation of the mask involves a nondifferentiable hard-thresholding operation. to backpropagate ieee transactions on circuits and systems for video technology 5 the gradient, we adopt the straight-through estimator to approximate this operator as shown in figure 3 . formally, in the forward calculation, the predicted mask used in the multiplication is obtained via {modifier letter circumflex accent} mi = h), where h returns 1 if the p is greater than 0.5, otherwise 0. in backpropagation, we approximate the gradient as {partial differential} {modifier letter circumflex accent} mi {partial differential}) {almost equal to}1. the schematic illustration of this solution is shown in figure 3 . solution 4. the above two designs are based on the elementwise product operation to merge the information of mask prediction, which can be quite restrictive and potentially sensitive to the mask prediction quality. here we propose an alternative solution as shown in figure 3 . the idea is to use several convolutional layers to map the mask into a feature map which can be further concatenated with the image features to perform the density estimation. similar to solution 1, we can use the ground-truth mask at the training time and replace it with the predicted ones at the test stage. in this design, we use one channel of ground truth mask to generate a feature map with 256 channels, and then we concatenate the 256 channels from previous layers as the input for the last density map regressor. finally, the architecture of the density map regressor is c-c-c. solution 5. similar to the solution 2, we could further improve solution 4 by using the estimated posterior probability to replace the predicted mask. this allows joint training of all the components of the network. the structure of this solution is shown in figure 3 . since this structure learns the incorporation operation through a set of convolutional layers rather than a simple elementwise product, we postulate that it can be less sensitive to the value of posterior estimation. f. implementation details our proposed method is trained from scratch based on the pytorch framework. firstly, we generate the ground truth following from previous method by using a gaussian kernel. we fix the kernel size for all datasets to generate the density map although using geometry-adaptive kernel for different datasets might further improve prediction performance. for the proposed multi-scale backbone shown in figure 2, we randomly mirror the cropped training images and their associated gt on the fly. what's more, the initialization of the network is drawn from normal distribution with 0.01 standard deviation. in order to gain a quicker training speed, the adam optimizer is used to train the network before 11th epoch and then switch to mini-batch stochastic gradient descent . the learning rate is initially set to 1e-5 and then is decreased by a factor of 0.1 every 20 epochs. as for using pre-trained vgg16 as backbone, we use original images as training dataset without data augmentation unless otherwise stated. in our experiments, we use sgd optimizer train the network for the datasets with different size of images and the rest ones use adam optimizer. in addition, we use standard cross-entropy loss for all the experiments.\",\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'IV',\n",
       " 'Section': 'IV Experiment',\n",
       " 'Text': \"in this section, we conduct experiments on three challenging public datasets to demonstrate the effectiveness our proposed method including shanghaitech dataset , ucf cc 50 dataset and worldexpo' 10 dataset . the purposes of our experiments are threefold: verify if the proposed mask-aware strategies lead to significant improvement over the baselines. identify the most effective mask-aware density estimation solution. compare our proposed approach against the state-of-the-art methods. in our experiments, we use shanghaitech dataset a to achieve the first and the second objective. the identified best-performed solution will then be compared against the state-of-the-art on all three datasets. in what follows, we present the evaluation criterion and datasets in our experiments. then we present a detailed analysis of the proposed solutions and identify the most effective one. finally, we compare our method with other state-of-theart methods. a. evaluation metrics we use mean absolute error and mean square error as the evaluation metrics. the two metrics are defined as follows: mae = 1 n n x i=1 |pri -gti| and mse = v u u t 1 n n x i=1 2, where n is the number of the images in the test dataset, and pri denotes the predicted object count obtained from the network for the i-th image while gti denotes the ground truth count of the i-th image. more specifically, pri equals to the sum of values in the estimated density map. b. datasets shanghaitech dataset. this is a large-scale crowd counting dataset, which contains 1198 images with 330,165 annotated heads. it is split into two parts: part a has 482 images randomly collected from the internet including 300 images for training and the rest for testing, and part b contains 716 images taken from busy streets of metropolitan in shanghai, and with 400 images for training and the remaining images for testing. we randomly crop 200 patches from each training image with the resolution of 192 * 160. ucf cc 50 dataset. the ucf cc 50 dataset has only 50 images captured from various perspectives, which is a very challenging counting dataset introduced by . on average, it contains 1280 persons per image ranging from 94 to 4543. we crop 60 patches from each image to train both methods as this dateset is too small, and followed by , 5-fold crossvalidation is used to evaluate our proposed method. worldexpo' 10. the worldexpo' 10 is the largest crossscene crowd counting dataset introduced by , . it ieee transactions on circuits and systems for video technology 6 table i the experimental comparison on the baselines and five proposed methods on shanghai part a. solution 1-5 corresponds to the architectures in figure 3. method mae mse baseline 1 77.25 127.21 baseline 2 74.96 117.72 our proposed solution 1 87.45 128.81 our proposed solution 2 69.77 120.61 our proposed solution 3 76.66 115.40 our proposed solution 4 71.37 111.91 our proposed solution 5 65.74 107.83 table ii the experimental comparison on baselines, our proposed method and csrnet on shanghai part a. method mae mse baseline 3 73.66 120.26 our proposed solution 5 65.74 107.83 csrnet 68.2 115.0 our model csr 61.82 100.01 consists of 1132 annotated video shot by 108 surveillance cameras from shanghai 2010 worldexpo. there are 3980 frames uniformly sampled from the videos sequences, where 3380 frames are used for training and the rest for testing. the number of pedestrians ranges from 1 to 220. different from the above datasets, the region of interest is provided for the images in the dataset. during data preprocessing, we mask each frame and its corresponding density map with roi. c. analysis of the proposed approaches this paper proposes five different designs for the maskaware density regressor. its effectiveness will be examined in this subsection. we use solution 1-5 to denote the proposed architectures shown in figure 1. besides these solutions, we also compare our method against three baselines to verify the benefit of introducing mask-aware network design. the baselines are: {bullet} baseline 1 is a simply backbone subnetwork plus the density estimation branch as in solution 1-2. the purpose of presenting this baseline is to examine if adding mask branch and mask-aware density regressor can indeed lead to improvement. {bullet} baseline 2 is a deeper version of baseline 1. we notice that our solution 4 and 5 essentially use deeper networks for density regression. thus it is fair to compare against a baseline with the comparable depth. the experiment results of the above methods are summarized in table 1. from the results, we could make the following observations. the proposed solution 1 does not lead to the improved performance over baseline 1 which is comparable to it in terms of the network depth. on the contrary, it worsens the density estimation performance. in comparison, solution 2 leads to significant performance improvement. comparing with baseline 1, it reduces the estimation error by 7 in mae and mse. this observation suggests that it is inappropriate to treat the mask prediction and density prediction independently. it is crucial to train those two tasks jointly. somewhat surprising, the proposed solution 3 has no significant improvement. we postulate that it is due to the difficulty in optimizing the non-differentiable operator despite the fact that we have already approximated it by the straightthrough estimator. solution 4 also leads to an improved performance over baselines, although the improvement over its comparable method, baseline 2, is marginal. note that solution 4 does not utilize the joint training strategy and the mask-aware density regressor will receive different mask inputs at the training and testing stage respectively. however, this limit does not prevent the method from gaining performance improvement. this may suggest that using convolutional layers to combine the mask prediction information is more robust than the elementwise product. our last solution 5 further achieves significant performance improvement over solution 4 and baseline 2. it reduces the mae from 74.96 in baseline 2 to 65.74. this again shows the benefit of joint training and the power of using convolutional layers for information fusion. d. ablation study to have more insights into our proposed method, we conduct ablation studies of the proposed method on the part one of shanghaitech a dataset. the main studies and findings are presented below. to understand the effect of segmentation branch, we set a new baseline . this baseline uses identical network structure as our solution 5, but replaces the target of the mask prediction by density regression. in this way, the structure is similar to that in . this baseline is to verify whether the improvement of the proposed method merely comes from the architecture, or the mask prediction objective. from table ii, it is not hard to conclude that our bestperformed solution 5 still achieves significant improvement over baseline 3. recall that the difference between solution 5 and baseline 3 is that the former adopts the mask prediction as the training objective. the performance discrepancy of these two methods suggests that using mask information could indeed benefit the density estimation. the improvement of our method does not solely come from the network structure. in figure 4, we also visualize the estimated density maps of our best-performed method and baseline approaches. from 4, it is interesting to find that although the proposed approach gives more accurate count estimation, it does not provide a visibly better foreground/background separation than the baselines. this may suggest that the benefit of introducing the mask objective is not as simple as providing a better foreground/background separation. we postulate that the better performance achieved by our approach is due to that its density value estimation becomes more accurate with the guidance of the mask prediction. we also conduct a comparison experiment between binary cross entropy loss and focal loss. the result shows that the network with binary cross entropy loss can achieve almost ieee transactions on circuits and systems for video technology 7 fig. 4. a comparison of the density map generated by our best-performed method and two baselines in shanghaitech part a. the same performance: mae: 66.08, mse: 104.69 compared with that of the solution 5. so focal loss in this paper is a general setting for the mask branch. to compare the considered model with different backbones, we construct a new network with the same network structure in the solution 5 on top of a recent state-of-the-art network . to distinguish our proposed baseline, we term this network as our method csr for short. as shown in table ii, we can see our method csr can achieve a promising improvement over the original csrnet. to some extent, it indicates that a good baseline with the exploited network structure can boost the performance. also note that the pretrained model can be easily trained in a simple setting as shown in sec. iii compared to our proposed model trained from scratch. we argue that the main benefits derives from the pre-trained vgg 16. compared with csrnet, our proposed baseline is more computationally efficient. to show the interactions among the roi mask, input and density regression, we visualize the feature maps among those layers in figure 5. we use the test images) in the part a of shanghaitech dataset.we find that there exist mask errors after the sigmoid layer of the segmentation branch as shown in figure 5. we randomly selected one feature map after feeding back the predicted mask posterior. interestingly, from figure 5, it can be seen that the errors in the mask prediction are suppressed in the sampled feature map. this suggests that the network has the capability of separating the error pattern at the mask prediction stage into different feature maps and potentially suppressing the error signal for density estimation. after the fusion of the two branches, each feature map in the regressor only focuses on a small part of the interest region shown in figure 5. from the above discussion, we can see that even though there exist mask errors in the mask branch, they will not magnify in the next stage. finally, we get a refined density map as shown in figure 5. here we argue that the mask error will not magnify in the next stage. as is known, there are different density levels in the crowd. so we conduct the comparative experiment with three levels on shanghaitech part a to show the improvement of our method. we split the density into three types of crowd: low crowd , middle crowd and high crowd. from figure 6, it is easily concluded that the proposed method achieves a promising result on the low and middle level of crowd. this is because the proposed segmentation branch has the ability to discriminate background and foreground. as for high-level crowd, it poses a challenging situation for most methods. the texture information of the crowd people are missing in those scenes so it is really hard to exact robust features for each head. as a result, we can not see clear ieee transactions on circuits and systems for video technology 8 fig. 5. the visualization of feature maps in the mask branch. is the input image; is the output in segmentation branch; is randomly selected feature map from the feedback convolution layers of the segmentation branch; is randomly selected feature map after concatenating the feedback of segmentation branch; is the final predicted density map. fig. 6. the average mae of different density levels tested on shanghaitech part a. promotion in this interval. as for the our method with pretrained model, we can see that it has a similar improvement in low and middle crowds compared to the model with the proposed backbone while it also achieves a good result in high crowd. we conjecture that the pre-trained backbone has more prior knowledge to capture the texture information in high density level crowd than the model trained from scratch. e. comparison with the state-of-the-art we further compare our best-performed solution against the state-of-the-art results in various datasets. firstly, we make a comparison on the part a and part b of the shanghaitech dataset. we compare our method against cc-counting , fcn , mcnn, tdf-net , switching-net , , netvlad , cp-cnn and csrnet . the results are summarized in table 3. we can see that our method also achieves competitive results with the state-of-the-art methods and while keeping economic parameters. it is noted that the number of parameters of our proposed method is less than 5.1 million while the number in the cp-cnn is 68.4 million. so our method is more parameter economic and potentially more efficient. as for our method csr surpasses the two methods significantly in this dataset. specifically, the mae of part a is 61.8, which outperforms that of the csrnet by about 6.4. in terms of the mse, our proposed method shows significant improvement over csrnet by 13%. in part b, we also see that our method csr achieves 18.9% in mae and 16.9% in mse improvement compared to csrnet on part b. these results show the benefits of our proposed strategy in such a high variance scene. in addition, we report the results of our approach on ucf cc 50 dataset in table 4. our method obtains a 12.5 improvement in mae over cp-cnn but is worse than csrnet. we argue that the main reason lies in that the pretrained model enjoys more prior information compared with our model trained from scratch especially in such a small dataset. instead, our model csr armed with pre-trained vgg16 is superior to other models in mae. it should be noted that it shows 20.7 and 38.2 improvement over csrnet in terms of mae and mse, respectively. finally, we present the results of our method on the worldexpo' 10 dataset as shown in table v. our method with light weight achieves a relatively good performance which is on par with the state-of-the-art methods like tdf-net, netvlad, and classical methods mcnn and cccounting but it is inferior to csrnet and cp-cnn. besides, our model csr precedes csrnet and cp-cnn while obtaining the first place in s1, s2 and s5 scenes.\",\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'V',\n",
       " 'Section': 'V Conclusion',\n",
       " 'Text': \"in this paper, we address the crowd counting problem with deep neural networks. our main discovery is the benefit ieee transactions on circuits and systems for video technology 9 table iii the performance comparison on the shanghaitech dataset. part a part b method mae mse mae mse cc-counting 181.8 277.7 32.0 49.8 fcn 126.5 173.5 23.8 33.1 mcnn 110.2 173.2 26.4 41.3 tdf-net 97.5 145.1 20.7 32.8 switching-net 90.4 135.0 21.6 33.4 ba-cnn 20.2 35.6 netvlad 107.6 169.3 21.4 33.9 cp-cnn 73.6 106.4 20.1 30.1 csrnet 68.2 115.0 10.6 16.0 our method 65.7 107.8 11.7 16.4 our model csr 61.8 100.0 8.6 13.3 table iv the performance comparison on the ucf cc 50 dataset. method mae mse cc-counting 467.0 498.5 fcn 338.6 424.5 mcnn 377.6 509.1 tdf-net 354.7 491.4 switching-net 318.1 439.2 ba-cnn 409.5 563.7 netvlad 311.3 401.8 cp-cnn 295.8 320.9 csrnet 266.1 397.5 our method 283.3 411.6 our model csr 245.4 349.3 table v the performance comparison on the worldexpo'10 dataset. method s1 s2 s3 s4 s5 avg cc-counting 9.8 14.1 14.3 22.2 3.7 12.82 mcnn 3.4 20.6 12.9 13.0 8.1 11.6 tdf-net 2.7 23.4 10.7 17.6 3.3 11.54 switching-net 4.4 15.7 10.0 11.0 5.9 9.4 ba-cnn 4.1 21.7 11.9 11.0 3.5 10.44 netvlad 3.7 15.9 10.2 15.2 6.7 10.5 cp-cnn 2.9 14.7 10.5 10.4 5.8 8.86 csrnet 2.9 11.5 8.6 16.6 3.4 8.6 our method 3.0 16.7 11.6 12.5 4.1 9.58 our model csr 2.2 11.5 11.6 13.9 2.5 8.34 of using a dedicated network branch to predict the foreground/background mask and incorporating mask prediction into density map estimation. we systematically study five different designs of the mask-aware density estimator and identify the best performed solution. through the experimental validation, we show that the proposed scheme is effective and achieves the state-of-the-art crowd counting performance on various datasets. acknowledgment the authors would like to thank the editor and the anonymous reviewers for their valuable comments and constructive suggestions. this work is supported by the scientific research foundation of graduate school of southeast university , the postgraduate research & practice innovation program of jiangsu province , the national natural science foundation of china , key research and development program in jiangsu province and a project funded by the priority academic program development of jiangsu higher education institutions.\",\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Section_Num': 'References',\n",
       " 'Section': 'References',\n",
       " 'Text': '',\n",
       " 'Subsections': [],\n",
       " 'Groundtruth': ''}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open json file\n",
    "with open(f\"{project_processed_data_path}/{filename}.json\") as f:\n",
    "    data = json.load(f)\n",
    "    for item in data:\n",
    "        display(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section Name:  Abstract\n",
      "Generated Summary:   crowd counting problem aims to count the number of objects within an image or a\n",
      "frame in the videos and is usually solved by estimating the density map\n",
      "generated from the object location annotations. in contrast to traditional\n",
      "methods which do not differentiate the density prediction of these two states,\n",
      "we propose to use a dedicated network branch to predict the object/non-object\n",
      "mask and then combine its prediction with the input image to produce the density\n",
      "map. our rationale is that the mask prediction could be better modeled as a\n",
      "binary segmentation problem and the difficulty of estimating the density could\n",
      "be reduced if the mask is known. to this end, we study five possible solutions,\n",
      "and via analysis and experimental validation we identify the most effective one.\n",
      "through extensive experiments on five public datasets, we demonstrate the\n",
      "superior performance of the proposed approach over the baselines and show that\n",
      "our network could achieve the state-of-the-art performance.\n",
      "Section Name:  I Introduction\n",
      "Generated Summary:   rowd counting is a significant topic for crowd understanding and analysis -,\n",
      "which has attracted much attention in multimedia and computer vision community\n",
      "due to large and practical demands for better management, safety and security,.\n",
      "it aims to count the number of objects within an image or a frame in the videos\n",
      "and is a very challenging problem because the objects-of-interest, e.g, people,\n",
      "can occur at a variety of scales, with heavy occlusions and cluttered visual\n",
      "appearances. also, due to the difficulty in providing highly detailed\n",
      "annotations such as object bounding boxes or instance-level segmentation masks,\n",
      "existing datasets usually adopt a weak-level annotating scheme by labeling each\n",
      "object with a dot inside. these challenges make the traditional detection based\n",
      "approach less robust - and most existing methods - choose to solve this problem\n",
      "by estimating a density map generated from the dot-level annotation. in this\n",
      "paper, we propose to use a dedicated branch of a network to first predict the\n",
      "foreground/background mask, and then fuse the prediction with the input image to\n",
      "produce the final density map estimation to produce the final density map\n",
      "estimation.\n",
      "Section Name:  II Related work\n",
      "Generated Summary:   to date, many approaches have been proposed to study the issues existing in\n",
      "crowd counting, -. here we present a brief review of the related work. to date,\n",
      "many approaches have been proposed to study the issues existing in crowd\n",
      "counting, -. for a more detailed survey of crowd counting, we refer the readers\n",
      "to,,. detection seems to be a straightforward solution for crowd counting. the\n",
      "most early methods use hand-crafted features such as haar wavelets, histogram\n",
      "oriented gradients to model the pedestrian, which are then fed to classifiers to\n",
      "distinguish whether there is pedestrian or not. although monocularbased methods\n",
      "work well in a low density region, the performance is severely affected when\n",
      "they meet the crowded scenes with occlusion and scene clutter. as a alternative\n",
      "solution of the detection-based methods, the regression-based approaches are\n",
      "proposed to tackle the extremely dense crowds. it was shown that the density map\n",
      "regression framework offers a robust crowd counting solution for various\n",
      "challenging scenarios, and since then it becomes the mainstream framework for\n",
      "this problem.   various extensions - have been proposed to further improve the\n",
      "training and prediction of density maps. for example, the authors proposed to\n",
      "cast the crowd counting problem as a density map estimation problem.   the\n",
      "integral of the image density over any image region gives the count of objects\n",
      "within that region. the integral of the image density over any image region\n",
      "gives the count of objects within that region. the authors proposed to cast the\n",
      "crowd counting problem as a density map\n",
      "Section Name:  III Our proposed method\n",
      "Generated Summary:   this paper considers the case that a point-wise annotation is provided for\n",
      "training images. specifically, a dot is annotated within each object-of-interest\n",
      "and this pointwise annotation is further converted into a density map: d = x\n",
      "xibelong to a g. this paper considers the case that a point-wise annotation is\n",
      "provided for training images. specifically, a dot is annotated within each\n",
      "object-of-interest and this pointwise annotation is further converted into a\n",
      "density map: d = x xibelong to a g. this paper considers the case that a point-\n",
      "wise annotation is provided for training images. specifically, a dot is\n",
      "annotated within each object-of-interest and this pointwise annotation is\n",
      "further converted into a density map: d = x xibelong to a g. this paper\n",
      "considers the case that the counting problem can be cast as a density regression\n",
      "problem and the mean square loss is usually employed to train the regressor : lr\n",
      "= x x -d)2, where f is the regression network and {greek small letter lamda}2 as\n",
      "the empirically chosen variance term. a typical choice of {greek small letter\n",
      "sigma}2 will make g = 0 if x is not within the local neighborhood of\n",
      "Section Name:  IV Experiment\n",
      "Generated Summary:   in this paper, we propose a new approach for crowd counting density estimation\n",
      "based on mask-aware strategies.   the proposed approach is based on a network of\n",
      "3980 frames uniformly sampled from the videos sequences, where 3380 frames are\n",
      "used for training and the rest for testing.   we conduct experiments on three\n",
      "challenging public datasets including shanghaitech dataset, ucf cc 50 dataset\n",
      "and worldexpo' 10 dataset to demonstrate the effectiveness of our proposed\n",
      "method including shanghaitech dataset, ucf cc 50 dataset and worldexpo' 10\n",
      "dataset.   the purposes of our experiments are threefold : verify if the\n",
      "proposed mask-aware strategies lead to significant improvement over the\n",
      "baselines ; identify the most effective mask-aware density estimation solution ;\n",
      "and compare our proposed approach against the state-of-the-art methods. in our\n",
      "experiments, we use shanghaitech dataset a to achieve the first and the second\n",
      "objective.   then we present a detailed analysis of the proposed solutions and\n",
      "identify the most effective one. finally, we compare our method with other\n",
      "state-of-the-theart methods on all three datasets.      crowd counting, crowd\n",
      "estimation, mask-aware strategies, shanghai 2010 worldexpo.\n",
      "Section Name:  V Conclusion\n",
      "Generated Summary:   in this paper, we address the crowd counting problem with deep neural networks.\n",
      "our main discovery is the benefit ieee transactions on circuits and systems for\n",
      "video technology.\n",
      "Section Name:  References\n",
      "Generated Summary:   we report on the results of a detailed analysis of the @xmath0@xmath1@xmath2@xm\n",
      "ath3@xmath4@xmath5@xmath6@xmath7@xmath8@xmath9@xmath10@xmath11@xmath12@xmath13@x\n",
      "math14@xmath15@xmath16@xmath17@xmath18@xmath19@xmath20@xmath21@xmath22@xmath23@x\n",
      "math24@xmath25@xmath26@xmath27@xmath28@xmath29@xmath30@xmath40@xmath11@xmath11@x\n",
      "math12@xmath13@xmath14@xmath11@xmath12@xmath13@xmath14@xmath15@xmath12@xmath13@x\n",
      "math14@xmath15@xmath12@xmath13@xmath14@xmath15@xmath12@xmath13@xmath14@xmath15@x\n",
      "math12@xmath13@xmath14@xmath15@xmath12@xmath13@xmath14@xmath15@xmath12@xmath13@x\n",
      "math14@xmath15@xmath12@xmath13@xmath14@xmath15@xmath12@xmath13\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"gpt-3.5-turbo-0125\":\n",
    "    with open(f\"processed/{filename}.json\", encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    get_summaries(data)\n",
    "    with open(f\"gpt_summaries/{filename}.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "else:\n",
    "    summarizer = SummarizationModel(model_name)\n",
    "    model = summarizer.model\n",
    "\n",
    "    # path for the extracted pdf's json file\n",
    "    data_file_path = os.path.join('processed', f'{filename}.json')\n",
    "    # Load  the json file for summarization\n",
    "    pdf_data = load_data(data_file_path)\n",
    "\n",
    "    summarizer_model = SummarizationModel(model_name)\n",
    "\n",
    "    #Write the final summary to the summary jsonfile\n",
    "    output_file =os.path.join('model_summarizer/results/model-summary_results.json')\n",
    "    summarizer.summarize_pdf(pdf_data, output_file, summarizer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate PPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wang Zihan\\.conda\\envs\\dba5102\\lib\\site-packages\\transformers\\generation\\utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "section_texts = []\n",
    "section_names = []\n",
    "section_image_paths = []\n",
    "if model_name == \"gpt-3.5-turbo-0125\":\n",
    "    with open(f\"gpt_summaries/{filename}.json\", encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for section in data:\n",
    "        section_names.append(section[\"Section\"])\n",
    "        section_texts.append(get_section_groundtruth(section)) # Use GPT generated summaries\n",
    "        section_image_paths.append(get_section_image_paths(section))\n",
    "else:\n",
    "    with open(f\"processed/{filename}.json\", encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    for section in data:\n",
    "        section_names.append(section[\"Section\"])\n",
    "        section_texts.append(get_section_summary(section)) # Use pretrained model generated summaries\n",
    "        section_image_paths.append(get_section_image_paths(section))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the slide json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpt_ppt_parsing:\n",
    "    title_slide_data = get_title_slide_data(filename)\n",
    "    toc_slide_data = get_toc_slide_data(filename, section_names)\n",
    "    content_slide_datas = get_content_slide_datas(section_names, section_texts)\n",
    "else:\n",
    "    title_slide_data = {'title': filename, 'subtitle': 'Presentation subtitle'}\n",
    "    toc_slide_data = {'title': 'Table of Contents', 'content': [{'text': filename, 'indent_level': 0}]}\n",
    "    for section in data:\n",
    "        if section['Section'] == \"No_title\":\n",
    "            continue\n",
    "        toc_slide_data['content'].append({'text': section['Section'], 'indent_level': 1})\n",
    "    content_slide_datas = []\n",
    "    for i, section in enumerate(data):\n",
    "        if section['Section'] == \"No_title\":\n",
    "            continue\n",
    "        slide = {'title': section['Section'],\n",
    "                'content': []}\n",
    "        \n",
    "        sents = sent_tokenize(section_texts[i])\n",
    "        for sent in sents[1:]:\n",
    "            slide['content'].append({'text': sent, 'indent_level': 0})\n",
    "\n",
    "        content_slide_datas.append([slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = \"Parcel\"\n",
    "prs = generate_section_level_ppt(theme, title_slide_data, toc_slide_data, content_slide_datas, section_image_paths)\n",
    "prs.save(f\"powerpoints/{filename}.pptx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dba5102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
